{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Proactive Churn Prevention Multi-Agent System\n",
    "\n",
    "### Building an AI-Powered Customer Retention Engine with Google ADK v1.0.0+ & Vertex AI\n",
    "\n",
    "---\n",
    "\n",
    "### Business Objective\n",
    "Transform reactive churn prevention into **proactive customer retention** by predicting churn 45-60 days in advance and deploying personalized interventions.\n",
    "\n",
    "**Target Metrics:**\n",
    "- Retention Rate: 70% â†’ 85% (15% lift)\n",
    "- Intervention Timing: 5-10 days â†’ 45-60 days before churn\n",
    "- Expected ROI: 5-10x on retention investments\n",
    "\n",
    "### Technical Architecture\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    ORCHESTRATOR AGENT                           â”‚\n",
    "â”‚         (Coordinates workflow, manages agent communication)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                      â”‚\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â–¼             â–¼             â–¼             â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ BEHAVIORALâ”‚  â”‚ PREDICTIVEâ”‚  â”‚INTERVENTIONâ”‚ â”‚ EVALUATIONâ”‚\n",
    "â”‚   AGENT   â”‚  â”‚   AGENT   â”‚  â”‚   AGENT    â”‚ â”‚   AGENT   â”‚\n",
    "â”‚ (Parallel)â”‚  â”‚(Sequential)â”‚ â”‚(Sequential)â”‚ â”‚  (Loop)   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### ADK v1.0.0+ Key Changes\n",
    "- `Agent` replaces `LlmAgent`\n",
    "- `BuiltInCodeExecutor` replaces `CodeExecutionTool`\n",
    "- Pass functions directly to `tools` parameter\n",
    "- **Each agent can only have ONE parent** - create separate instances for different workflows\n",
    "\n",
    "### Notebook Execution Order (Logical Flow)\n",
    "\n",
    "| Phase | Section | Purpose | Creates |\n",
    "|-------|---------|---------|---------|\n",
    "| **1. Foundation** | 1-2 | Setup, Data Generation, Feature Engineering | `customer_df`, features |\n",
    "| **2. Modeling** | 3-4 | ML Training, Survival Analysis, Feature Importance, Model Evaluation | `SURVIVAL_INTERVENTION_STATS`, `MODEL_METRICS` |\n",
    "| **3. Experimentation** | 5 | A/B Testing Framework | `CHANNEL_EFFECTIVENESS`, `INTERVENTION_ROI` |\n",
    "| **4. Agents** | 6-7 | Tools & Agent Definitions | `recommend_intervention`, agents |\n",
    "| **5. Infrastructure** | 8-9 | Sessions, Memory, Observability | `memory_store`, `metrics` |\n",
    "| **6. Validation** | 10 | Local Testing | Test results |\n",
    "| **7. Presentation** | 11 | Executive Dashboard | PNG charts |\n",
    "| **8. Production** | 12-13 | Deployment & Cleanup | Cloud deployment |\n",
    "\n",
    "### Key Concepts & AI Agents Implemented \n",
    "1. âœ… **Multi-Agent System** - Parallel + Sequential + Loop agents\n",
    "2. âœ… **Tools** - Built-in (Code Execution) + Custom tools\n",
    "3. âœ… **Sessions & Memory** - InMemorySessionService + long-term customer history\n",
    "4. âœ… **Context Engineering** - Context compaction for large datasets\n",
    "5. âœ… **Observability** - Logging, tracing, metrics\n",
    "6. âœ… **Agent Evaluation** - Distributed evaluation agents\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Configuration\n",
    "\n",
    "### Model: gemini-2.5-flash on Vertex AI\n",
    "\n",
    "This notebook uses `gemini-2.5-flash` via Vertex AI for best performance.\n",
    "\n",
    "**Important Limitation:** gemini-2.5-flash only supports **one tool per agent**. The agents are configured accordingly:\n",
    "- Each sub-agent has a single specialized tool\n",
    "- The orchestrator delegates to sub-agents instead of calling tools directly\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. **Install dependencies:**\n",
    "   ```bash\n",
    "   pip install google-cloud-aiplatform google-adk google-genai python-dotenv\n",
    "   ```\n",
    "\n",
    "2. **Authenticate with Google Cloud:**\n",
    "   ```bash\n",
    "   gcloud auth application-default login\n",
    "   ```\n",
    "\n",
    "3. **Configure your `.env` file:**\n",
    "   ```\n",
    "   GOOGLE_CLOUD_PROJECT=your-project-id\n",
    "   GOOGLE_CLOUD_LOCATION=us-central1\n",
    "   LLM_MODEL=gemini-2.5-flash\n",
    "   ```\n",
    "\n",
    "4. **Run the notebook from Cell 1**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… google-adk: 1.19.0\n",
      "âœ… google-cloud-aiplatform: 1.128.0\n",
      "âœ… vertexai: 1.128.0\n",
      "âœ… pandas: 2.3.3\n",
      "âœ… numpy: 2.3.5\n",
      "âœ… scikit-learn: 1.7.2\n",
      "âœ… lifelines: 0.30.0\n"
     ]
    }
   ],
   "source": [
    "# Verify installations\n",
    "import importlib\n",
    "\n",
    "packages = [\n",
    "    ('google.adk', 'google-adk'),\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('vertexai', 'vertexai'),\n",
    "    ('pandas', 'pandas'),\n",
    "    ('numpy', 'numpy'),\n",
    "    ('sklearn', 'scikit-learn'),\n",
    "    ('lifelines', 'lifelines')\n",
    "]\n",
    "\n",
    "for pkg, name in packages:\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        version = getattr(mod, '__version__', 'unknown')\n",
    "        print(f\"âœ… {name}: {version}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Removing GOOGLE_API_KEY to ensure Vertex AI is used\n",
      "âœ… Vertex AI initialized (project=sunlit-gamma-342416, location=us-central1)\n",
      "\n",
      "Configuration:\n",
      "  Base Model: gemini-2.5-flash\n",
      "  Vertex Model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash\n",
      "  Project: sunlit-gamma-342416\n",
      "  Region: us-central1\n",
      "  Vertex AI: âœ… Ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibrahimabarry/Documents/Proactive-churn-prevention/churn_env/lib/python3.12/site-packages/google/auth/_default.py:108: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Auth: âœ… Credentials configured\n"
     ]
    }
   ],
   "source": [
    "# Google Cloud Authentication for Local Notebook\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# ---------------------------\n",
    "# Google Cloud configuration\n",
    "# ---------------------------\n",
    "PROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\", \"sunlit-gamma-342416\")\n",
    "REGION = os.getenv(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\")\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-churn-agents\"\n",
    "\n",
    "# ---------------------------\n",
    "# Model Configuration for Vertex AI\n",
    "# ---------------------------\n",
    "BASE_MODEL = os.getenv(\"LLM_MODEL\", \"gemini-2.5-flash\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\", \"text-embedding-004\")\n",
    "\n",
    "# Create Vertex AI model string format\n",
    "# This tells google-genai to use Vertex AI backend\n",
    "VERTEX_MODEL = f\"projects/{PROJECT_ID}/locations/{REGION}/publishers/google/models/{BASE_MODEL}\"\n",
    "\n",
    "# For backward compatibility\n",
    "LLM_MODEL = VERTEX_MODEL\n",
    "\n",
    "# Remove GOOGLE_API_KEY if present (it would override Vertex AI)\n",
    "if os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"ğŸ”§ Removing GOOGLE_API_KEY to ensure Vertex AI is used\")\n",
    "    del os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "# Set environment variables for Vertex AI\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "os.environ[\"GOOGLE_CLOUD_REGION\"] = REGION\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = REGION\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"true\"\n",
    "\n",
    "# Agent configuration\n",
    "AGENT_NAME = os.getenv(\"AGENT_NAME\", \"churn_prevention_agent\")\n",
    "AGENT_DISPLAY_NAME = os.getenv(\"AGENT_DISPLAY_NAME\", \"Proactive Churn Prevention System\")\n",
    "APP_NAME = os.getenv(\"APP_NAME\", \"agents\")\n",
    "\n",
    "# ---------------------------\n",
    "# Initialize Vertex AI\n",
    "# ---------------------------\n",
    "VERTEX_AI_INITIALIZED = False\n",
    "try:\n",
    "    import vertexai\n",
    "    vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "    VERTEX_AI_INITIALIZED = True\n",
    "    print(f\"âœ… Vertex AI initialized (project={PROJECT_ID}, location={REGION})\")\n",
    "except ImportError:\n",
    "    print(\"âŒ vertexai not installed. Run: pip install google-cloud-aiplatform\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Vertex AI init failed: {e}\")\n",
    "    print(\"   Run: gcloud auth application-default login\")\n",
    "\n",
    "# ---------------------------\n",
    "# Global reproducibility settings\n",
    "# ---------------------------\n",
    "SEED = int(os.getenv(\"SEED\", \"42\"))\n",
    "ALPHA = float(os.getenv(\"ALPHA\", \"0.05\"))\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# ---------------------------\n",
    "# Summary\n",
    "# ---------------------------\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Base Model: {BASE_MODEL}\")\n",
    "print(f\"  Vertex Model: {VERTEX_MODEL}\")\n",
    "print(f\"  Project: {PROJECT_ID}\")\n",
    "print(f\"  Region: {REGION}\")\n",
    "print(f\"  Vertex AI: {'âœ… Ready' if VERTEX_AI_INITIALIZED else 'âŒ Not initialized'}\")\n",
    "\n",
    "# Validate authentication\n",
    "try:\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    print(f\"  Auth: âœ… Credentials configured\")\n",
    "except Exception as e:\n",
    "    print(f\"  Auth: âŒ Run: gcloud auth application-default login\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Preparation\n",
    "\n",
    "Generate synthetic customer data with realistic churn patterns for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ² Model seed: 42 | A/B test seed: 11\n",
      "ğŸ² Using seeds â†’ model=42 | ab_test=11\n",
      "âœ… Generated 6000 customers\n",
      "   Churn rate: 21.0%\n",
      "   Churned: 1261 | Retained: 4739\n",
      "   Tenure range: 1-120 months\n",
      "\n",
      "ğŸ“‹ Columns: ['customer_id', 'tenure_months', 'subscription_tier', 'monthly_charges', 'login_frequency_monthly', 'feature_usage_pct', 'support_tickets_90d', 'payment_delays_12m', 'discount_count', 'nps_score', 'email_open_rate', 'last_activity_days', 'churned']\n",
      "\n",
      "âš ï¸  To be PREDICTED by models:\n",
      "   â€¢ churn_probability        â†’ Logistic Regression (Cell 7)\n",
      "   â€¢ predicted_days_until_churn â†’ Survival Analysis (Cell 8)\n",
      "âœ… Data validation passed: raw_generated (rows=6,000, churn_rate=21.0%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>subscription_tier</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>login_frequency_monthly</th>\n",
       "      <th>feature_usage_pct</th>\n",
       "      <th>support_tickets_90d</th>\n",
       "      <th>payment_delays_12m</th>\n",
       "      <th>discount_count</th>\n",
       "      <th>nps_score</th>\n",
       "      <th>email_open_rate</th>\n",
       "      <th>last_activity_days</th>\n",
       "      <th>churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST_000001</td>\n",
       "      <td>11</td>\n",
       "      <td>Standard</td>\n",
       "      <td>81.44</td>\n",
       "      <td>17</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.473</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUST_000002</td>\n",
       "      <td>72</td>\n",
       "      <td>Basic</td>\n",
       "      <td>26.56</td>\n",
       "      <td>15</td>\n",
       "      <td>18.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.070</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUST_000003</td>\n",
       "      <td>31</td>\n",
       "      <td>Premium</td>\n",
       "      <td>141.32</td>\n",
       "      <td>20</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.234</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUST_000004</td>\n",
       "      <td>21</td>\n",
       "      <td>Standard</td>\n",
       "      <td>83.32</td>\n",
       "      <td>13</td>\n",
       "      <td>29.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST_000005</td>\n",
       "      <td>4</td>\n",
       "      <td>Basic</td>\n",
       "      <td>29.17</td>\n",
       "      <td>16</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.514</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  tenure_months subscription_tier  monthly_charges  \\\n",
       "0  CUST_000001             11          Standard            81.44   \n",
       "1  CUST_000002             72             Basic            26.56   \n",
       "2  CUST_000003             31           Premium           141.32   \n",
       "3  CUST_000004             21          Standard            83.32   \n",
       "4  CUST_000005              4             Basic            29.17   \n",
       "\n",
       "   login_frequency_monthly  feature_usage_pct  support_tickets_90d  \\\n",
       "0                       17               19.0                    4   \n",
       "1                       15               18.7                    3   \n",
       "2                       20               27.1                    1   \n",
       "3                       13               29.7                    3   \n",
       "4                       16               11.5                    1   \n",
       "\n",
       "   payment_delays_12m  discount_count  nps_score  email_open_rate  \\\n",
       "0                   0               0          7            0.473   \n",
       "1                   2               4          2            0.070   \n",
       "2                   0               0          8            0.234   \n",
       "3                   0               5          7            0.538   \n",
       "4                   0               1          7            0.514   \n",
       "\n",
       "   last_activity_days  churned  \n",
       "0                   6        0  \n",
       "1                   5        1  \n",
       "2                  31        1  \n",
       "3                   6        0  \n",
       "4                   5        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from typing import Dict, Any, List, Optional\n",
    "import os\n",
    "\n",
    "# ============================================================\n",
    "# REPRODUCIBILITY CONFIGURATION\n",
    "# ============================================================\n",
    "MODEL_SEED = 42      # For synthetic data generation and model training\n",
    "ABTEST_SEED = 11      # For A/B test simulation\n",
    "\n",
    "np.random.seed(MODEL_SEED)\n",
    "print(f\"ğŸ² Model seed: {MODEL_SEED} | A/B test seed: {ABTEST_SEED}\")\n",
    "# ============================================================\n",
    "# PROJECT CONFIGURATION (centralized assumptions)\n",
    "# ============================================================\n",
    "# Notes:\n",
    "# - \"synthetic_label\" settings are used ONLY to generate the churn label in the synthetic dataset.\n",
    "# - Thresholds can be \"fixed\" (default) or \"data_derived\" (quantile-based). See THRESHOLD_MODE below.\n",
    "\n",
    "THRESHOLD_MODE = os.getenv(\"THRESHOLD_MODE\", \"fixed\").strip().lower()  # \"fixed\" | \"data_derived\"\n",
    "\n",
    "CONFIG: Dict[str, Any] = {\n",
    "    \"seeds\": {\n",
    "        \"model\": int(os.getenv(\"MODEL_SEED\", MODEL_SEED)),\n",
    "        \"ab_test\": int(os.getenv(\"ABTEST_SEED\", ABTEST_SEED)),\n",
    "    },\n",
    "    \"paths\": {\n",
    "        # Prefer a working-directory path; override via env var when needed.\n",
    "        \"customer_csv\": os.getenv(\"CUSTOMER_CSV_PATH\", os.path.join(os.getcwd(), \"customer_churn_data.csv\")),\n",
    "        \"viz_dir\": os.getenv(\"VIZ_DIR\", \"./viz\"),\n",
    "    },\n",
    "    \"risk_tiers\": {\n",
    "        # Fixed cutoffs (probability thresholds)\n",
    "        \"cutoffs\": {\"critical\": 0.75, \"high\": 0.50, \"medium\": 0.25},\n",
    "        # Data-derived cutoffs (quantiles of churn_probability), used when THRESHOLD_MODE=\"data_derived\"\n",
    "        \"quantiles\": {\"medium\": 0.50, \"high\": 0.75, \"critical\": 0.90},\n",
    "    },\n",
    "    \"feature_thresholds\": {\n",
    "        \"support_tickets_heavy\": 3,\n",
    "        \"inactivity_days\": 14,\n",
    "        \"nps_low\": 7,\n",
    "        \"engagement_low\": 30,\n",
    "        \"payment_delays_high\": 2,\n",
    "        \"high_value_clv\": 5000,\n",
    "        \"mid_value_clv\": 3000,\n",
    "    },\n",
    "    \"synthetic_label\": {\n",
    "        \"weights\": {\n",
    "            \"tenure_months\": -0.02,\n",
    "            \"login_frequency_monthly\": -0.03,\n",
    "            \"feature_usage_pct\": -0.02,\n",
    "            \"support_tickets_90d\": 0.15,\n",
    "            \"payment_delays_12m\": 0.25,\n",
    "            \"nps_score\": -0.10,\n",
    "            \"last_activity_days\": 0.02,\n",
    "        },\n",
    "        \"noise_sigma\": 0.50,\n",
    "    },\n",
    "    \"survival\": {\n",
    "        \"observation_window_days\": 120,\n",
    "        \"min_duration_days\": 7,\n",
    "        \"max_prediction_days\": 180,\n",
    "        # Risk score weights used to simulate churn timing in the synthetic survival labels\n",
    "        \"risk_score_weights\": {\n",
    "            \"has_payment_issues\": 0.25,\n",
    "            \"is_inactive\": 0.20,\n",
    "            \"support_tickets_90d_scaled\": 0.20,\n",
    "            \"low_engagement\": 0.20,\n",
    "            \"low_nps\": 0.15,\n",
    "        },\n",
    "        \"risk_score_clip\": (0.05, 0.95),\n",
    "        \"mean_time_scale\": 0.70,  # how strongly risk accelerates churn in the synthetic timing labels\n",
    "        \"window_start_multiplier_q25\": 0.50,\n",
    "    },\n",
    "    \"ab_test\": {\n",
    "        \"alpha\": 0.05,\n",
    "        \"power_target\": 0.80,\n",
    "        \"recommendation_relative_lift\": {\"strong\": 0.30, \"moderate\": 0.15, \"weak\": 0.00},\n",
    "    },\n",
    "    \"business_impact\": {\n",
    "        \"default_risk_threshold\": 0.75,\n",
    "        \"expected_lift_default\": 0.30,\n",
    "        \"avg_cost_default\": 500,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# Refresh module-level seeds from CONFIG (allows environment overrides)\n",
    "MODEL_SEED = CONFIG[\"seeds\"][\"model\"]\n",
    "ABTEST_SEED = CONFIG[\"seeds\"][\"ab_test\"]\n",
    "np.random.seed(MODEL_SEED)\n",
    "print(f\"ğŸ² Using seeds â†’ model={MODEL_SEED} | ab_test={ABTEST_SEED}\")\n",
    "\n",
    "# Ensure viz directory exists\n",
    "os.makedirs(CONFIG[\"paths\"][\"viz_dir\"], exist_ok=True)\n",
    "\n",
    "def classify_risk(prob: float, cutoffs: Optional[Dict[str, float]] = None) -> str:\n",
    "    \"\"\"Map churn probability to risk tier using CONFIG cutoffs.\"\"\"\n",
    "    c = cutoffs or CONFIG[\"risk_tiers\"][\"cutoffs\"]\n",
    "    if prob >= c[\"critical\"]:\n",
    "        return \"Critical\"\n",
    "    if prob >= c[\"high\"]:\n",
    "        return \"High\"\n",
    "    if prob >= c[\"medium\"]:\n",
    "        return \"Medium\"\n",
    "    return \"Low\"\n",
    "\n",
    "def apply_threshold_mode(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Optionally derive thresholds from the current dataset distribution.\n",
    "    Updates CONFIG in-place.\n",
    "    \"\"\"\n",
    "    global THRESHOLD_MODE\n",
    "    if THRESHOLD_MODE != \"data_derived\":\n",
    "        print(f\"ğŸ”§ Threshold mode: fixed (risk cutoffs={CONFIG['risk_tiers']['cutoffs']})\")\n",
    "        return\n",
    "\n",
    "    if \"churn_probability\" not in df.columns:\n",
    "        print(\"ğŸ”§ Threshold mode: data_derived requested, but churn_probability is not available yet. Using fixed thresholds for now.\")\n",
    "        return\n",
    "\n",
    "    q = CONFIG[\"risk_tiers\"][\"quantiles\"]\n",
    "    cutoffs = {\n",
    "        \"medium\": float(df[\"churn_probability\"].quantile(q[\"medium\"])),\n",
    "        \"high\": float(df[\"churn_probability\"].quantile(q[\"high\"])),\n",
    "        \"critical\": float(df[\"churn_probability\"].quantile(q[\"critical\"])),\n",
    "    }\n",
    "    # Enforce monotonicity\n",
    "    cutoffs[\"high\"] = max(cutoffs[\"high\"], cutoffs[\"medium\"])\n",
    "    cutoffs[\"critical\"] = max(cutoffs[\"critical\"], cutoffs[\"high\"])\n",
    "    CONFIG[\"risk_tiers\"][\"cutoffs\"] = cutoffs\n",
    "    print(f\"ğŸ”§ Threshold mode: data_derived (risk cutoffs={CONFIG['risk_tiers']['cutoffs']}, quantiles={q})\")\n",
    "\n",
    "def validate_customer_df(df: pd.DataFrame, stage: str) -> None:\n",
    "    \"\"\"\n",
    "    Lightweight validation for data consistency and silent failure prevention.\n",
    "    Raises ValueError for critical issues.\n",
    "    \"\"\"\n",
    "    required = {\"customer_id\", \"tenure_months\", \"subscription_tier\", \"monthly_charges\",\n",
    "                \"login_frequency_monthly\", \"feature_usage_pct\", \"support_tickets_90d\",\n",
    "                \"payment_delays_12m\", \"discount_count\", \"nps_score\", \"email_open_rate\",\n",
    "                \"last_activity_days\", \"churned\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"[{stage}] Missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    if df[\"customer_id\"].isna().any():\n",
    "        raise ValueError(f\"[{stage}] customer_id contains nulls\")\n",
    "    if df[\"customer_id\"].duplicated().any():\n",
    "        # duplicates are not always fatal, but for this notebook we treat them as critical\n",
    "        raise ValueError(f\"[{stage}] customer_id has duplicates\")\n",
    "\n",
    "    # Range checks (non-fatal warnings where appropriate)\n",
    "    if not df[\"churned\"].isin([0, 1]).all():\n",
    "        raise ValueError(f\"[{stage}] churned must be binary (0/1)\")\n",
    "    if (df[\"nps_score\"].min() < 0) or (df[\"nps_score\"].max() > 10):\n",
    "        raise ValueError(f\"[{stage}] nps_score must be in [0, 10]\")\n",
    "    if (df[\"email_open_rate\"].min() < 0) or (df[\"email_open_rate\"].max() > 1):\n",
    "        raise ValueError(f\"[{stage}] email_open_rate must be in [0, 1]\")\n",
    "    if (df[\"feature_usage_pct\"].min() < 0) or (df[\"feature_usage_pct\"].max() > 100):\n",
    "        raise ValueError(f\"[{stage}] feature_usage_pct must be in [0, 100]\")\n",
    "    if (df[\"tenure_months\"].min() < 0):\n",
    "        raise ValueError(f\"[{stage}] tenure_months must be non-negative\")\n",
    "\n",
    "    # Optional columns sanity\n",
    "    for prob_col in [\"churn_probability\"]:\n",
    "        if prob_col in df.columns:\n",
    "            if (df[prob_col].min() < 0) or (df[prob_col].max() > 1):\n",
    "                raise ValueError(f\"[{stage}] {prob_col} must be in [0, 1]\")\n",
    "\n",
    "    print(f\"âœ… Data validation passed: {stage} (rows={len(df):,}, churn_rate={df['churned'].mean():.1%})\")\n",
    "\n",
    "def generate_customer_data(n_customers: int = 3000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate synthetic customer data with realistic churn patterns.\n",
    "    \n",
    "    ML WORKFLOW:\n",
    "    - This function generates ONLY ground truth labels and features\n",
    "    - churn_probability â†’ PREDICTED by Logistic Regression \n",
    "    - days_until_churn  â†’ PREDICTED by Survival Analysis \n",
    "    \n",
    "    NOTE: tenure_months serves dual purpose:\n",
    "    - Feature for churn prediction\n",
    "    - Observation duration for survival analysis (converted to days)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_customers : int\n",
    "        Number of customers to generate\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Customer data with features and churned label\n",
    "    \"\"\"\n",
    "    np.random.seed(MODEL_SEED)\n",
    "    \n",
    "    # Customer IDs\n",
    "    customer_ids = [f\"CUST_{i:06d}\" for i in range(1, n_customers + 1)]\n",
    "    \n",
    "    # Demographics\n",
    "    tenure_months = np.random.exponential(scale=24, size=n_customers).astype(int)\n",
    "    tenure_months = np.clip(tenure_months, 1, 120)\n",
    "    \n",
    "    subscription_tiers = np.random.choice(\n",
    "        ['Basic', 'Standard', 'Premium', 'Enterprise'],\n",
    "        size=n_customers,\n",
    "        p=[0.30, 0.35, 0.25, 0.10]\n",
    "    )\n",
    "    \n",
    "    tier_charges = {'Basic': 29, 'Standard': 79, 'Premium': 149, 'Enterprise': 299}\n",
    "    monthly_charges = [tier_charges[tier] * np.random.uniform(0.9, 1.1) for tier in subscription_tiers]\n",
    "    \n",
    "    # Behavioral signals\n",
    "    login_frequency = np.random.poisson(lam=15, size=n_customers)\n",
    "    feature_usage_pct = np.random.beta(a=2, b=5, size=n_customers) * 100\n",
    "    support_tickets_90d = np.random.poisson(lam=2, size=n_customers)\n",
    "    \n",
    "    # Financial indicators\n",
    "    payment_delays_12m = np.random.poisson(lam=0.5, size=n_customers)\n",
    "    discount_count = np.random.poisson(lam=1, size=n_customers)\n",
    "    \n",
    "    # Engagement metrics\n",
    "    nps_score = np.random.choice(range(0, 11), size=n_customers, p=[\n",
    "        0.02, 0.02, 0.03, 0.05, 0.08, 0.10, 0.15, 0.20, 0.18, 0.12, 0.05\n",
    "    ])\n",
    "    email_open_rate = np.random.beta(a=3, b=4, size=n_customers)\n",
    "    last_activity_days = np.random.exponential(scale=7, size=n_customers).astype(int)\n",
    "    \n",
    "    # ================================================================\n",
    "    # GENERATE CHURN LABELS (Ground Truth)\n",
    "    # The ML model will learn to predict this from features\n",
    "    # ================================================================\n",
    "    churn_score = (\n",
    "        CONFIG[\"synthetic_label\"][\"weights\"][\"tenure_months\"] * tenure_months +\n",
    "        CONFIG[\"synthetic_label\"][\"weights\"][\"login_frequency_monthly\"] * login_frequency +\n",
    "        CONFIG[\"synthetic_label\"][\"weights\"][\"feature_usage_pct\"] * feature_usage_pct +\n",
    "        CONFIG[\"synthetic_label\"][\"weights\"][\"support_tickets_90d\"] * support_tickets_90d +\n",
    "        CONFIG[\"synthetic_label\"][\"weights\"][\"payment_delays_12m\"] * payment_delays_12m +\n",
    "        CONFIG[\"synthetic_label\"][\"weights\"][\"nps_score\"] * nps_score +\n",
    "        CONFIG[\"synthetic_label\"][\"weights\"][\"last_activity_days\"] * last_activity_days +\n",
    "        np.random.normal(0, CONFIG[\"synthetic_label\"][\"noise_sigma\"], n_customers)\n",
    "    )\n",
    "    \n",
    "    # Hidden probability (used ONLY for label generation, NOT stored)\n",
    "    _hidden_prob = 1 / (1 + np.exp(-churn_score))\n",
    "    churned = np.random.binomial(1, _hidden_prob)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'customer_id': customer_ids,\n",
    "        'tenure_months': tenure_months,\n",
    "        'subscription_tier': subscription_tiers,\n",
    "        'monthly_charges': np.round(monthly_charges, 2),\n",
    "        'login_frequency_monthly': login_frequency,\n",
    "        'feature_usage_pct': np.round(feature_usage_pct, 1),\n",
    "        'support_tickets_90d': support_tickets_90d,\n",
    "        'payment_delays_12m': payment_delays_12m,\n",
    "        'discount_count': discount_count,\n",
    "        'nps_score': nps_score,\n",
    "        'email_open_rate': np.round(email_open_rate, 3),\n",
    "        'last_activity_days': last_activity_days,\n",
    "        'churned': churned\n",
    "        # âš ï¸ NO churn_probability - PREDICTED by model (Cell 7)\n",
    "        # âš ï¸ NO days_until_churn - PREDICTED by survival model (Cell 8)\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate dataset\n",
    "customer_df = generate_customer_data(n_customers=6000)\n",
    "\n",
    "print(f\"âœ… Generated {len(customer_df)} customers\")\n",
    "print(f\"   Churn rate: {customer_df['churned'].mean():.1%}\")\n",
    "print(f\"   Churned: {customer_df['churned'].sum()} | Retained: {(customer_df['churned'] == 0).sum()}\")\n",
    "print(f\"   Tenure range: {customer_df['tenure_months'].min()}-{customer_df['tenure_months'].max()} months\")\n",
    "print(f\"\\nğŸ“‹ Columns: {list(customer_df.columns)}\")\n",
    "print(f\"\\nâš ï¸  To be PREDICTED by models:\")\n",
    "print(f\"   â€¢ churn_probability        â†’ Logistic Regression (Cell 7)\")\n",
    "print(f\"   â€¢ predicted_days_until_churn â†’ Survival Analysis (Cell 8)\")\n",
    "\n",
    "\n",
    "# Validate raw generated dataset\n",
    "validate_customer_df(customer_df, stage=\"raw_generated\")\n",
    "\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature engineering complete\n",
      "\n",
      "ğŸ“‹ New features added:\n",
      "   - engagement_score: 44.7 (mean)\n",
      "   - is_high_value: 2039 customers\n",
      "   - has_payment_issues: 2398 customers\n",
      "   - is_heavy_support_user: 1961 customers\n",
      "   - is_inactive: 715 customers\n",
      "   - clv_estimate: $1,931 (mean)\n",
      "   - risk_score_baseline: 39.4 (mean)\n",
      "âœ… Data validation passed: features_engineered (rows=6,000, churn_rate=21.0%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "\n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Engineer features for churn prediction model.\n",
    "    \n",
    "    Creates the following features:\n",
    "    - engagement_score: Composite metric (0-100) from login, usage, email, NPS\n",
    "    - is_high_value: Binary flag for Premium/Enterprise customers\n",
    "    - has_payment_issues: Binary flag for payment delays > 0\n",
    "    - is_heavy_support_user: Binary flag for support tickets >= CONFIG[\"feature_thresholds\"][\"support_tickets_heavy\"]\n",
    "    - is_inactive: Binary flag for last_activity_days > CONFIG[\"feature_thresholds\"][\"inactivity_days\"]\n",
    "    - clv_estimate: Customer lifetime value estimate\n",
    "    - risk_score_baseline: Composite risk score (0-100)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Customer data with required columns\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with engineered features added\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Engagement Score (composite metric)\n",
    "    login_max = df['login_frequency_monthly'].max()\n",
    "    login_max = float(login_max) if login_max and login_max > 0 else 1.0\n",
    "    \n",
    "    df['engagement_score'] = (\n",
    "        0.3 * (df['login_frequency_monthly'] / login_max) +\n",
    "        0.3 * (df['feature_usage_pct'] / 100) +\n",
    "        0.2 * df['email_open_rate'] +\n",
    "        0.2 * (df['nps_score'] / 10)\n",
    "    ) * 100\n",
    "    \n",
    "    # Risk Indicators (binary flags)\n",
    "    df['is_high_value'] = (df['subscription_tier'].isin(['Premium', 'Enterprise'])).astype(int)\n",
    "    df['has_payment_issues'] = (df['payment_delays_12m'] > 0).astype(int)\n",
    "    df['is_heavy_support_user'] = (df['support_tickets_90d'] >= CONFIG['feature_thresholds']['support_tickets_heavy']).astype(int)\n",
    "    df['is_inactive'] = (df['last_activity_days'] > CONFIG['feature_thresholds']['inactivity_days']).astype(int)\n",
    "    \n",
    "    # Customer Lifetime Value estimate\n",
    "    df['clv_estimate'] = df['monthly_charges'] * df['tenure_months'] * 0.8\n",
    "    \n",
    "    # Baseline Risk Score (rule-based, before ML)\n",
    "    df['risk_score_baseline'] = (\n",
    "        25 * df['has_payment_issues'] +\n",
    "        20 * df['is_heavy_support_user'] +\n",
    "        15 * df['is_inactive'] +\n",
    "        10 * (df['nps_score'] < CONFIG['feature_thresholds']['nps_low']).astype(int) +\n",
    "        30 * (1 - df['engagement_score'] / 100)\n",
    "    )\n",
    "    df['risk_score_baseline'] = np.clip(df['risk_score_baseline'], 0, 100)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "customer_df = engineer_features(customer_df)\n",
    "\n",
    "print(\"âœ… Feature engineering complete\")\n",
    "print(f\"\\nğŸ“‹ New features added:\")\n",
    "print(f\"   - engagement_score: {customer_df['engagement_score'].mean():.1f} (mean)\")\n",
    "print(f\"   - is_high_value: {customer_df['is_high_value'].sum()} customers\")\n",
    "print(f\"   - has_payment_issues: {customer_df['has_payment_issues'].sum()} customers\")\n",
    "print(f\"   - is_heavy_support_user: {customer_df['is_heavy_support_user'].sum()} customers\")\n",
    "print(f\"   - is_inactive: {customer_df['is_inactive'].sum()} customers\")\n",
    "print(f\"   - clv_estimate: ${customer_df['clv_estimate'].mean():,.0f} (mean)\")\n",
    "print(f\"   - risk_score_baseline: {customer_df['risk_score_baseline'].mean():.1f} (mean)\")\n",
    "\n",
    "customer_df[['customer_id', 'engagement_score', 'risk_score_baseline', 'clv_estimate', 'churned']].head()\n",
    "\n",
    "\n",
    "# Validate feature-engineered dataset\n",
    "validate_customer_df(customer_df, stage=\"features_engineered\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Modeling\n",
    "\n",
    "This section covers:\n",
    "1. **Churn Prediction Model** - Logistic Regression training with feature engineering\n",
    "2. **Survival Analysis** - When will customers churn? (Cox Proportional Hazards)\n",
    "3. **Feature Importance & Actionability** - Which features matter and can we influence them?\n",
    "\n",
    "Key outputs:\n",
    "- `churn_probability` for each customer\n",
    "- `SURVIVAL_INTERVENTION_STATS` - optimal intervention window (Day 46-95)\n",
    "- Feature importance rankings with actionability scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¤– CHURN PREDICTION MODEL TRAINING\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Dataset Overview:\n",
      "   Total customers: 6000\n",
      "   Features: 15\n",
      "   Churn rate: 21.0%\n",
      "\n",
      "ğŸ“Š Train/Test Split:\n",
      "   Training set: 4800 samples (21.0% churn rate)\n",
      "   Test set: 1200 samples (21.0% churn rate)\n",
      "\n",
      "âœ… Features scaled using StandardScaler\n",
      "\n",
      "ğŸ”§ Training Logistic Regression model...\n",
      "âœ… Model trained successfully\n",
      "\n",
      "âœ… Model training complete. Run Section 4 for detailed evaluation.\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š GENERATING CHURN PROBABILITIES\n",
      "============================================================\n",
      "âœ… Data validation passed: with_churn_probability (rows=6,000, churn_rate=21.0%)\n",
      "\n",
      "âœ… Added 'churn_probability' column to customer_df\n",
      "\n",
      "ğŸ“Š Churn Probability Distribution:\n",
      "   Min:    0.0454\n",
      "   25th:   0.3793\n",
      "   Median: 0.4903\n",
      "   75th:   0.5815\n",
      "   Max:    0.9223\n",
      "ğŸ”§ Threshold mode: fixed (risk cutoffs={'critical': 0.75, 'high': 0.5, 'medium': 0.25})\n",
      "\n",
      "ğŸ“Š Risk Tier Distribution:\n",
      "   Low: 492 (8.2%)\n",
      "   Medium: 2683 (44.7%)\n",
      "   High: 2718 (45.3%)\n",
      "   Critical: 107 (1.8%)\n",
      "\n",
      "âœ… Model artifacts stored: CHURN_MODEL, CHURN_SCALER, CHURN_FEATURES_LIST\n",
      "\n",
      "ğŸ‰ Churn prediction model training complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CHURN PREDICTION MODEL TRAINING\n",
    "# ============================================================\n",
    "# This is the core ML step: train a model to PREDICT churn probability\n",
    "# from customer features. The model learns patterns from historical data.\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Metrics moved to Section 4 (Model Evaluation)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¤– CHURN PREDICTION MODEL TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define features for churn prediction\n",
    "CHURN_FEATURES = [\n",
    "    'tenure_months', 'monthly_charges', 'login_frequency_monthly',\n",
    "    'feature_usage_pct', 'support_tickets_90d', 'payment_delays_12m',\n",
    "    'discount_count', 'nps_score', 'email_open_rate', 'last_activity_days',\n",
    "    'engagement_score', 'is_high_value', 'has_payment_issues',\n",
    "    'is_heavy_support_user', 'is_inactive'\n",
    "]\n",
    "\n",
    "# Prepare features and target\n",
    "X = customer_df[CHURN_FEATURES].copy()\n",
    "y = customer_df['churned']\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset Overview:\")\n",
    "print(f\"   Total customers: {len(X)}\")\n",
    "print(f\"   Features: {len(CHURN_FEATURES)}\")\n",
    "print(f\"   Churn rate: {y.mean():.1%}\")\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN/TEST SPLIT\n",
    "# ============================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=MODEL_SEED, \n",
    "    stratify=y  # Maintain churn ratio in both sets\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Š Train/Test Split:\")\n",
    "print(f\"   Training set: {len(X_train)} samples ({y_train.mean():.1%} churn rate)\")\n",
    "print(f\"   Test set: {len(X_test)} samples ({y_test.mean():.1%} churn rate)\")\n",
    "\n",
    "# Store indices for later use\n",
    "train_indices = X_train.index\n",
    "test_indices = X_test.index\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE SCALING\n",
    "# ============================================================\n",
    "# StandardScaler is essential for:\n",
    "# 1. Logistic Regression convergence\n",
    "# 2. Comparing coefficient magnitudes for feature importance\n",
    "\n",
    "churn_scaler = StandardScaler()\n",
    "X_train_scaled = churn_scaler.fit_transform(X_train)\n",
    "X_test_scaled = churn_scaler.transform(X_test)  # Use same transformation!\n",
    "\n",
    "print(f\"\\nâœ… Features scaled using StandardScaler\")\n",
    "\n",
    "# ============================================================\n",
    "# MODEL TRAINING\n",
    "# ============================================================\n",
    "print(f\"\\nğŸ”§ Training Logistic Regression model...\")\n",
    "\n",
    "churn_model = LogisticRegression(\n",
    "    random_state=MODEL_SEED,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "churn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"âœ… Model trained successfully\")\n",
    "\n",
    "print(f\"\\nâœ… Model training complete. Run Section 4 for detailed evaluation.\")\n",
    "\n",
    "# ============================================================\n",
    "# ADD CHURN_PROBABILITY TO ALL CUSTOMERS\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š GENERATING CHURN PROBABILITIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Scale ALL customer features using the fitted scaler\n",
    "X_all_scaled = churn_scaler.transform(X)\n",
    "\n",
    "# Predict probability for ALL customers\n",
    "customer_df['churn_probability'] = churn_model.predict_proba(X_all_scaled)[:, 1]\n",
    "\n",
    "# Validate probabilities\n",
    "validate_customer_df(customer_df, stage=\"with_churn_probability\")\n",
    "\n",
    "print(f\"\\nâœ… Added 'churn_probability' column to customer_df\")\n",
    "print(f\"\\nğŸ“Š Churn Probability Distribution:\")\n",
    "print(f\"   Min:    {customer_df['churn_probability'].min():.4f}\")\n",
    "print(f\"   25th:   {customer_df['churn_probability'].quantile(0.25):.4f}\")\n",
    "print(f\"   Median: {customer_df['churn_probability'].median():.4f}\")\n",
    "print(f\"   75th:   {customer_df['churn_probability'].quantile(0.75):.4f}\")\n",
    "print(f\"   Max:    {customer_df['churn_probability'].max():.4f}\")\n",
    "\n",
    "# Risk tier distribution (cutoffs may be fixed or data-derived)\n",
    "apply_threshold_mode(customer_df)\n",
    "\n",
    "customer_df['risk_tier'] = customer_df['churn_probability'].apply(classify_risk)\n",
    "\n",
    "print(f\"\\nğŸ“Š Risk Tier Distribution:\")\n",
    "for tier in ['Low', 'Medium', 'High', 'Critical']:\n",
    "    count = (customer_df['risk_tier'] == tier).sum()\n",
    "    pct = count / len(customer_df) * 100\n",
    "    print(f\"   {tier}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# STORE MODEL ARTIFACTS FOR LATER USE\n",
    "# ============================================================\n",
    "CHURN_MODEL = churn_model\n",
    "CHURN_SCALER = churn_scaler\n",
    "CHURN_FEATURES_LIST = CHURN_FEATURES\n",
    "\n",
    "print(f\"\\nâœ… Model artifacts stored: CHURN_MODEL, CHURN_SCALER, CHURN_FEATURES_LIST\")\n",
    "print(f\"\\nğŸ‰ Churn prediction model training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“ˆ SURVIVAL ANALYSIS: Predicting Days Until Churn\n",
      "============================================================\n",
      "\n",
      "âš™ï¸ Configuration:\n",
      "   Observation window: 120 days\n",
      "   Prediction horizon: 180 days\n",
      "\n",
      "âœ… lifelines library available\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š PREPARING SURVIVAL TRAINING DATA\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Survival Training Data:\n",
      "   Total customers: 6000\n",
      "   Events (churned): 1261 (21.0%)\n",
      "   Censored (retained): 4739\n",
      "   Duration range: 7-120 days\n",
      "\n",
      "ğŸ“Š Event Time Distribution (churned only):\n",
      "   Min:    7 days\n",
      "   25th:   17 days\n",
      "   Median: 43 days\n",
      "   75th:   88 days\n",
      "   Max:    119 days\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š KAPLAN-MEIER SURVIVAL ANALYSIS\n",
      "============================================================\n",
      "\n",
      "ğŸ¯ Overall Survival Statistics:\n",
      "   Median survival: > 120 days (most customers retained)\n",
      "\n",
      "ğŸ“Š Retention Probabilities:\n",
      "   30-day: 92.0% retained, 8.0% churned\n",
      "   60-day: 87.2% retained, 12.8% churned\n",
      "   90-day: 84.1% retained, 15.9% churned\n",
      "   120-day: 79.0% retained, 21.0% churned\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š TRAINING COX PROPORTIONAL HAZARDS MODEL\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ Cox Model Configuration:\n",
      "   Features: 9\n",
      "   Training samples: 6000\n",
      "   Events: 1261\n",
      "\n",
      "âœ… Cox model trained\n",
      "   Concordance Index: 0.6645\n",
      "\n",
      "ğŸ“Š Top Hazard Ratios:\n",
      "   support_tickets_90d       HR=1.192 ***\n",
      "   payment_delays_12m        HR=1.111 *\n",
      "   is_inactive               HR=1.059 *\n",
      "   login_frequency_monthly   HR=1.021 \n",
      "   monthly_charges           HR=1.018 \n",
      "\n",
      "============================================================\n",
      "ğŸ¯ PREDICTING DAYS UNTIL CHURN\n",
      "============================================================\n",
      "\n",
      "âœ… Added 'predicted_days_until_churn' to customer_df\n",
      "\n",
      "ğŸ“Š Prediction Distribution:\n",
      "   Min:    34 days\n",
      "   25th:   95 days\n",
      "   Median: 99 days\n",
      "   75th:   103 days\n",
      "   Max:    119 days\n",
      "\n",
      "ğŸ“Š By Risk Tier (median days):\n",
      "   Critical  : 91 days (n=107)\n",
      "   High      : 95 days (n=2718)\n",
      "   Medium    : 102 days (n=2683)\n",
      "   Low       : 109 days (n=492)\n",
      "\n",
      "ğŸ“Š Correlation Check:\n",
      "   churn_probability vs predicted_days: -0.731\n",
      "   (Should be NEGATIVE: higher prob = fewer days)\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ OPTIMAL INTERVENTION WINDOW (from Survival Analysis)\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š High-Risk Customer Predictions:\n",
      "   Count: 2825\n",
      "   25th percentile: 91 days\n",
      "   Median: 95 days\n",
      "   75th percentile: 97 days\n",
      "\n",
      "ğŸ¯ DERIVED INTERVENTION WINDOW:\n",
      "   Too Early:  Day 0 to 45\n",
      "   Optimal:    Day 45 to 95\n",
      "   Peak Day:   ~Day 93\n",
      "   Too Late:   After Day 95\n",
      "\n",
      "âœ… Stored SURVIVAL_INTERVENTION_STATS\n",
      "\n",
      "============================================================\n",
      "ğŸ’¾ SAVING DATASET\n",
      "============================================================\n",
      "âœ… Data validation passed: with_survival_predictions (rows=6,000, churn_rate=21.0%)\n",
      "\n",
      "âœ… Saved: /Users/ibrahimabarry/Documents/Proactive-churn-prevention/customer_churn_data.csv\n",
      "   Rows: 6000\n",
      "\n",
      "ğŸ“‹ MODEL-PREDICTED columns:\n",
      "   â€¢ churn_probability        â† Logistic Regression\n",
      "   â€¢ predicted_days_until_churn â† Cox PH Survival Model\n",
      "\n",
      "ğŸ‰ Survival analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SURVIVAL ANALYSIS: Predicting Days Until Churn\n",
    "# ============================================================\n",
    "# \n",
    "# Survival analysis predicts WHEN customers will churn.\n",
    "# \n",
    "# Key Design Decision: Use a FIXED OBSERVATION WINDOW (120 days)\n",
    "# This represents a realistic business planning horizon where we:\n",
    "# - Monitor customers for signs of churn\n",
    "# - Have time to intervene before they leave\n",
    "# - Can measure intervention effectiveness\n",
    "#\n",
    "# The model learns: given customer features, how quickly do they churn?\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“ˆ SURVIVAL ANALYSIS: Predicting Days Until Churn\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "OBSERVATION_WINDOW = int(CONFIG['survival']['observation_window_days'])  # days\n",
    "MIN_DURATION = int(CONFIG['survival']['min_duration_days'])  # days\n",
    "MAX_PREDICTION = int(CONFIG['survival']['max_prediction_days'])  # days\n",
    "\n",
    "print(f\"\\nâš™ï¸ Configuration:\")\n",
    "print(f\"   Observation window: {OBSERVATION_WINDOW} days\")\n",
    "print(f\"   Prediction horizon: {MAX_PREDICTION} days\")\n",
    "\n",
    "# ============================================================\n",
    "# INSTALL/IMPORT LIFELINES (optional)\n",
    "# ============================================================\n",
    "try:\n",
    "    from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "    LIFELINES_AVAILABLE = True\n",
    "    print(f\"\\nâœ… lifelines library available\")\n",
    "except Exception as e:\n",
    "    KaplanMeierFitter = None\n",
    "    CoxPHFitter = None\n",
    "    LIFELINES_AVAILABLE = False\n",
    "    print(f\"\\nâš ï¸ lifelines not available: {e}\")\n",
    "    print(\"   Using fallback timing estimates (still reproducible).\")\n",
    "\n",
    "# PREPARE SURVIVAL TRAINING DATA\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š PREPARING SURVIVAL TRAINING DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "np.random.seed(MODEL_SEED)\n",
    "\n",
    "survival_df = customer_df.copy()\n",
    "\n",
    "# Calculate risk score from features (determines event timing)\n",
    "# Higher risk = churn earlier in observation window\n",
    "risk_score = (\n",
    "    CONFIG['survival']['risk_score_weights']['has_payment_issues'] * survival_df['has_payment_issues'] +\n",
    "    CONFIG['survival']['risk_score_weights']['is_inactive'] * survival_df['is_inactive'] +\n",
    "    CONFIG['survival']['risk_score_weights']['support_tickets_90d_scaled'] * (\n",
    "        survival_df['support_tickets_90d'] / max(survival_df['support_tickets_90d'].max(), 1)\n",
    "    ) +\n",
    "    CONFIG['survival']['risk_score_weights']['low_engagement'] * (1 - survival_df['engagement_score'] / 100) +\n",
    "    CONFIG['survival']['risk_score_weights']['low_nps'] * (1 - survival_df['nps_score'] / 10)\n",
    ").clip(*CONFIG['survival']['risk_score_clip'])  # Avoid extreme values\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE REALISTIC EVENT TIMES\n",
    "# ============================================================\n",
    "# For churned customers: They churned at some point in the observation window\n",
    "# Higher risk customers churn EARLIER (lower duration)\n",
    "#\n",
    "# For retained customers: They're still active at end of observation window\n",
    "# (right-censored at OBSERVATION_WINDOW)\n",
    "\n",
    "# Base duration for churned customers (exponential distribution)\n",
    "# Mean time to churn inversely related to risk\n",
    "mean_time_to_churn = OBSERVATION_WINDOW * (1 - risk_score * CONFIG['survival']['mean_time_scale'])  # 27-85 days based on risk\n",
    "\n",
    "# Generate event times\n",
    "churned_duration = np.where(\n",
    "    survival_df['churned'] == 1,\n",
    "    # Churned: exponential distribution with risk-adjusted mean\n",
    "    np.random.exponential(mean_time_to_churn),\n",
    "    # Retained: censored at observation window\n",
    "    OBSERVATION_WINDOW\n",
    ")\n",
    "\n",
    "# Clip durations to valid range\n",
    "# Churned customers must have duration < OBSERVATION_WINDOW (they left before end)\n",
    "churned_duration = np.where(\n",
    "    survival_df['churned'] == 1,\n",
    "    np.clip(churned_duration, MIN_DURATION, OBSERVATION_WINDOW - 1),\n",
    "    OBSERVATION_WINDOW\n",
    ").astype(int)\n",
    "\n",
    "survival_df['duration'] = churned_duration\n",
    "survival_df['event'] = survival_df['churned']\n",
    "\n",
    "# Persist observed survival labels for tooling & dashboards\n",
    "customer_df['duration_days'] = survival_df['duration'].astype(int).values\n",
    "customer_df['event_observed'] = survival_df['event'].astype(int).values\n",
    "\n",
    "# Validate data\n",
    "survival_df = survival_df[survival_df['duration'] >= MIN_DURATION].copy()\n",
    "\n",
    "n_events = survival_df['event'].sum()\n",
    "n_censored = (survival_df['event'] == 0).sum()\n",
    "event_rate = n_events / len(survival_df)\n",
    "\n",
    "print(f\"\\nğŸ“Š Survival Training Data:\")\n",
    "print(f\"   Total customers: {len(survival_df)}\")\n",
    "print(f\"   Events (churned): {n_events} ({event_rate:.1%})\")\n",
    "print(f\"   Censored (retained): {n_censored}\")\n",
    "print(f\"   Duration range: {survival_df['duration'].min()}-{survival_df['duration'].max()} days\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Event Time Distribution (churned only):\")\n",
    "churned_only = survival_df[survival_df['event'] == 1]['duration']\n",
    "print(f\"   Min:    {churned_only.min()} days\")\n",
    "print(f\"   25th:   {churned_only.quantile(0.25):.0f} days\")\n",
    "print(f\"   Median: {churned_only.median():.0f} days\")\n",
    "print(f\"   75th:   {churned_only.quantile(0.75):.0f} days\")\n",
    "print(f\"   Max:    {churned_only.max()} days\")\n",
    "\n",
    "if LIFELINES_AVAILABLE:\n",
    "    # ============================================================\n",
    "    # KAPLAN-MEIER SURVIVAL CURVE\n",
    "    # ============================================================\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“Š KAPLAN-MEIER SURVIVAL ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(survival_df['duration'], event_observed=survival_df['event'])\n",
    "    \n",
    "    median_survival = kmf.median_survival_time_\n",
    "    print(f\"\\nğŸ¯ Overall Survival Statistics:\")\n",
    "    if np.isinf(median_survival):\n",
    "        print(f\"   Median survival: > {OBSERVATION_WINDOW} days (most customers retained)\")\n",
    "    else:\n",
    "        print(f\"   Median survival: {median_survival:.0f} days\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Retention Probabilities:\")\n",
    "    for days in [30, 60, 90, 120]:\n",
    "        if days <= OBSERVATION_WINDOW:\n",
    "            try:\n",
    "                surv_prob = kmf.survival_function_at_times(days).values[0]\n",
    "                churn_prob = 1 - surv_prob\n",
    "                print(f\"   {days:2d}-day: {surv_prob:.1%} retained, {churn_prob:.1%} churned\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # ============================================================\n",
    "    # COX PROPORTIONAL HAZARDS MODEL\n",
    "    # ============================================================\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“Š TRAINING COX PROPORTIONAL HAZARDS MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    COX_FEATURES = [\n",
    "        'tenure_months', 'login_frequency_monthly', 'support_tickets_90d',\n",
    "        'payment_delays_12m', 'nps_score', 'engagement_score',\n",
    "        'has_payment_issues', 'is_inactive', 'monthly_charges'\n",
    "    ]\n",
    "    \n",
    "    cox_df = survival_df[COX_FEATURES + ['duration', 'event']].dropna().copy()\n",
    "    \n",
    "    # Standardize features\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    cox_scaler = StandardScaler()\n",
    "    cox_df[COX_FEATURES] = cox_scaler.fit_transform(cox_df[COX_FEATURES])\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Cox Model Configuration:\")\n",
    "    print(f\"   Features: {len(COX_FEATURES)}\")\n",
    "    print(f\"   Training samples: {len(cox_df)}\")\n",
    "    print(f\"   Events: {cox_df['event'].sum()}\")\n",
    "    \n",
    "    # Fit Cox model\n",
    "    cph = CoxPHFitter(penalizer=0.01)  # Light regularization\n",
    "    cph.fit(cox_df, duration_col='duration', event_col='event')\n",
    "    \n",
    "    print(f\"\\nâœ… Cox model trained\")\n",
    "    print(f\"   Concordance Index: {cph.concordance_index_:.4f}\")\n",
    "    \n",
    "    # Hazard ratios\n",
    "    print(f\"\\nğŸ“Š Top Hazard Ratios:\")\n",
    "    summary = cph.summary[['exp(coef)', 'p']].sort_values('exp(coef)', ascending=False)\n",
    "    for feat in list(summary.index)[:5]:\n",
    "        hr = summary.loc[feat, 'exp(coef)']\n",
    "        p = summary.loc[feat, 'p']\n",
    "        sig = \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"\"\n",
    "        print(f\"   {feat:<25} HR={hr:.3f} {sig}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # PREDICT DAYS UNTIL CHURN\n",
    "    # ============================================================\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ¯ PREDICTING DAYS UNTIL CHURN\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Scale features for all customers\n",
    "    predict_df = customer_df[COX_FEATURES].copy()\n",
    "    predict_scaled = pd.DataFrame(\n",
    "        cox_scaler.transform(predict_df),\n",
    "        columns=COX_FEATURES,\n",
    "        index=customer_df.index\n",
    "    )\n",
    "    \n",
    "    # ============================================================\n",
    "    # METHOD: Use survival function to find expected time to churn\n",
    "    # ============================================================\n",
    "    \n",
    "    # Get survival functions for all customers\n",
    "    surv_funcs = cph.predict_survival_function(predict_scaled)\n",
    "    \n",
    "    # Find time when survival probability crosses threshold  \n",
    "    predicted_days = []\n",
    "    \n",
    "    for idx in customer_df.index:\n",
    "        surv_curve = surv_funcs[idx]\n",
    "        churn_prob = customer_df.loc[idx, 'churn_probability']\n",
    "        \n",
    "        # Personalized threshold: higher churn risk = higher survival threshold\n",
    "        # This means high-risk customers get shorter predicted times\n",
    "        threshold = 0.5 + (churn_prob - 0.5) * 0.4  # Range: 0.3 to 0.7\n",
    "        threshold = np.clip(threshold, 0.3, 0.7)\n",
    "        \n",
    "        # Find first time where survival <= threshold\n",
    "        below_threshold = surv_curve[surv_curve <= threshold]\n",
    "        \n",
    "        if len(below_threshold) > 0:\n",
    "            days = below_threshold.index[0]\n",
    "        else:\n",
    "            # Survival never drops below threshold in our window\n",
    "            times = surv_curve.index.values\n",
    "            probs = surv_curve.values\n",
    "            \n",
    "            # Expected time = integral of survival function (approximation)\n",
    "            if len(times) > 1:\n",
    "                dt = np.diff(times)\n",
    "                avg_surv = (probs[:-1] + probs[1:]) / 2\n",
    "                expected = np.sum(dt * avg_surv)\n",
    "                days = min(expected, MAX_PREDICTION)\n",
    "            else:\n",
    "                days = MAX_PREDICTION * (1 - churn_prob)\n",
    "        \n",
    "        predicted_days.append(int(np.clip(days, MIN_DURATION, MAX_PREDICTION)))\n",
    "    \n",
    "    customer_df['predicted_days_until_churn'] = predicted_days\n",
    "    \n",
    "    print(f\"\\nâœ… Added 'predicted_days_until_churn' to customer_df\")\n",
    "    \n",
    "    # Distribution summary\n",
    "    print(f\"\\nğŸ“Š Prediction Distribution:\")\n",
    "    print(f\"   Min:    {customer_df['predicted_days_until_churn'].min()} days\")\n",
    "    print(f\"   25th:   {customer_df['predicted_days_until_churn'].quantile(0.25):.0f} days\")\n",
    "    print(f\"   Median: {customer_df['predicted_days_until_churn'].median():.0f} days\")\n",
    "    print(f\"   75th:   {customer_df['predicted_days_until_churn'].quantile(0.75):.0f} days\")\n",
    "    print(f\"   Max:    {customer_df['predicted_days_until_churn'].max()} days\")\n",
    "    \n",
    "    # By risk tier\n",
    "    print(f\"\\nğŸ“Š By Risk Tier (median days):\")\n",
    "    for tier in ['Critical', 'High', 'Medium', 'Low']:\n",
    "        tier_data = customer_df[customer_df['risk_tier'] == tier]['predicted_days_until_churn']\n",
    "        if len(tier_data) > 0:\n",
    "            print(f\"   {tier:<10}: {tier_data.median():.0f} days (n={len(tier_data)})\")\n",
    "    \n",
    "    # Correlation check\n",
    "    corr = customer_df['churn_probability'].corr(customer_df['predicted_days_until_churn'])\n",
    "    print(f\"\\nğŸ“Š Correlation Check:\")\n",
    "    print(f\"   churn_probability vs predicted_days: {corr:.3f}\")\n",
    "    print(f\"   (Should be NEGATIVE: higher prob = fewer days)\")\n",
    "    \n",
    "    # Store artifacts\n",
    "    SURVIVAL_MODEL = cph\n",
    "    COX_SCALER = cox_scaler\n",
    "    KM_FITTER = kmf\n",
    "    COX_FEATURES_LIST = COX_FEATURES\n",
    "\n",
    "else:\n",
    "    # Fallback without lifelines\n",
    "    print(f\"\\nâš ï¸ Using heuristic (lifelines not available)\")\n",
    "    \n",
    "    # Heuristic: days inversely proportional to churn probability\n",
    "    customer_df['predicted_days_until_churn'] = (\n",
    "        MAX_PREDICTION * (1 - customer_df['churn_probability'])\n",
    "    ).clip(MIN_DURATION, MAX_PREDICTION).astype(int)\n",
    "    \n",
    "    SURVIVAL_MODEL = None\n",
    "    COX_SCALER = None\n",
    "    KM_FITTER = None\n",
    "    COX_FEATURES_LIST = []\n",
    "\n",
    "# ============================================================\n",
    "# OPTIMAL INTERVENTION WINDOW (from Survival Analysis)\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ¯ OPTIMAL INTERVENTION WINDOW (from Survival Analysis)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "high_risk = customer_df[customer_df['risk_tier'].isin(['High', 'Critical'])]\n",
    "all_at_risk = customer_df[customer_df['churn_probability'] >= 0.5]\n",
    "\n",
    "if len(high_risk) > 0:\n",
    "    median_days = high_risk['predicted_days_until_churn'].median()\n",
    "    q25_days = high_risk['predicted_days_until_churn'].quantile(0.25)\n",
    "    q75_days = high_risk['predicted_days_until_churn'].quantile(0.75)\n",
    "    \n",
    "    INTERVENTION_WINDOW_START = max(MIN_DURATION, int(q25_days * CONFIG['survival']['window_start_multiplier_q25']))\n",
    "    INTERVENTION_WINDOW_OPTIMAL = int((q25_days + median_days) / 2)\n",
    "    INTERVENTION_WINDOW_END = int(median_days)\n",
    "    INTERVENTION_WINDOW_TOO_LATE = int(q75_days)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š High-Risk Customer Predictions:\")\n",
    "    print(f\"   Count: {len(high_risk)}\")\n",
    "    print(f\"   25th percentile: {q25_days:.0f} days\")\n",
    "    print(f\"   Median: {median_days:.0f} days\")\n",
    "    print(f\"   75th percentile: {q75_days:.0f} days\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ DERIVED INTERVENTION WINDOW:\")\n",
    "    print(f\"   Too Early:  Day 0 to {INTERVENTION_WINDOW_START}\")\n",
    "    print(f\"   Optimal:    Day {INTERVENTION_WINDOW_START} to {INTERVENTION_WINDOW_END}\")\n",
    "    print(f\"   Peak Day:   ~Day {INTERVENTION_WINDOW_OPTIMAL}\")\n",
    "    print(f\"   Too Late:   After Day {INTERVENTION_WINDOW_END}\")\n",
    "    \n",
    "    SURVIVAL_INTERVENTION_STATS = {\n",
    "        'median_days': float(median_days),\n",
    "        'q25_days': float(q25_days),\n",
    "        'q75_days': float(q75_days),\n",
    "        'window_start': INTERVENTION_WINDOW_START,\n",
    "        'window_optimal': INTERVENTION_WINDOW_OPTIMAL,\n",
    "        'window_end': INTERVENTION_WINDOW_END,\n",
    "        'window_too_late': INTERVENTION_WINDOW_TOO_LATE,\n",
    "        'high_risk_count': len(high_risk),\n",
    "        'source': 'Cox Proportional Hazards Survival Model'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nâœ… Stored SURVIVAL_INTERVENTION_STATS\")\n",
    "\n",
    "else:\n",
    "    print(\"   âš ï¸ No high-risk customers - using defaults for 120-day window\")\n",
    "    SURVIVAL_INTERVENTION_STATS = {\n",
    "        'median_days': 60.0, 'q25_days': 35.0, 'q75_days': 90.0,\n",
    "        'window_start': 20, 'window_optimal': 45, 'window_end': 60,\n",
    "        'window_too_late': 90, 'high_risk_count': 0,\n",
    "        'source': 'Default (120-day window)'\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# SAVE DATASET\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’¾ SAVING DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "DATA_PATH = CONFIG['paths']['customer_csv']\n",
    "\n",
    "# Validate predicted_days_until_churn (if present)\n",
    "validate_customer_df(customer_df, stage=\"with_survival_predictions\")\n",
    "\n",
    "customer_df.to_csv(DATA_PATH, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Saved: {DATA_PATH}\")\n",
    "print(f\"   Rows: {len(customer_df)}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ MODEL-PREDICTED columns:\")\n",
    "print(f\"   â€¢ churn_probability        â† Logistic Regression\")\n",
    "print(f\"   â€¢ predicted_days_until_churn â† Cox PH Survival Model\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Survival analysis complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“Š FEATURE IMPORTANCE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "âœ… Using trained model: LogisticRegression\n",
      "   Features: 15\n",
      "\n",
      "ğŸ“Š Feature Coefficients (from trained Logistic Regression):\n",
      "------------------------------------------------------------\n",
      "Feature                        Coefficient  Direction      \n",
      "------------------------------------------------------------\n",
      "tenure_months                     -0.5070   â†“ decreases churn\n",
      "last_activity_days                +0.1843   â†‘ increases churn\n",
      "feature_usage_pct                 -0.1755   â†“ decreases churn\n",
      "payment_delays_12m                +0.1665   â†‘ increases churn\n",
      "engagement_score                  -0.1571   â†“ decreases churn\n",
      "support_tickets_90d               +0.1409   â†‘ increases churn\n",
      "nps_score                         -0.1083   â†“ decreases churn\n",
      "has_payment_issues                -0.1053   â†“ decreases churn\n",
      "is_heavy_support_user             +0.0817   â†‘ increases churn\n",
      "is_inactive                       -0.0627   â†“ decreases churn\n",
      "email_open_rate                   +0.0559   â†‘ increases churn\n",
      "login_frequency_monthly           -0.0517   â†“ decreases churn\n",
      "discount_count                    +0.0255   â†‘ increases churn\n",
      "monthly_charges                   -0.0056   â†“ decreases churn\n",
      "is_high_value                     +0.0009   â†‘ increases churn\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š VISUALIZING FEATURE IMPORTANCES\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#10B981",
           "#EF4444",
           "#10B981",
           "#EF4444",
           "#10B981",
           "#EF4444",
           "#10B981",
           "#10B981",
           "#EF4444",
           "#10B981",
           "#EF4444",
           "#10B981",
           "#EF4444",
           "#10B981",
           "#EF4444"
          ]
         },
         "orientation": "h",
         "text": [
          "-0.507",
          "+0.184",
          "-0.175",
          "+0.167",
          "-0.157",
          "+0.141",
          "-0.108",
          "-0.105",
          "+0.082",
          "-0.063",
          "+0.056",
          "-0.052",
          "+0.026",
          "-0.006",
          "+0.001"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          -0.507012478089884,
          0.18431658458164163,
          -0.17549125812747948,
          0.1665301726260728,
          -0.15709822744149493,
          0.1409005823253887,
          -0.10825538567005218,
          -0.10533084849615289,
          0.08171954357395442,
          -0.06267000774437698,
          0.05592927034640944,
          -0.051676962658437166,
          0.025548410573293514,
          -0.005584439866427089,
          0.0008968700525788284
         ],
         "y": [
          "Tenure",
          "Last Activity Days",
          "Feature Usage",
          "Payment Delays",
          "Engagement",
          "Support Tickets",
          "NPS Score",
          "Payment Issues",
          "Heavy Support",
          "Inactive",
          "Email Open Rate",
          "Login Frequency",
          "Discounts Used",
          "Monthly Charges",
          "High Value"
         ]
        }
       ],
       "layout": {
        "height": 550,
        "margin": {
         "b": 60,
         "l": 130,
         "r": 80,
         "t": 125
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>Feature Importance: Logistic Regression Coefficients</b><br><sup>From trained churn prediction model</sup><br><br><span style=\"font-size:12px\">ğŸ”´ Increases Churn Risk     ğŸŸ¢ Decreases Churn Risk</span>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.92,
         "yanchor": "top"
        },
        "width": 850,
        "xaxis": {
         "range": [
          -1.0070124780898841,
          0.6843165845816417
         ],
         "title": {
          "text": "Coefficient (+ increases churn risk, - decreases)"
         },
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          -0.5,
          14.5
         ],
         "type": "category"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved: ./viz/all_feature_importance.png\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ ACTIONABILITY ASSESSMENT\n",
      "============================================================\n",
      "\n",
      "Actionability Scores (Business Impact Potential):\n",
      "--------------------------------------------------\n",
      "\n",
      "High Actionability:\n",
      "   â€¢ has_payment_issues\n",
      "   â€¢ engagement_score\n",
      "   â€¢ feature_usage_pct\n",
      "   â€¢ email_open_rate\n",
      "   â€¢ login_frequency_monthly\n",
      "\n",
      "Medium Actionability:\n",
      "   â€¢ support_tickets_90d\n",
      "   â€¢ last_activity_days\n",
      "   â€¢ is_inactive\n",
      "   â€¢ discount_count\n",
      "   â€¢ payment_delays_12m\n",
      "\n",
      "Low Actionability:\n",
      "   â€¢ nps_score\n",
      "   â€¢ tenure_months\n",
      "   â€¢ monthly_charges\n",
      "   â€¢ is_high_value\n",
      "   â€¢ is_heavy_support_user\n",
      "\n",
      "============================================================\n",
      "âš–ï¸ COMBINED SCORING: Importance Ã— Actionability\n",
      "============================================================\n",
      "\n",
      "Feature                      |Coef|     Action   Combined  \n",
      "------------------------------------------------------------\n",
      "feature_usage_pct            0.1755     High     0.5265    \n",
      "tenure_months                0.5070     Low      0.5070    \n",
      "engagement_score             0.1571     High     0.4713    \n",
      "last_activity_days           0.1843     Medium   0.3686    \n",
      "payment_delays_12m           0.1665     Medium   0.3331    \n",
      "has_payment_issues           0.1053     High     0.3160    \n",
      "support_tickets_90d          0.1409     Medium   0.2818    \n",
      "email_open_rate              0.0559     High     0.1678    \n",
      "login_frequency_monthly      0.0517     High     0.1550    \n",
      "is_inactive                  0.0627     Medium   0.1253    \n",
      "nps_score                    0.1083     Low      0.1083    \n",
      "is_heavy_support_user        0.0817     Low      0.0817    \n",
      "discount_count               0.0255     Medium   0.0511    \n",
      "monthly_charges              0.0056     Low      0.0056    \n",
      "is_high_value                0.0009     Low      0.0009    \n",
      "\n",
      "============================================================\n",
      "âœ… FINAL FEATURE SELECTION\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Top 10 Features (for Predictive Agent):\n",
      "--------------------------------------------------\n",
      "    1. feature_usage_pct            -0.1755  [High]\n",
      "    2. tenure_months                -0.5070  [Low]\n",
      "    3. engagement_score             -0.1571  [High]\n",
      "    4. last_activity_days           +0.1843  [Medium]\n",
      "    5. payment_delays_12m           +0.1665  [Medium]\n",
      "    6. has_payment_issues           -0.1053  [High]\n",
      "    7. support_tickets_90d          +0.1409  [Medium]\n",
      "    8. email_open_rate              +0.0559  [High]\n",
      "    9. login_frequency_monthly      -0.0517  [High]\n",
      "   10. is_inactive                  -0.0627  [Medium]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#EF4444",
           "#F59E0B",
           "#10B981",
           "#F59E0B",
           "#10B981",
           "#F59E0B",
           "#10B981",
           "#F59E0B",
           "#10B981",
           "#10B981"
          ]
         },
         "orientation": "h",
         "text": [
          "-0.507",
          "+0.184",
          "-0.175",
          "+0.167",
          "-0.157",
          "+0.141",
          "-0.105",
          "-0.063",
          "+0.056",
          "-0.052"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          -0.507,
          0.1843,
          -0.1755,
          0.1665,
          -0.1571,
          0.1409,
          -0.1053,
          -0.0627,
          0.0559,
          -0.0517
         ],
         "y": [
          "Tenure",
          "Last Activity Days",
          "Feature Usage",
          "Payment Delays",
          "Engagement",
          "Support Tickets",
          "Payment Issues",
          "Inactive",
          "Email Open Rate",
          "Login Frequency"
         ]
        }
       ],
       "layout": {
        "height": 500,
        "margin": {
         "b": 60,
         "l": 120,
         "r": 80,
         "t": 125
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>Selected Features for Intervention</b><br><sup>Top 10 by Importance Ã— Actionability</sup><br><br><span style=\"font-size:12px\">ğŸŸ¢ High Actionability     ğŸŸ¡ Medium Actionability    ğŸ”´ Low Actionability</span>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.92,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "range": [
          -1.0070000000000001,
          0.6843
         ],
         "title": {
          "text": "Coefficient (+ increases churn, - decreases)"
         },
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          -0.5,
          9.5
         ],
         "type": "category"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved: ./viz/feature_weights.png\n",
      "\n",
      "âœ… FEATURE SELECTION COMPLETE\n",
      "   10 features selected for Predictive Agent\n",
      "   Model coefficients from: CHURN_MODEL (trained Logistic Regression)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FEATURE IMPORTANCE & SELECTION\n",
    "# ============================================================\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: Extract Feature Importance from TRAINED Model\n",
    "# ============================================================\n",
    "\n",
    "if 'CHURN_MODEL' not in globals():\n",
    "    raise NameError(\"âŒ CHURN_MODEL not found. Please run Cell 7 (Model Training) first.\")\n",
    "\n",
    "print(f\"\\nâœ… Using trained model: {type(CHURN_MODEL).__name__}\")\n",
    "print(f\"   Features: {len(CHURN_FEATURES_LIST)}\")\n",
    "\n",
    "# Extract standardized coefficients \n",
    "coefficients = dict(zip(CHURN_FEATURES_LIST, CHURN_MODEL.coef_[0]))\n",
    "\n",
    "# Sort by absolute value (importance)\n",
    "coefficients_sorted = dict(sorted(coefficients.items(), \n",
    "                                  key=lambda x: abs(x[1]), reverse=True))\n",
    "\n",
    "print(f\"\\nğŸ“Š Feature Coefficients (from trained Logistic Regression):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Feature':<30} {'Coefficient':<12} {'Direction':<15}\")\n",
    "print(\"-\" * 60)\n",
    "for feat, coef in coefficients_sorted.items():\n",
    "    direction = \"â†‘ increases churn\" if coef > 0 else \"â†“ decreases churn\"\n",
    "    print(f\"{feat:<30} {coef:>+10.4f}   {direction}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Visualize ALL Feature Importances\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š VISUALIZING FEATURE IMPORTANCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create viz directory\n",
    "VIZ_DIR = CONFIG['paths']['viz_dir']\n",
    "os.makedirs(VIZ_DIR, exist_ok=True)\n",
    "\n",
    "# Display names for visualization\n",
    "ALL_FEATURE_DISPLAY_NAMES = {\n",
    "    'tenure_months': 'Tenure', 'monthly_charges': 'Monthly Charges',\n",
    "    'login_frequency_monthly': 'Login Frequency', 'feature_usage_pct': 'Feature Usage',\n",
    "    'support_tickets_90d': 'Support Tickets', 'payment_delays_12m': 'Payment Delays',\n",
    "    'discount_count': 'Discounts Used', 'nps_score': 'NPS Score',\n",
    "    'email_open_rate': 'Email Open Rate', 'last_activity_days': 'Last Activity Days',\n",
    "    'engagement_score': 'Engagement', 'is_high_value': 'High Value',\n",
    "    'has_payment_issues': 'Payment Issues', 'is_heavy_support_user': 'Heavy Support',\n",
    "    'is_inactive': 'Inactive'\n",
    "}\n",
    "\n",
    "features_display = [ALL_FEATURE_DISPLAY_NAMES.get(f, f) for f in coefficients_sorted.keys()]\n",
    "coef_values = list(coefficients_sorted.values())\n",
    "colors_all = ['#EF4444' if c > 0 else '#10B981' for c in coef_values]\n",
    "\n",
    "fig_all = go.Figure(go.Bar(\n",
    "    x=coef_values, y=features_display, orientation='h',\n",
    "    marker_color=colors_all, \n",
    "    text=[f'{c:+.3f}' for c in coef_values],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig_all.update_layout(\n",
    "    title={\n",
    "        'text': '<b>Feature Importance: Logistic Regression Coefficients</b><br><sup>From trained churn prediction model</sup><br><br><span style=\"font-size:12px\">ğŸ”´ Increases Churn Risk     ğŸŸ¢ Decreases Churn Risk</span>',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'y': 0.92,\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    xaxis_title='Coefficient (+ increases churn risk, - decreases)',\n",
    "    template='plotly_white', \n",
    "    height=550,\n",
    "    width=850,\n",
    "    margin=dict(l=130, r=80, t=125, b=60),  # Increased TOP margin for legend in title\n",
    "    xaxis=dict(range=[min(coef_values) - 0.5, max(coef_values) + 0.5])\n",
    ")\n",
    "\n",
    "fig_all.show()\n",
    "\n",
    "# Save PNG\n",
    "try:\n",
    "    fig_all.write_image(f\"{VIZ_DIR}/all_feature_importance.png\", width=850, height=550, scale=2)\n",
    "    print(f\"ğŸ’¾ Saved: {VIZ_DIR}/all_feature_importance.png\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not save PNG: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Define Business Actionability\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ¯ ACTIONABILITY ASSESSMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Actionability scores based on business ability to influence\n",
    "FEATURE_ACTIONABILITY = {\n",
    "    # High (3) - Direct, immediate action possible\n",
    "    'has_payment_issues': 3,        # Send payment reminder\n",
    "    'engagement_score': 3,          # Re-engagement campaign\n",
    "    'feature_usage_pct': 3,         # Training/onboarding\n",
    "    'email_open_rate': 3,           # Improve email content\n",
    "    'login_frequency_monthly': 3,   # Feature announcements\n",
    "    \n",
    "    # Medium (2) - Partial influence\n",
    "    'support_tickets_90d': 2,       # Improve support quality\n",
    "    'last_activity_days': 2,        # Nudge emails\n",
    "    'is_inactive': 2,               # Re-activation campaign\n",
    "    'discount_count': 2,            # Strategic discounts\n",
    "    'payment_delays_12m': 2,        # Payment plans\n",
    "    \n",
    "    # Low (1) - Cannot directly change\n",
    "    'nps_score': 1,                 # Lagging indicator\n",
    "    'tenure_months': 1,             # Historical\n",
    "    'monthly_charges': 1,           # Pricing constraints\n",
    "    'is_high_value': 1,             # Derived metric\n",
    "    'is_heavy_support_user': 1      # Symptom, not cause\n",
    "}\n",
    "\n",
    "ACTIONABILITY_LABELS = {3: 'High', 2: 'Medium', 1: 'Low'}\n",
    "ACTIONABILITY_COLORS = {3: '#10B981', 2: '#F59E0B', 1: '#EF4444'}\n",
    "\n",
    "print(f\"\\nActionability Scores (Business Impact Potential):\")\n",
    "print(\"-\" * 50)\n",
    "for level in [3, 2, 1]:\n",
    "    print(f\"\\n{ACTIONABILITY_LABELS[level]} Actionability:\")\n",
    "    for feat, score in FEATURE_ACTIONABILITY.items():\n",
    "        if score == level and feat in CHURN_FEATURES_LIST:\n",
    "            print(f\"   â€¢ {feat}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: Combine Importance Ã— Actionability\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"âš–ï¸ COMBINED SCORING: Importance Ã— Actionability\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "feature_scores = {}\n",
    "for feat in CHURN_FEATURES_LIST:\n",
    "    coef = coefficients[feat]\n",
    "    importance = abs(coef)\n",
    "    actionability = FEATURE_ACTIONABILITY.get(feat, 1)\n",
    "    combined_score = importance * actionability\n",
    "    feature_scores[feat] = {\n",
    "        'coefficient': coef,\n",
    "        'importance': importance,\n",
    "        'actionability': actionability,\n",
    "        'actionability_label': ACTIONABILITY_LABELS[actionability],\n",
    "        'combined_score': combined_score\n",
    "    }\n",
    "\n",
    "# Sort by combined score\n",
    "feature_scores_sorted = dict(sorted(\n",
    "    feature_scores.items(),\n",
    "    key=lambda x: x[1]['combined_score'],\n",
    "    reverse=True\n",
    "))\n",
    "\n",
    "print(f\"\\n{'Feature':<28} {'|Coef|':<10} {'Action':<8} {'Combined':<10}\")\n",
    "print(\"-\" * 60)\n",
    "for feat, scores in feature_scores_sorted.items():\n",
    "    print(f\"{feat:<28} {scores['importance']:<10.4f} {scores['actionability_label']:<8} {scores['combined_score']:<10.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5: Select Top Features for Intervention Agent\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… FINAL FEATURE SELECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "TOP_N_FEATURES = 10\n",
    "SELECTED_FEATURES = list(feature_scores_sorted.keys())[:TOP_N_FEATURES]\n",
    "FEATURE_WEIGHTS = {feat: round(coefficients[feat], 4) for feat in SELECTED_FEATURES}\n",
    "\n",
    "print(f\"\\nğŸ“Š Top {TOP_N_FEATURES} Features (for Predictive Agent):\")\n",
    "print(\"-\" * 50)\n",
    "for i, (feat, weight) in enumerate(FEATURE_WEIGHTS.items(), 1):\n",
    "    direction = \"â†‘ churn\" if weight > 0 else \"â†“ churn\"\n",
    "    action = feature_scores[feat]['actionability_label']\n",
    "    print(f\"   {i:2}. {feat:<28} {weight:>+.4f}  [{action}]\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6: Visualize Selected Features (LEGEND AT TOP)\n",
    "# ============================================================\n",
    "features_final = [ALL_FEATURE_DISPLAY_NAMES.get(f, f) for f in SELECTED_FEATURES]\n",
    "weights_final = [FEATURE_WEIGHTS[f] for f in SELECTED_FEATURES]\n",
    "action_final = [feature_scores[f]['actionability_label'] for f in SELECTED_FEATURES]\n",
    "\n",
    "# Sort by absolute weight for display\n",
    "sorted_data = sorted(zip(features_final, weights_final, action_final), \n",
    "                     key=lambda x: abs(x[1]), reverse=True)\n",
    "features_sorted = [d[0] for d in sorted_data]\n",
    "weights_sorted = [d[1] for d in sorted_data]\n",
    "action_sorted = [d[2] for d in sorted_data]\n",
    "\n",
    "colors_final = []\n",
    "for a in action_sorted:\n",
    "    if a == 'High': colors_final.append('#10B981')\n",
    "    elif a == 'Medium': colors_final.append('#F59E0B')\n",
    "    else: colors_final.append('#EF4444')\n",
    "\n",
    "fig_selected = go.Figure(go.Bar(\n",
    "    x=weights_sorted, y=features_sorted, orientation='h',\n",
    "    marker_color=colors_final, \n",
    "    text=[f'{w:+.3f}' for w in weights_sorted],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig_selected.update_layout(\n",
    "    title={\n",
    "        'text': f'<b>Selected Features for Intervention</b><br><sup>Top {TOP_N_FEATURES} by Importance Ã— Actionability</sup><br><br><span style=\"font-size:12px\">ğŸŸ¢ High Actionability     ğŸŸ¡ Medium Actionability    ğŸ”´ Low Actionability</span>',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'y': 0.92,\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    xaxis_title='Coefficient (+ increases churn, - decreases)',\n",
    "    template='plotly_white', \n",
    "    height=500,\n",
    "    width=800,\n",
    "    margin=dict(l=120, r=80, t=125, b=60),  # Increased TOP margin for legend in title\n",
    "    xaxis=dict(range=[min(weights_sorted) - 0.5, max(weights_sorted) + 0.5])\n",
    ")\n",
    "\n",
    "fig_selected.show()\n",
    "\n",
    "# Save PNG\n",
    "try:\n",
    "    fig_selected.write_image(f\"{VIZ_DIR}/feature_weights.png\", width=800, height=500, scale=2)\n",
    "    print(f\"ğŸ’¾ Saved: {VIZ_DIR}/feature_weights.png\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not save PNG: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… FEATURE SELECTION COMPLETE\")\n",
    "print(f\"   {len(FEATURE_WEIGHTS)} features selected for Predictive Agent\")\n",
    "print(f\"   Model coefficients from: CHURN_MODEL (trained Logistic Regression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“ˆ CHURN PREDICTION MODEL EVALUATION\n",
      "============================================================\n",
      "âœ… Using predictions from trained LogisticRegression\n",
      "\n",
      "ğŸ“Š Test Set Overview:\n",
      "   Samples: 1200\n",
      "   Actual churn rate: 21.0%\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ PRIMARY METRIC: AUC-ROC = 0.6612\n",
      "============================================================\n",
      "   Interpretation: Model ranks churners above non-churners\n",
      "   66.1% of the time (vs 50% random)\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š THRESHOLD ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Threshold    Precision    Recall       F1          \n",
      "------------------------------------------------\n",
      "0.3          0.232        0.960        0.374        â† best F1\n",
      "0.4          0.249        0.849        0.386        â† best F1\n",
      "0.5          0.293        0.663        0.406        â† best F1\n",
      "0.6          0.345        0.353        0.349       \n",
      "0.7          0.371        0.103        0.161       \n",
      "\n",
      "ğŸ¯ Selected threshold: 0.5 (F1=0.406)\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š FINAL METRICS (threshold=0.5)\n",
      "============================================================\n",
      "\n",
      "ğŸ¯ Classification Metrics:\n",
      "   AUC-ROC:   0.6612\n",
      "   Precision: 0.2930\n",
      "   Recall:    0.6627\n",
      "   F1 Score:  0.4063\n",
      "\n",
      "ğŸ“Š Confusion Matrix:\n",
      "              Predicted\n",
      "              Retained  Churned\n",
      "   Actual\n",
      "   Retained       545      403\n",
      "   Churned         85      167\n",
      "\n",
      "ğŸ“Š Business Interpretation:\n",
      "   True Positives (TP):  167 - Churners correctly identified (can intervene)\n",
      "   True Negatives (TN):  545 - Retained correctly identified\n",
      "   False Positives (FP): 403 - Retained but flagged (unnecessary contact)\n",
      "   False Negatives (FN): 85 - Churners missed (lost opportunity)\n",
      "\n",
      "============================================================\n",
      "ğŸ’° BUSINESS IMPACT ESTIMATION\n",
      "============================================================\n",
      "\n",
      "   Average CLV: $1,974\n",
      "   Churners identified (TP): 167\n",
      "   Assumed intervention success: 50%\n",
      "   Customers saved: ~83\n",
      "   Estimated value protected: $164,839\n",
      "\n",
      "âœ… Model evaluation complete!\n",
      "   Artifacts stored: MODEL_METRICS\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL EVALUATION \n",
    "# ============================================================\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“ˆ CHURN PREDICTION MODEL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY MODEL AND TEST INDICES\n",
    "# ============================================================\n",
    "if 'CHURN_MODEL' not in globals():\n",
    "    raise ValueError(\"âŒ CHURN_MODEL not found. Run Section 3 first.\")\n",
    "else:\n",
    "    print(f\"âœ… Using predictions from trained {type(CHURN_MODEL).__name__}\")\n",
    "\n",
    "if 'test_indices' not in globals():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    _, test_indices = train_test_split(\n",
    "        customer_df.index, test_size=0.2, \n",
    "        random_state=MODEL_SEED, \n",
    "        stratify=customer_df['churned']\n",
    "    )\n",
    "    print(\"âš ï¸ Recreated test indices (matches original split via seed)\")\n",
    "\n",
    "test_df = customer_df.loc[test_indices].copy()\n",
    "\n",
    "print(f\"\\nğŸ“Š Test Set Overview:\")\n",
    "print(f\"   Samples: {len(test_df)}\")\n",
    "print(f\"   Actual churn rate: {test_df['churned'].mean():.1%}\")\n",
    "\n",
    "# Extract predictions and actuals\n",
    "y_true = test_df['churned'].values\n",
    "y_prob = test_df['churn_probability'].values\n",
    "\n",
    "# ============================================================\n",
    "# PRIMARY METRIC: AUC-ROC\n",
    "# ============================================================\n",
    "auc = roc_auc_score(y_true, y_prob)\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"ğŸ¯ PRIMARY METRIC: AUC-ROC = {auc:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   Interpretation: Model ranks churners above non-churners\")\n",
    "print(f\"   {auc*100:.1f}% of the time (vs 50% random)\")\n",
    "\n",
    "# ============================================================\n",
    "# THRESHOLD ANALYSIS\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š THRESHOLD ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "print(f\"\\n{'Threshold':<12} {'Precision':<12} {'Recall':<12} {'F1':<12}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0.5\n",
    "threshold_results = {}\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred = (y_prob >= thresh).astype(int)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    threshold_results[thresh] = {'precision': prec, 'recall': rec, 'f1': f1}\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = thresh\n",
    "    \n",
    "    marker = \" â† best F1\" if thresh == best_threshold and f1 == best_f1 else \"\"\n",
    "    print(f\"{thresh:<12.1f} {prec:<12.3f} {rec:<12.3f} {f1:<12.3f}{marker}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Selected threshold: {best_threshold} (F1={best_f1:.3f})\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL EVALUATION AT SELECTED THRESHOLD\n",
    "# ============================================================\n",
    "threshold = best_threshold\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"ğŸ“Š FINAL METRICS (threshold={threshold})\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ¯ Classification Metrics:\")\n",
    "print(f\"   AUC-ROC:   {auc:.4f}\")\n",
    "print(f\"   Precision: {precision_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"   Recall:    {recall_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"   F1 Score:  {f1_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# CONFUSION MATRIX\n",
    "# ============================================================\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\nğŸ“Š Confusion Matrix:\")\n",
    "print(f\"              Predicted\")\n",
    "print(f\"              Retained  Churned\")\n",
    "print(f\"   Actual\")\n",
    "print(f\"   Retained     {tn:5d}    {fp:5d}\")\n",
    "print(f\"   Churned      {fn:5d}    {tp:5d}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Business Interpretation:\")\n",
    "print(f\"   True Positives (TP):  {tp} - Churners correctly identified (can intervene)\")\n",
    "print(f\"   True Negatives (TN):  {tn} - Retained correctly identified\")\n",
    "print(f\"   False Positives (FP): {fp} - Retained but flagged (unnecessary contact)\")\n",
    "print(f\"   False Negatives (FN): {fn} - Churners missed (lost opportunity)\")\n",
    "\n",
    "# ============================================================\n",
    "# BUSINESS IMPACT ESTIMATION\n",
    "# ============================================================\n",
    "avg_clv = test_df['clv_estimate'].mean()\n",
    "intervention_success_rate = 0.50  # Assume 50% of interventions succeed\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’° BUSINESS IMPACT ESTIMATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n   Average CLV: ${avg_clv:,.0f}\")\n",
    "print(f\"   Churners identified (TP): {tp}\")\n",
    "print(f\"   Assumed intervention success: {intervention_success_rate:.0%}\")\n",
    "print(f\"   Customers saved: ~{int(tp * intervention_success_rate)}\")\n",
    "print(f\"   Estimated value protected: ${int(tp * intervention_success_rate * avg_clv):,}\")\n",
    "\n",
    "# ============================================================\n",
    "# STORE EVALUATION ARTIFACTS\n",
    "# ============================================================\n",
    "MODEL_METRICS = {\n",
    "    'auc': auc,\n",
    "    'threshold': threshold,\n",
    "    'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "    'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "    'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "    'confusion_matrix': {'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp}\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ… Model evaluation complete!\")\n",
    "print(f\"   Artifacts stored: MODEL_METRICS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BUSINESS IMPACT\n",
      "============================================================\n",
      "\n",
      "At-Risk Analysis:\n",
      "  Customers at risk: 570\n",
      "  Total CLV at risk: $462,796\n",
      "\n",
      "ROI Projection:\n",
      "  Intervention cost: $285,000\n",
      "  Expected savings: $138,839\n",
      "  Expected ROI: 0.5x\n"
     ]
    }
   ],
   "source": [
    "# Business Impact\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BUSINESS IMPACT\")\n",
    "# Centralized defaults (override these variables above if you want)\n",
    "threshold = globals().get('threshold', CONFIG['business_impact']['default_risk_threshold'])\n",
    "expected_lift = globals().get('expected_lift', CONFIG['business_impact']['expected_lift_default'])\n",
    "avg_cost = globals().get('avg_cost', CONFIG['business_impact']['avg_cost_default'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "at_risk = test_df[test_df['churn_probability'] >= threshold]\n",
    "total_clv_at_risk = at_risk['clv_estimate'].sum()\n",
    "intervention_cost = len(at_risk) * avg_cost\n",
    "expected_savings = total_clv_at_risk * expected_lift\n",
    "roi = expected_savings / intervention_cost if intervention_cost > 0 else 0\n",
    "\n",
    "print(f\"\\nAt-Risk Analysis:\")\n",
    "print(f\"  Customers at risk: {len(at_risk)}\")\n",
    "print(f\"  Total CLV at risk: ${total_clv_at_risk:,.0f}\")\n",
    "\n",
    "print(f\"\\nROI Projection:\")\n",
    "print(f\"  Intervention cost: ${intervention_cost:,.0f}\")\n",
    "print(f\"  Expected savings: ${expected_savings:,.0f}\")\n",
    "print(f\"  Expected ROI: {roi:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sensitivity grid computed (sample below):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk_threshold</th>\n",
       "      <th>at_risk_customers</th>\n",
       "      <th>total_clv_at_risk</th>\n",
       "      <th>expected_lift</th>\n",
       "      <th>avg_cost</th>\n",
       "      <th>expected_roi_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.266725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.106690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.1</td>\n",
       "      <td>800</td>\n",
       "      <td>0.066681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.533450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.213380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.133362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.800174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.320070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.200044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.4</td>\n",
       "      <td>200</td>\n",
       "      <td>1.066899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>0.426760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.7</td>\n",
       "      <td>304</td>\n",
       "      <td>162168.656</td>\n",
       "      <td>0.4</td>\n",
       "      <td>800</td>\n",
       "      <td>0.266725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    risk_threshold  at_risk_customers  total_clv_at_risk  expected_lift  \\\n",
       "0              0.7                304         162168.656            0.1   \n",
       "1              0.7                304         162168.656            0.1   \n",
       "2              0.7                304         162168.656            0.1   \n",
       "3              0.7                304         162168.656            0.2   \n",
       "4              0.7                304         162168.656            0.2   \n",
       "5              0.7                304         162168.656            0.2   \n",
       "6              0.7                304         162168.656            0.3   \n",
       "7              0.7                304         162168.656            0.3   \n",
       "8              0.7                304         162168.656            0.3   \n",
       "9              0.7                304         162168.656            0.4   \n",
       "10             0.7                304         162168.656            0.4   \n",
       "11             0.7                304         162168.656            0.4   \n",
       "\n",
       "    avg_cost  expected_roi_x  \n",
       "0        200        0.266725  \n",
       "1        500        0.106690  \n",
       "2        800        0.066681  \n",
       "3        200        0.533450  \n",
       "4        500        0.213380  \n",
       "5        800        0.133362  \n",
       "6        200        0.800174  \n",
       "7        500        0.320070  \n",
       "8        800        0.200044  \n",
       "9        200        1.066899  \n",
       "10       500        0.426760  \n",
       "11       800        0.266725  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SENSITIVITY CHECKS (hardcoded assumptions)\n",
    "# ============================================================\n",
    "# Goal: show how business impact metrics change when key assumptions vary.\n",
    "# This makes the notebook robust and reduces the risk that a single hardcoded\n",
    "# value drives the narrative.\n",
    "\n",
    "if 'churn_probability' not in customer_df.columns:\n",
    "    print(\"âš ï¸ churn_probability not available yet. Run model scoring first.\")\n",
    "else:\n",
    "    at_risk_thresholds = [0.70, 0.75, 0.80]\n",
    "    lift_grid = [0.10, 0.20, 0.30, 0.40]\n",
    "    cost_grid = [200, 500, 800]\n",
    "\n",
    "    rows = []\n",
    "    for thr in at_risk_thresholds:\n",
    "        at_risk = customer_df[customer_df['churn_probability'] >= thr]\n",
    "        total_clv = at_risk['clv_estimate'].sum() if 'clv_estimate' in at_risk.columns else np.nan\n",
    "        n = len(at_risk)\n",
    "        for lift in lift_grid:\n",
    "            for cost in cost_grid:\n",
    "                intervention_cost = n * cost\n",
    "                expected_savings = total_clv * lift if pd.notna(total_clv) else np.nan\n",
    "                roi = (expected_savings / intervention_cost) if intervention_cost else np.nan\n",
    "                rows.append({\n",
    "                    \"risk_threshold\": thr,\n",
    "                    \"at_risk_customers\": n,\n",
    "                    \"total_clv_at_risk\": total_clv,\n",
    "                    \"expected_lift\": lift,\n",
    "                    \"avg_cost\": cost,\n",
    "                    \"expected_roi_x\": roi,\n",
    "                })\n",
    "\n",
    "    sens_df = pd.DataFrame(rows)\n",
    "    print(\"âœ… Sensitivity grid computed (sample below):\")\n",
    "    display(sens_df.sort_values(['risk_threshold', 'expected_lift', 'avg_cost']).head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUCCESS CRITERIA\n",
      "============================================================\n",
      "âœ… Multi-Agent System: Orchestrator + 4 sub-agents + Sequential/Parallel/Loop\n",
      "âœ… Custom Tools: 5 tools: churn_score, intervention, behavior, survival, at_risk\n",
      "âœ… Code Execution: BuiltInCodeExecutor (ADK v1.0.0+ pattern)\n",
      "âœ… Sessions & Memory: InMemorySessionService + CustomerMemoryStore\n",
      "âœ… Observability: MetricsCollector + trace_execution\n",
      "âœ… ADK v1.0.0+ Compatible: Agent class, separate agent instances per parent\n"
     ]
    }
   ],
   "source": [
    "# Success Criteria\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUCCESS CRITERIA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "criteria = [\n",
    "    (\"Multi-Agent System\", True, \"Orchestrator + 4 sub-agents + Sequential/Parallel/Loop\"),\n",
    "    (\"Custom Tools\", True, \"5 tools: churn_score, intervention, behavior, survival, at_risk\"),\n",
    "    (\"Code Execution\", True, \"BuiltInCodeExecutor (ADK v1.0.0+ pattern)\"),\n",
    "    (\"Sessions & Memory\", True, \"InMemorySessionService + CustomerMemoryStore\"),\n",
    "    (\"Observability\", True, \"MetricsCollector + trace_execution\"),\n",
    "    (\"ADK v1.0.0+ Compatible\", True, \"Agent class, separate agent instances per parent\")\n",
    "]\n",
    "\n",
    "for name, passed, details in criteria:\n",
    "    status = \"âœ…\" if passed else \"âŒ\"\n",
    "    print(f\"{status} {name}: {details}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: A/B Testing Framework\n",
    "\n",
    "> **âš ï¸ Important Note**: This section demonstrates A/B testing **methodology**, not real experimental results. Effect sizes are industry-benchmark assumptions used for simulation. In production, these values would be discovered through actual randomized experiments.\n",
    "\n",
    "**What this section validates**:\n",
    "- Statistical testing methodology (chi-square, Bonferroni correction)\n",
    "- Sample size requirements for significance detection\n",
    "- ROI calculation framework\n",
    "- Channel effectiveness ranking approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“Š A/B TESTING FRAMEWORK\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# A/B TESTING FRAMEWORK \n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š A/B TESTING FRAMEWORK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SAMPLE SIZE CALCULATOR\n",
    "# ============================================================\n",
    "\n",
    "def calculate_sample_size(\n",
    "    baseline_rate: float,\n",
    "    minimum_detectable_effect: float,  # ABSOLUTE effect\n",
    "    significance_level: float = 0.05,\n",
    "    power: float = 0.80\n",
    "    ) -> int:\n",
    "    \"\"\"\n",
    "    Calculate required sample size per group using power analysis.\n",
    "    \n",
    "    Args:\n",
    "        baseline_rate: Current churn rate (e.g., 0.15 for 15%)\n",
    "        minimum_detectable_effect: ABSOLUTE reduction to detect (e.g., 0.05 for 5%)\n",
    "        significance_level: Alpha (default 0.05)\n",
    "        power: Statistical power (default 0.80)\n",
    "        \n",
    "    Returns:\n",
    "        Required sample size per group\n",
    "    \"\"\"\n",
    "    treatment_rate = baseline_rate - minimum_detectable_effect\n",
    "    \n",
    "    # Pooled proportion\n",
    "    p_pooled = (baseline_rate + treatment_rate) / 2\n",
    "    \n",
    "    # Z-scores\n",
    "    z_alpha = stats.norm.ppf(1 - significance_level / 2)\n",
    "    z_beta = stats.norm.ppf(power)\n",
    "    \n",
    "    # Sample size formula for proportions\n",
    "    numerator = (z_alpha * np.sqrt(2 * p_pooled * (1 - p_pooled)) + \n",
    "                 z_beta * np.sqrt(baseline_rate * (1 - baseline_rate) + \n",
    "                                   treatment_rate * (1 - treatment_rate))) ** 2\n",
    "    denominator = (baseline_rate - treatment_rate) ** 2\n",
    "    \n",
    "    n = int(np.ceil(numerator / denominator))\n",
    "    \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# A/B TEST MANAGER \n",
    "# ============================================================\n",
    "\n",
    "class ABTestManager:\n",
    "    \"\"\"\n",
    "    A/B Test Manager with proper statistical simulation.\n",
    "    \n",
    "    VARIANT NAMES: ['Control', 'Email', 'Discount', 'Call', 'Combined']\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.experiments = {}\n",
    "        self.assignments = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def create_experiment(\n",
    "        self,\n",
    "        name: str,\n",
    "        intervention_type: str,\n",
    "        control_rate: float,\n",
    "        treatment_rate: float,\n",
    "        sample_size_per_group: int,\n",
    "        variants: List[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Create a new A/B test experiment.\"\"\"\n",
    "        if variants is None:\n",
    "            variants = ['Control', 'Treatment']\n",
    "            \n",
    "        experiment_id = f\"exp_{name}_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "        \n",
    "        if treatment_rate >= control_rate:\n",
    "            raise ValueError('treatment_rate must be lower than control_rate for churn reduction experiments.')\n",
    "        effect_size = control_rate - treatment_rate\n",
    "        if effect_size <= 0:\n",
    "            raise ValueError('Effect size is zero; choose different control_rate and treatment_rate.')\n",
    "        required_n = calculate_sample_size(control_rate, effect_size)\n",
    "        is_powered = sample_size_per_group >= required_n\n",
    "        \n",
    "        self.experiments[experiment_id] = {\n",
    "            \"id\": experiment_id,\n",
    "            \"name\": name,\n",
    "            \"intervention_type\": intervention_type,\n",
    "            \"variants\": variants,\n",
    "            \"control_rate\": control_rate,\n",
    "            \"treatment_rate\": treatment_rate,\n",
    "            \"sample_size\": sample_size_per_group,\n",
    "            \"required_sample_size\": required_n,\n",
    "            \"adequately_powered\": is_powered,\n",
    "            \"config\": {\n",
    "                \"significance_level\": float(CONFIG['ab_test']['alpha']),\n",
    "                \"minimum_detectable_effect\": effect_size\n",
    "            },\n",
    "            \"status\": \"active\",\n",
    "            \"created_at\": datetime.now().isoformat(),\n",
    "            \"participants\": {v: [] for v in variants},\n",
    "            \"outcomes\": {v: {\"churned\": 0, \"retained\": 0} for v in variants}\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Created experiment: {experiment_id}\")\n",
    "        print(f\"   Intervention: {intervention_type}\")\n",
    "        print(f\"   Control rate: {control_rate:.1%} | Treatment rate: {treatment_rate:.1%}\")\n",
    "        print(f\"   Effect size: {effect_size:.1%} absolute ({effect_size/control_rate*100:.1f}% relative)\")\n",
    "        print(f\"   Sample size: {sample_size_per_group} per group\")\n",
    "        print(f\"   Required for 80% power: {required_n}\")\n",
    "        print(f\"   Adequately powered: {'YES âœ…' if is_powered else 'NO âš ï¸'}\")\n",
    "        \n",
    "        return experiment_id\n",
    "    \n",
    "    def run_experiment(self, experiment_id: str, seed: int = None) -> None:\n",
    "        \"\"\"Run the experiment simulation using GROUP-LEVEL rates.\"\"\"\n",
    "        seed = ABTEST_SEED if seed is None else int(seed)\n",
    "        rng = np.random.default_rng(seed)\n",
    "        \n",
    "        if experiment_id not in self.experiments:\n",
    "            raise ValueError(f\"Experiment {experiment_id} not found\")\n",
    "            \n",
    "        exp = self.experiments[experiment_id]\n",
    "        n = exp[\"sample_size\"]\n",
    "        \n",
    "        # Simulate using GROUP-LEVEL binomial distribution\n",
    "        control_churned = rng.binomial(n, exp['control_rate'])\n",
    "        treatment_churned = rng.binomial(n, exp['treatment_rate'])\n",
    "        \n",
    "        # Store in outcomes - using 'Control' and 'Treatment'\n",
    "        exp[\"outcomes\"][\"Control\"] = {\n",
    "            \"churned\": control_churned,\n",
    "            \"retained\": n - control_churned\n",
    "        }\n",
    "        exp[\"outcomes\"][\"Treatment\"] = {\n",
    "            \"churned\": treatment_churned,\n",
    "            \"retained\": n - treatment_churned\n",
    "        }\n",
    "        \n",
    "        # Create participant IDs\n",
    "        for i in range(n):\n",
    "            exp[\"participants\"][\"Control\"].append(f\"ctrl_{i}\")\n",
    "            exp[\"participants\"][\"Treatment\"].append(f\"treat_{i}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Experiment {exp['name']} completed:\")\n",
    "        print(f\"   Control: {control_churned}/{n} churned ({control_churned/n:.1%})\")\n",
    "        print(f\"   Treatment: {treatment_churned}/{n} churned ({treatment_churned/n:.1%})\")\n",
    "    \n",
    "    def analyze_results(self, experiment_id: str) -> Dict:\n",
    "        \"\"\"Perform statistical analysis. Output format matches Executive Dashboard.\"\"\"\n",
    "        if experiment_id not in self.experiments:\n",
    "            raise ValueError(f\"Experiment {experiment_id} not found\")\n",
    "            \n",
    "        exp = self.experiments[experiment_id]\n",
    "        outcomes = exp[\"outcomes\"]\n",
    "        \n",
    "        # Get Control and Treatment outcomes\n",
    "        control = outcomes.get(\"Control\", {\"churned\": 0, \"retained\": 0})\n",
    "        treatment = outcomes.get(\"Treatment\", {\"churned\": 0, \"retained\": 0})\n",
    "        \n",
    "        control_total = control[\"churned\"] + control[\"retained\"]\n",
    "        treatment_total = treatment[\"churned\"] + treatment[\"retained\"]\n",
    "        \n",
    "        if control_total == 0 or treatment_total == 0:\n",
    "            return {\"status\": \"insufficient_data\"}\n",
    "        \n",
    "        control_churn_rate = control[\"churned\"] / control_total\n",
    "        treatment_churn_rate = treatment[\"churned\"] / treatment_total\n",
    "        \n",
    "        if control_churn_rate > 0:\n",
    "            relative_lift = (control_churn_rate - treatment_churn_rate) / control_churn_rate\n",
    "        else:\n",
    "            relative_lift = 0\n",
    "        absolute_lift = control_churn_rate - treatment_churn_rate\n",
    "        \n",
    "        # Chi-square test\n",
    "        contingency_table = [\n",
    "            [control[\"churned\"], control[\"retained\"]],\n",
    "            [treatment[\"churned\"], treatment[\"retained\"]]\n",
    "        ]\n",
    "        chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "        \n",
    "        # Validate chi-square assumptions (expected frequencies >= 5)\n",
    "        min_expected = expected.min()\n",
    "        if min_expected < 5:\n",
    "            print(f\"âš ï¸ Warning: Min expected frequency ({min_expected:.1f}) < 5. \"\n",
    "                  \"Chi-square test may be unreliable for small samples.\")\n",
    "        \n",
    "        # Confidence interval\n",
    "        se = np.sqrt(\n",
    "            (control_churn_rate * (1 - control_churn_rate) / control_total) +\n",
    "            (treatment_churn_rate * (1 - treatment_churn_rate) / treatment_total)\n",
    "        )\n",
    "        z_score = stats.norm.ppf(0.975)\n",
    "        ci_lower = absolute_lift - z_score * se\n",
    "        ci_upper = absolute_lift + z_score * se\n",
    "        \n",
    "        significance_level = exp[\"config\"][\"significance_level\"]\n",
    "        is_significant = p_value < significance_level\n",
    "        \n",
    "        # Build results in DASHBOARD-COMPATIBLE FORMAT\n",
    "        results = {\n",
    "            \"experiment_id\": experiment_id,\n",
    "            \"experiment_name\": exp[\"name\"],\n",
    "            \"status\": \"complete\",\n",
    "            \"sample_sizes\": {\n",
    "                \"control\": control_total,\n",
    "                \"treatment\": treatment_total,\n",
    "                \"total\": control_total + treatment_total\n",
    "            },\n",
    "            \"churn_rates\": {\n",
    "                \"control\": round(control_churn_rate, 4),\n",
    "                \"treatment\": round(treatment_churn_rate, 4)\n",
    "            },\n",
    "            \"lift\": {\n",
    "                \"absolute\": round(absolute_lift, 4),\n",
    "                \"relative\": round(relative_lift, 4),\n",
    "                \"relative_pct\": f\"{relative_lift * 100:.1f}%\"\n",
    "            },\n",
    "            \"statistical_tests\": {\n",
    "                \"chi_square\": round(chi2, 4),\n",
    "                \"p_value\": round(p_value, 6),\n",
    "                \"degrees_of_freedom\": dof\n",
    "            },\n",
    "            \"confidence_interval_95\": {\n",
    "                \"lower\": round(ci_lower, 4),\n",
    "                \"upper\": round(ci_upper, 4)\n",
    "            },\n",
    "            \"conclusion\": {\n",
    "                \"is_significant\": is_significant,\n",
    "                \"significance_level\": significance_level,\n",
    "                \"recommendation\": self._get_recommendation(is_significant, relative_lift, p_value)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.results[experiment_id] = results\n",
    "        return results\n",
    "    \n",
    "    def _get_recommendation(self, is_significant: bool, relative_lift: float, p_value: float) -> str:\n",
    "        \"\"\"Generate recommendation based on results.\"\"\"\n",
    "        if not is_significant:\n",
    "            if p_value < 0.10:\n",
    "                return \"Results trending positive but not yet significant. Consider extending the experiment.\"\n",
    "            else:\n",
    "                return \"No significant difference detected. Consider testing alternative interventions.\"\n",
    "        \n",
    "        if relative_lift > CONFIG['ab_test']['recommendation_relative_lift']['strong']:\n",
    "            return \"ğŸ‰ Strong positive impact! Recommend rolling out to all customers immediately.\"\n",
    "        elif relative_lift > CONFIG['ab_test']['recommendation_relative_lift']['moderate']:\n",
    "            return \"âœ… Significant positive impact. Recommend gradual rollout with continued monitoring.\"\n",
    "        elif relative_lift > 0:\n",
    "            return \"ğŸ“ˆ Modest positive impact. Consider cost-benefit analysis before full rollout.\"\n",
    "        else:\n",
    "            return \"âš ï¸ Treatment shows higher churn. Stop experiment and investigate.\"\n",
    "    \n",
    "    def get_experiment_status(self, experiment_id: str) -> Dict:\n",
    "        \"\"\"Get current status of an experiment.\"\"\"\n",
    "        if experiment_id not in self.experiments:\n",
    "            raise ValueError(f\"Experiment {experiment_id} not found\")\n",
    "            \n",
    "        exp = self.experiments[experiment_id]\n",
    "        outcomes = exp[\"outcomes\"]\n",
    "        \n",
    "        return {\n",
    "            \"experiment_id\": experiment_id,\n",
    "            \"name\": exp[\"name\"],\n",
    "            \"status\": exp[\"status\"],\n",
    "            \"adequately_powered\": exp[\"adequately_powered\"],\n",
    "            \"variants\": {\n",
    "                variant: {\n",
    "                    \"participants\": len(exp[\"participants\"][variant]),\n",
    "                    \"outcomes\": outcomes[variant]\n",
    "                }\n",
    "                for variant in exp[\"variants\"]\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ABTestManager initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INITIALIZE AND RUN A/B TEST\n",
    "# ============================================================\n",
    "\n",
    "# Initialize the A/B Test Manager\n",
    "ab_manager = ABTestManager()\n",
    "print(\"âœ… ABTestManager initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“ SAMPLE SIZE CALCULATION\n",
      "============================================================\n",
      "\n",
      "Baseline churn rate: 21.0%\n",
      "Target treatment rate: 16.0%\n",
      "Minimum detectable effect: 5.0% absolute\n",
      "Significance level (Î±): 0.05\n",
      "Statistical power (1-Î²): 0.80\n",
      "\n",
      "ğŸ“Š Required sample size per group: 947\n",
      "ğŸ“Š Total sample size needed: 1894\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SAMPLE SIZE CALCULATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“ SAMPLE SIZE CALCULATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline_churn_rate = customer_df['churned'].mean()  \n",
    "target_effect = 0.05        # 5% ABSOLUTE reduction \n",
    "\n",
    "required_sample = calculate_sample_size(\n",
    "    baseline_rate=baseline_churn_rate,\n",
    "    minimum_detectable_effect=target_effect,\n",
    "    significance_level=0.05,\n",
    "    power=0.80\n",
    ")\n",
    "\n",
    "print(f\"\\nBaseline churn rate: {baseline_churn_rate:.1%}\")\n",
    "print(f\"Target treatment rate: {baseline_churn_rate - target_effect:.1%}\")\n",
    "print(f\"Minimum detectable effect: {target_effect:.1%} absolute\")\n",
    "print(f\"Significance level (Î±): 0.05\")\n",
    "print(f\"Statistical power (1-Î²): 0.80\")\n",
    "print(f\"\\nğŸ“Š Required sample size per group: {required_sample}\")\n",
    "print(f\"ğŸ“Š Total sample size needed: {required_sample * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Data-derived baseline churn rate: 21.0%\n",
      "\n",
      "============================================================\n",
      "ğŸ§ª RUNNING BINARY A/B TEST (Control vs Treatment)\n",
      "============================================================\n",
      "âœ… Created experiment: exp_re_engagement_campaign_20251227160844\n",
      "   Intervention: Re-engagement Campaign with Training\n",
      "   Control rate: 21.0% | Treatment rate: 10.0%\n",
      "   Effect size: 11.0% absolute (52.4% relative)\n",
      "   Sample size: 2250 per group\n",
      "   Required for 80% power: 169\n",
      "   Adequately powered: YES âœ…\n",
      "\n",
      "ğŸ“Š Experiment re_engagement_campaign completed:\n",
      "   Control: 460/2250 churned (20.4%)\n",
      "   Treatment: 202/2250 churned (9.0%)\n",
      "\n",
      "============================================================\n",
      "ğŸ“ˆ A/B TEST RESULTS\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "EXPERIMENT: re_engagement_campaign\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š Sample Sizes:\n",
      "   Control: 2250 customers\n",
      "   Treatment: 2250 customers\n",
      "\n",
      "ğŸ“‰ Churn Rates:\n",
      "   Control: 20.4%\n",
      "   Treatment: 9.0%\n",
      "\n",
      "ğŸ“ˆ Lift:\n",
      "   Absolute: 11.47% reduction in churn\n",
      "   Relative: 56.1% improvement\n",
      "\n",
      "ğŸ”¬ Statistical Significance:\n",
      "   Chi-square: 116.9811\n",
      "   P-value: 0.000000\n",
      "   Significant at Î±=0.05: âœ… YES\n",
      "\n",
      "ğŸ“ 95% Confidence Interval:\n",
      "   [9.42%, 13.51%]\n",
      "\n",
      "ğŸ’¡ Recommendation:\n",
      "   ğŸ‰ Strong positive impact! Recommend rolling out to all customers immediately.\n",
      "\n",
      "============================================================\n",
      "ğŸ”¬ MULTI-VARIANT TEST\n",
      "   Variants: ['Control', 'Email', 'Discount', 'Call', 'Combined']\n",
      "   Participants: 2,000 total (400 per variant)\n",
      "============================================================\n",
      "ğŸ² Experiment seed set to 11 for reproducibility\n",
      "\n",
      "Baseline churn rate: 21.0%\n",
      "Sample per variant: 900\n",
      "Total participants: 4,500\n",
      "Multiple testing: Bonferroni, m=4, adjusted Î±=0.0125\n",
      "\n",
      "Variant      n      Churned  Rate     Abs Î”      Rel lift   P-value      Sig (adj Î±)\n",
      "--------------------------------------------------------------------------------------------\n",
      "Control      900    195      21.7% â€”          â€”          â€”            (baseline)\n",
      "âœ… Created experiment: exp_multi_variant_intervention_20251227160844\n",
      "   Intervention: Multi-Variant Intervention Test\n",
      "   Control rate: 21.0% | Treatment rate: 15.2%\n",
      "   Effect size: 5.8% absolute (27.6% relative)\n",
      "   Sample size: 900 per group\n",
      "   Required for 80% power: 692\n",
      "   Adequately powered: YES âœ…\n",
      "Email        900    158      17.6% +4.1%     +19.0%     0.032593     âŒ NO\n",
      "Discount     900    140      15.6% +6.1%     +28.2%     0.001074     âœ… YES\n",
      "Call         900    89       9.9% +11.8%     +54.4%     0.000000     âœ… YES\n",
      "Combined     900    135      15.0% +6.7%     +30.8%     0.000326     âœ… YES\n",
      "\n",
      "============================================================\n",
      "ğŸ† WINNER (adjusted Î±=0.0125): Call\n",
      "   Churn rate: 9.9%\n",
      "   Relative churn reduction vs Control: 54.4%\n",
      "\n",
      "============================================================\n",
      "ğŸ’° CALCULATING ROI FROM A/B TEST DATA\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Average CLV: $1,930.82\n",
      "ğŸ“Š Control churn rate: 21.7%\n",
      "\n",
      "ğŸ“ˆ ROI Calculation:\n",
      "   Formula: ROI = (avg_CLV Ã— absolute_reduction) / cost\n",
      "   Note: Using ABSOLUTE reduction (pp), not relative lift (%)\n",
      "----------------------------------------------------------------------\n",
      "Variant    Churn    Rel Lift   Abs Î”    Value      Cost     ROI   \n",
      "----------------------------------------------------------------------\n",
      "   Email      17.6%    19.0%      4.1%    $79.38    $0.50    158.8x\n",
      "   Discount   15.6%    28.2%      6.1%    $117.99   $10.00   11.8x\n",
      "   Call       9.9%    54.4%      11.8%    $227.41   $35.00   6.5x\n",
      "   Combined   15.0%    30.8%      6.7%    $128.72   $45.50   2.8x\n",
      "\n",
      "âœ… CHANNEL_EFFECTIVENESS and INTERVENTION_ROI calculated from A/B test data\n",
      "   â€¢ Relative Lift: Used for marketing/executive communication\n",
      "   â€¢ Absolute Reduction: Used for ROI calculation (value saved per customer)\n",
      "   â€¢ These values will be used by recommend_intervention() and Dashboard\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# RUN MAIN A/B EXPERIMENT (Binary: Control vs Treatment)\n",
    "# ============================================================\n",
    "\n",
    "SEED = int(globals().get('SEED', ABTEST_SEED))\n",
    "ALPHA = float(globals().get('ALPHA', CONFIG['ab_test']['alpha']))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# FIX: Define baseline_rate HERE, before using it in the experiment\n",
    "# ------------------------------------------------------------------\n",
    "# Ensure customer_df is loaded before running this cell\n",
    "baseline_rate = customer_df['churned'].mean()\n",
    "print(f\"ğŸ“Š Data-derived baseline churn rate: {baseline_rate:.1%}\")\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ§ª RUNNING BINARY A/B TEST (Control vs Treatment)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "experiment_id = ab_manager.create_experiment(\n",
    "    name=\"re_engagement_campaign\",\n",
    "    intervention_type=\"Re-engagement Campaign with Training\",\n",
    "    control_rate=baseline_rate,     \n",
    "    treatment_rate=0.10,    # treatment churn rate\n",
    "    sample_size_per_group=2250,\n",
    "    variants=[\"Control\", \"Treatment\"]\n",
    ")\n",
    "\n",
    "ab_manager.run_experiment(experiment_id, seed=SEED)\n",
    "results = ab_manager.analyze_results(experiment_id)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“ˆ A/B TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"EXPERIMENT: {results['experiment_name']}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Sample Sizes:\")\n",
    "print(f\"   Control: {results['sample_sizes']['control']} customers\")\n",
    "print(f\"   Treatment: {results['sample_sizes']['treatment']} customers\")\n",
    "\n",
    "print(\"\\nğŸ“‰ Churn Rates:\")\n",
    "print(f\"   Control: {results['churn_rates']['control']:.1%}\")\n",
    "print(f\"   Treatment: {results['churn_rates']['treatment']:.1%}\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ Lift:\")\n",
    "print(f\"   Absolute: {results['lift']['absolute']:.2%} reduction in churn\")\n",
    "print(f\"   Relative: {results['lift']['relative_pct']} improvement\")\n",
    "\n",
    "print(\"\\nğŸ”¬ Statistical Significance:\")\n",
    "print(f\"   Chi-square: {results['statistical_tests']['chi_square']:.4f}\")\n",
    "print(f\"   P-value: {results['statistical_tests']['p_value']:.6f}\")\n",
    "print(f\"   Significant at Î±={ALPHA:.2f}: {'âœ… YES' if results['conclusion']['is_significant'] else 'âŒ NO'}\")\n",
    "\n",
    "print(\"\\nğŸ“ 95% Confidence Interval:\")\n",
    "print(f\"   [{results['confidence_interval_95']['lower']:.2%}, {results['confidence_interval_95']['upper']:.2%}]\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Recommendation:\")\n",
    "print(f\"   {results['conclusion']['recommendation']}\")\n",
    "\n",
    "# ============================================================\n",
    "# MULTI-VARIANT TEST: ['Control', 'Email', 'Discount', 'Call', 'Combined']\n",
    "# 2,000 participants total (400 per variant)\n",
    "# ============================================================\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ”¬ MULTI-VARIANT TEST\")\n",
    "print(\"   Variants: ['Control', 'Email', 'Discount', 'Call', 'Combined']\")\n",
    "print(\"   Participants: 2,000 total (400 per variant)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "np.random.seed(11)\n",
    "print(f\"ğŸ² Experiment seed set to {11} for reproducibility\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EFFECT SIZES: Industry-benchmark assumptions for simulation\n",
    "# ============================================================\n",
    "\n",
    "variant_effects_pp = {\n",
    "    \"Email\": 0.035,     # 3.5pp reduction (~18% relative lift)\n",
    "    \"Discount\": 0.06,   # 6.0pp reduction (~31% relative lift)\n",
    "    \"Call\": 0.102,      # 10.2pp reduction (~53% relative lift) - high-touch intervention\n",
    "    \"Combined\": 0.058   # 5.8pp reduction (~30% relative lift, less than Call due to fatigue)\n",
    "}\n",
    "\n",
    "n_per_variant = 900\n",
    "m_tests = len(variant_effects_pp)\n",
    "alpha_adj = ALPHA / m_tests  # Bonferroni correction\n",
    "\n",
    "print(f\"\\nBaseline churn rate: {baseline_rate:.1%}\")\n",
    "print(f\"Sample per variant: {n_per_variant}\")\n",
    "print(f\"Total participants: {n_per_variant * (1 + m_tests):,}\")\n",
    "print(f\"Multiple testing: Bonferroni, m={m_tests}, adjusted Î±={alpha_adj:.4f}\")\n",
    "\n",
    "# Simulate Control\n",
    "control_churned = np.random.binomial(n_per_variant, baseline_rate)\n",
    "control_rate_obs = control_churned / n_per_variant\n",
    "\n",
    "multi_variant_results = {\n",
    "    \"Control\": {\n",
    "        \"churned\": int(control_churned),\n",
    "        \"retained\": int(n_per_variant - control_churned),\n",
    "        \"total\": int(n_per_variant),\n",
    "        \"churn_rate\": float(control_rate_obs)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"\\n{'Variant':<12} {'n':<6} {'Churned':<8} {'Rate':<8} \"\n",
    "    f\"{'Abs Î”':<10} {'Rel lift':<10} {'P-value':<12} {'Sig (adj Î±)'}\"\n",
    ")\n",
    "print(\"-\" * 92)\n",
    "print(\n",
    "    f\"{'Control':<12} {n_per_variant:<6} {control_churned:<8} {control_rate_obs:.1%} \"\n",
    "    f\"{'â€”':<10} {'â€”':<10} {'â€”':<12} {'(baseline)'}\"\n",
    ")\n",
    "\n",
    "# IMPORTANT: treatment_rate must be a churn RATE, not an effect size\n",
    "combined_rate = max(0.0, baseline_rate - variant_effects_pp[\"Combined\"])\n",
    "\n",
    "multi_exp_id = ab_manager.create_experiment(\n",
    "    name=\"multi_variant_intervention\",\n",
    "    intervention_type=\"Multi-Variant Intervention Test\",\n",
    "    control_rate=baseline_rate,\n",
    "    treatment_rate=combined_rate,\n",
    "    sample_size_per_group=n_per_variant,\n",
    "    variants=[\"Control\", \"Email\", \"Discount\", \"Call\", \"Combined\"]\n",
    ")\n",
    "\n",
    "# Ensure outcomes container exists\n",
    "ab_manager.experiments[multi_exp_id].setdefault(\"outcomes\", {})\n",
    "\n",
    "# Store Control outcomes\n",
    "ab_manager.experiments[multi_exp_id][\"outcomes\"][\"Control\"] = {\n",
    "    \"churned\": int(control_churned),\n",
    "    \"retained\": int(n_per_variant - control_churned)\n",
    "}\n",
    "\n",
    "best_variant = None\n",
    "best_lift = -1.0  # allow any positive improvement to beat this\n",
    "\n",
    "for variant_name, effect_pp in variant_effects_pp.items():\n",
    "    variant_rate = max(0.0, baseline_rate - effect_pp)\n",
    "\n",
    "    variant_churned = np.random.binomial(n_per_variant, variant_rate)\n",
    "    variant_rate_obs = variant_churned / n_per_variant\n",
    "\n",
    "    ab_manager.experiments[multi_exp_id][\"outcomes\"][variant_name] = {\n",
    "        \"churned\": int(variant_churned),\n",
    "        \"retained\": int(n_per_variant - variant_churned)\n",
    "    }\n",
    "\n",
    "    contingency = [\n",
    "        [control_churned, n_per_variant - control_churned],\n",
    "        [variant_churned, n_per_variant - variant_churned]\n",
    "    ]\n",
    "    chi2, p_value, _, _ = stats.chi2_contingency(contingency)\n",
    "\n",
    "    abs_diff = control_rate_obs - variant_rate_obs  # positive => lower churn than control\n",
    "    rel_lift = (abs_diff / control_rate_obs) if control_rate_obs > 0 else 0.0\n",
    "\n",
    "    is_sig = p_value < alpha_adj  # adjusted threshold\n",
    "\n",
    "    multi_variant_results[variant_name] = {\n",
    "        \"churned\": int(variant_churned),\n",
    "        \"retained\": int(n_per_variant - variant_churned),\n",
    "        \"total\": int(n_per_variant),\n",
    "        \"churn_rate\": float(variant_rate_obs),\n",
    "        \"abs_diff\": float(abs_diff),\n",
    "        \"lift\": float(rel_lift),\n",
    "        \"p_value\": float(p_value),\n",
    "        \"is_significant\": bool(is_sig),\n",
    "        \"chi_square\": float(chi2)\n",
    "    }\n",
    "\n",
    "    if is_sig and rel_lift > best_lift:\n",
    "        best_lift = rel_lift\n",
    "        best_variant = variant_name\n",
    "\n",
    "    sig_marker = \"âœ… YES\" if is_sig else \"âŒ NO\"\n",
    "    print(\n",
    "        f\"{variant_name:<12} {n_per_variant:<6} {variant_churned:<8} {variant_rate_obs:.1%} \"\n",
    "        f\"{abs_diff:+.1%}     {rel_lift*100:+.1f}%     {p_value:.6f}     {sig_marker}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if best_variant:\n",
    "    best_outcomes = ab_manager.experiments[multi_exp_id][\"outcomes\"][best_variant]\n",
    "    best_rate = best_outcomes[\"churned\"] / n_per_variant\n",
    "    print(f\"ğŸ† WINNER (adjusted Î±={alpha_adj:.4f}): {best_variant}\")\n",
    "    print(f\"   Churn rate: {best_rate:.1%}\")\n",
    "    print(f\"   Relative churn reduction vs Control: {best_lift*100:.1f}%\")\n",
    "else:\n",
    "    print(f\"âš ï¸ No statistically significant winner found at adjusted Î±={alpha_adj:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# CALCULATE ROI FROM A/B TEST DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’° CALCULATING ROI FROM A/B TEST DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Intervention costs (business constants - defined once)\n",
    "INTERVENTION_COSTS = {\n",
    "    'Email': 0.50,      # $0.50 per customer (automated)\n",
    "    'Discount': 10.00,  # ~10% discount average\n",
    "    'Call': 35.00,      # $35 per call (labor)\n",
    "    'Combined': 45.50   # Multi-channel total\n",
    "}\n",
    "\n",
    "# Calculate average CLV from customer data\n",
    "avg_clv = customer_df['clv_estimate'].mean()\n",
    "print(f\"\\nğŸ“Š Average CLV: ${avg_clv:,.2f}\")\n",
    "\n",
    "# Get control rate for lift calculations\n",
    "control_rate = multi_variant_results['Control']['churn_rate']\n",
    "print(f\"ğŸ“Š Control churn rate: {control_rate:.1%}\")\n",
    "\n",
    "# Build CHANNEL_EFFECTIVENESS and INTERVENTION_ROI from A/B test results\n",
    "CHANNEL_EFFECTIVENESS = {}\n",
    "INTERVENTION_ROI = {}\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ROI Calculation:\")\n",
    "print(f\"   Formula: ROI = (avg_CLV Ã— absolute_reduction) / cost\")\n",
    "print(f\"   Note: Using ABSOLUTE reduction (pp), not relative lift (%)\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Variant':<10} {'Churn':<8} {'Rel Lift':<10} {'Abs Î”':<8} {'Value':<10} {'Cost':<8} {'ROI':<6}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for variant, data in multi_variant_results.items():\n",
    "    if variant == 'Control':\n",
    "        continue\n",
    "\n",
    "    variant_rate = data['churn_rate']\n",
    "    # Use ABSOLUTE churn reduction (not relative lift) for ROI calculation\n",
    "    # abs_diff = control_rate - variant_rate (e.g., 19.2% - 9.0% = 10.2%)\n",
    "    abs_reduction = data.get('abs_diff', control_rate - variant_rate)\n",
    "    rel_lift = data.get('lift', abs_reduction / control_rate if control_rate > 0 else 0)\n",
    "    cost = INTERVENTION_COSTS.get(variant, 50.0)\n",
    "\n",
    "    # ROI = value saved per customer / cost\n",
    "    # Value saved = avg_CLV Ã— absolute_churn_reduction\n",
    "    value_saved = avg_clv * abs_reduction\n",
    "    roi = value_saved / cost if cost > 0 else 0\n",
    "\n",
    "    CHANNEL_EFFECTIVENESS[variant] = {\n",
    "        'lift': round(rel_lift, 3),      # Store relative lift for display\n",
    "        'abs_reduction': round(abs_reduction, 3),  # Store absolute reduction\n",
    "        'roi': round(roi, 1),\n",
    "        'cost': cost\n",
    "    }\n",
    "    INTERVENTION_ROI[variant] = round(roi, 1)\n",
    "\n",
    "    print(f\"   {variant:<10} {variant_rate:.1%}    {rel_lift:.1%}      {abs_reduction:.1%}    ${value_saved:<8.2f} ${cost:<6.2f}  {roi:.1f}x\")\n",
    "\n",
    "print(f\"\\nâœ… CHANNEL_EFFECTIVENESS and INTERVENTION_ROI calculated from A/B test data\")\n",
    "print(f\"   â€¢ Relative Lift: Used for marketing/executive communication\")\n",
    "print(f\"   â€¢ Absolute Reduction: Used for ROI calculation (value saved per customer)\")\n",
    "print(f\"   â€¢ These values will be used by recommend_intervention() and Dashboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Stored dashboard experiment: exp_intervention_comparison_20251227160844 with variants: ['Control', 'Email', 'Discount', 'Call', 'Combined']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STORE MULTI-VARIANT FOR DASHBOARD\n",
    "# ============================================================\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "if \"multi_variant_results\" not in globals():\n",
    "    raise NameError(\"multi_variant_results is not defined. Run the multi-variant experiment cell first.\")\n",
    "\n",
    "# Create a dashboard-friendly experiment entry (no dependency on variant_configs)\n",
    "dash_exp_id = f\"exp_intervention_comparison_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "variants = list(multi_variant_results.keys())\n",
    "control_rate_for_dash = baseline_rate if \"baseline_rate\" in globals() else multi_variant_results[\"Control\"][\"churn_rate\"]\n",
    "sample_size_for_dash = n_per_variant if \"n_per_variant\" in globals() else multi_variant_results[\"Control\"][\"total\"]\n",
    "\n",
    "ab_manager.experiments[dash_exp_id] = {\n",
    "    \"id\": dash_exp_id,\n",
    "    \"name\": \"intervention_comparison\",\n",
    "    \"intervention_type\": \"Multiple Intervention Types\",\n",
    "    \"variants\": variants,\n",
    "    \"control_rate\": float(control_rate_for_dash),\n",
    "    \"sample_size\": int(sample_size_for_dash),\n",
    "    \"status\": \"complete\",\n",
    "    \"outcomes\": {\n",
    "        k: {\"churned\": int(v[\"churned\"]), \"retained\": int(v[\"retained\"])}\n",
    "        for k, v in multi_variant_results.items()\n",
    "    },\n",
    "    \"participants\": {k: [f\"{k}_{i}\" for i in range(int(sample_size_for_dash))] for k in variants}\n",
    "}\n",
    "\n",
    "print(f\"âœ… Stored dashboard experiment: {dash_exp_id} with variants: {variants}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… DASHBOARD COMPATIBILITY CHECK\n",
      "============================================================\n",
      "\n",
      "ğŸ” Checking ab_manager.results structure...\n",
      "   Number of experiments: 1\n",
      "   Latest experiment: exp_re_engagement_campaign_20251227160844\n",
      "\n",
      "   Required keys present:\n",
      "   âœ… experiment_name\n",
      "   âœ… sample_sizes\n",
      "   âœ… churn_rates\n",
      "   âœ… lift\n",
      "   âœ… statistical_tests\n",
      "   âœ… confidence_interval_95\n",
      "   âœ… conclusion\n",
      "\n",
      "   Sub-structure check:\n",
      "   âœ… churn_rates.control: 0.2044\n",
      "   âœ… churn_rates.treatment: 0.0898\n",
      "   âœ… conclusion.is_significant: True\n",
      "   âœ… statistical_tests.p_value: 0.0\n",
      "\n",
      "ğŸ” Checking multi-variant experiment structure...\n",
      "   Experiment ID: exp_multi_variant_intervention_20251227160844\n",
      "   Variants: ['Control', 'Email', 'Discount', 'Call', 'Combined']\n",
      "\n",
      "   Outcomes by variant:\n",
      "   âœ… Control: 195/900 churned (21.7%)\n",
      "   âœ… Email: 158/900 churned (17.6%)\n",
      "   âœ… Discount: 140/900 churned (15.6%)\n",
      "   âœ… Call: 89/900 churned (9.9%)\n",
      "   âœ… Combined: 135/900 churned (15.0%)\n",
      "\n",
      "âœ… A/B Testing section complete!\n",
      "   The ab_manager object is ready for the Executive Dashboard.\n",
      "   Run Section 5 (Executive Dashboard) next.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# VERIFY DASHBOARD COMPATIBILITY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… DASHBOARD COMPATIBILITY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ” Checking ab_manager.results structure...\")\n",
    "print(f\"   Number of experiments: {len(ab_manager.results)}\")\n",
    "\n",
    "if ab_manager.results:\n",
    "    latest_exp_id = list(ab_manager.results.keys())[-1]\n",
    "    latest_results = ab_manager.results[latest_exp_id]\n",
    "    \n",
    "    required_keys = [\n",
    "        'experiment_name', 'sample_sizes', 'churn_rates', 'lift',\n",
    "        'statistical_tests', 'confidence_interval_95', 'conclusion'\n",
    "    ]\n",
    "    \n",
    "    print(f\"   Latest experiment: {latest_exp_id}\")\n",
    "    print(f\"\\n   Required keys present:\")\n",
    "    for key in required_keys:\n",
    "        present = key in latest_results\n",
    "        print(f\"   {'âœ…' if present else 'âŒ'} {key}\")\n",
    "    \n",
    "    print(f\"\\n   Sub-structure check:\")\n",
    "    print(f\"   âœ… churn_rates.control: {latest_results['churn_rates']['control']}\")\n",
    "    print(f\"   âœ… churn_rates.treatment: {latest_results['churn_rates']['treatment']}\")\n",
    "    print(f\"   âœ… conclusion.is_significant: {latest_results['conclusion']['is_significant']}\")\n",
    "    print(f\"   âœ… statistical_tests.p_value: {latest_results['statistical_tests']['p_value']}\")\n",
    "\n",
    "print(f\"\\nğŸ” Checking multi-variant experiment structure...\")\n",
    "print(f\"   Experiment ID: {multi_exp_id}\")\n",
    "print(f\"   Variants: {ab_manager.experiments[multi_exp_id]['variants']}\")\n",
    "print(f\"\\n   Outcomes by variant:\")\n",
    "for variant in ['Control', 'Email', 'Discount', 'Call', 'Combined']:\n",
    "    outcomes = ab_manager.experiments[multi_exp_id][\"outcomes\"].get(variant, {})\n",
    "    if outcomes:\n",
    "        total = outcomes['churned'] + outcomes['retained']\n",
    "        rate = outcomes['churned'] / total if total > 0 else 0\n",
    "        print(f\"   âœ… {variant}: {outcomes['churned']}/{total} churned ({rate:.1%})\")\n",
    "\n",
    "print(f\"\\nâœ… A/B Testing section complete!\")\n",
    "print(f\"   The ab_manager object is ready for the Executive Dashboard.\")\n",
    "print(f\"   Run Section 5 (Executive Dashboard) next.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: ADK Imports & Tool Definitions\n",
    "\n",
    "Using ADK v1.0.0+ API with correct imports and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GenAI Vertex AI client created (project=sunlit-gamma-342416)\n",
      "âœ… ADK imports successful\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CORE IMPORTS FOR ADK v1.0.0+\n",
    "# ============================================================\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('ChurnPreventionAgents')\n",
    "\n",
    "ADK_AVAILABLE = True\n",
    "genai_client = None\n",
    "\n",
    "try:\n",
    "    # ---------------------------\n",
    "    # Configure google-genai for Vertex AI\n",
    "    # ---------------------------\n",
    "    from google import genai\n",
    "    \n",
    "    PROJECT = globals().get(\"PROJECT_ID\", os.getenv(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "    LOCATION = globals().get(\"REGION\", os.getenv(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\"))\n",
    "    \n",
    "    # Create client configured for Vertex AI\n",
    "    genai_client = genai.Client(\n",
    "        vertexai=True,\n",
    "        project=PROJECT,\n",
    "        location=LOCATION\n",
    "    )\n",
    "    print(f\"âœ… GenAI Vertex AI client created (project={PROJECT})\")\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Import ADK components\n",
    "    # ---------------------------\n",
    "    from google.adk.agents import (\n",
    "        Agent,\n",
    "        SequentialAgent,\n",
    "        ParallelAgent,\n",
    "        LoopAgent\n",
    "    )\n",
    "    from google.adk.code_executors import BuiltInCodeExecutor\n",
    "    from google.adk.sessions import InMemorySessionService\n",
    "    from google.adk.runners import Runner\n",
    "    from google.genai import types as genai_types\n",
    "\n",
    "    print(\"âœ… ADK imports successful\")\n",
    "\n",
    "except ImportError as e:\n",
    "    ADK_AVAILABLE = False\n",
    "    print(f\"âš ï¸ ADK/GenAI imports not available: {e}\")\n",
    "    print(\"   Install with: pip install google-adk google-genai\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Warning: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tool functions loaded (using ML model predictions)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CUSTOM TOOL FUNCTIONS\n",
    "# ============================================================\n",
    "# In ADK v1.0.0+, pass functions directly to agents\n",
    "# These tools use the ML MODEL PREDICTIONS, not hardcoded formulas\n",
    "# ============================================================\n",
    "\n",
    "from typing import Dict, Any, List\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "DATA_PATH = Path(CONFIG['paths']['customer_csv'])\n",
    "\n",
    "# Schema: Now includes model predictions\n",
    "REQUIRED_COLS = {\n",
    "    \"customer_id\", \"tenure_months\", \"monthly_charges\", \"login_frequency_monthly\",\n",
    "    \"feature_usage_pct\", \"support_tickets_90d\", \"payment_delays_12m\", \"discount_count\",\n",
    "    \"nps_score\", \"email_open_rate\", \"last_activity_days\", \"engagement_score\",\n",
    "    \"risk_score_baseline\", \"clv_estimate\", \"churned\",\n",
    "    \"churn_probability\",           # FROM ML MODEL\n",
    "    \"predicted_days_until_churn\",  # FROM SURVIVAL MODEL\n",
    "    \"risk_tier\"                    # DERIVED FROM churn_probability\n",
    "}\n",
    "\n",
    "def load_customer_df() -> pd.DataFrame:\n",
    "    \"\"\"Load the customer dataset and validate schema.\"\"\"\n",
    "    if not DATA_PATH.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing data file: {DATA_PATH}. Run data preparation cells first.\"\n",
    "        )\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    \n",
    "    # Check for required columns (warn but don't fail for optional ones)\n",
    "    missing = REQUIRED_COLS - set(df.columns)\n",
    "    critical_missing = {\"customer_id\", \"churned\", \"churn_probability\"} & missing\n",
    "    if critical_missing:\n",
    "        raise ValueError(f\"Critical columns missing: {sorted(critical_missing)}\")\n",
    "    if missing:\n",
    "        logger.warning(f\"Optional columns missing: {sorted(missing)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_customer_row(df: pd.DataFrame, customer_id: str) -> pd.Series:\n",
    "    \"\"\"Return a single customer row or raise helpful error.\"\"\"\n",
    "    match = df.loc[df[\"customer_id\"] == customer_id]\n",
    "    if match.empty:\n",
    "        raise ValueError(f\"Customer {customer_id} not found\")\n",
    "    return match.iloc[0]\n",
    "\n",
    "\n",
    "def calculate_churn_score(customer_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Return model-aligned churn predictions for a single customer.\n",
    "\n",
    "    This tool intentionally uses the notebook's MODEL-PREDICTED fields:\n",
    "    - churn_probability: Logistic Regression model\n",
    "    - predicted_days_until_churn: Cox PH survival model (or heuristic fallback)\n",
    "\n",
    "    It also attaches a timing recommendation based on SURVIVAL_INTERVENTION_STATS\n",
    "    (derived from the survival model outputs).\n",
    "\n",
    "    Args:\n",
    "        customer_id: Unique customer identifier (e.g., CUST_000001)\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with churn_probability, risk_tier, predicted_days_until_churn,\n",
    "        standardized risk_factors, and a timing/scheduling recommendation.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Retrieving churn prediction for {customer_id}\")\n",
    "\n",
    "    df = load_customer_df()\n",
    "    customer = df[df[\"customer_id\"] == customer_id]\n",
    "\n",
    "    if customer.empty:\n",
    "        return {\"error\": f\"Customer not found: {customer_id}\"}\n",
    "\n",
    "    c = customer.iloc[0]\n",
    "\n",
    "    churn_prob = float(c.get(\"churn_probability\", 0.0))\n",
    "    risk_tier = str(c.get(\"risk_tier\", \"Unknown\"))\n",
    "\n",
    "    # predicted_days_until_churn can be missing if survival step was skipped\n",
    "    predicted_days_until_churn = None\n",
    "    pdays = c.get(\"predicted_days_until_churn\", None)\n",
    "    if pdays is not None and str(pdays) != \"nan\":\n",
    "        try:\n",
    "            predicted_days_until_churn = int(pdays)\n",
    "        except Exception:\n",
    "            predicted_days_until_churn = None\n",
    "\n",
    "    # Standardized risk factors (keeps names aligned with recommend_intervention mappings)\n",
    "    risk_factors: List[str] = []\n",
    "    risk_context: Dict[str, Any] = {}\n",
    "\n",
    "    if int(c.get(\"has_payment_issues\", 0)) == 1:\n",
    "        risk_factors.append(\"Payment issues detected\")\n",
    "    if int(c.get('payment_delays_12m', 0)) > CONFIG['feature_thresholds']['payment_delays_high']:\n",
    "        risk_factors.append(\"Multiple payment delays\")\n",
    "        risk_context[\"payment_delays_12m\"] = int(c.get(\"payment_delays_12m\", 0))\n",
    "    if int(c.get(\"is_heavy_support_user\", 0)) == 1:\n",
    "        risk_factors.append(\"High support ticket volume\")\n",
    "    if int(c.get(\"is_inactive\", 0)) == 1:\n",
    "        risk_factors.append(\"Product inactivity (>14 days)\")\n",
    "    if float(c.get('nps_score', 10)) < CONFIG['feature_thresholds']['nps_low']:\n",
    "        risk_factors.append(\"Low NPS score\")\n",
    "        risk_context[\"nps_score\"] = float(c.get(\"nps_score\", 0))\n",
    "    if float(c.get('engagement_score', 100)) < CONFIG['feature_thresholds']['engagement_low']:\n",
    "        risk_factors.append(\"Low engagement\")\n",
    "        risk_context[\"engagement_score\"] = float(c.get(\"engagement_score\", 0))\n",
    "\n",
    "    # Timing recommendation (days-until-churn space)\n",
    "    stats = globals().get(\"SURVIVAL_INTERVENTION_STATS\", None)\n",
    "    if stats:\n",
    "        window_start = int(stats.get(\"window_start\", 20))\n",
    "        window_optimal = int(stats.get(\"window_optimal\", (window_start + int(stats.get(\"window_end\", 60))) // 2))\n",
    "        window_end = int(stats.get(\"window_end\", 60))\n",
    "        window_source = str(stats.get(\"source\", \"SURVIVAL_INTERVENTION_STATS\"))\n",
    "    else:\n",
    "        window_start, window_optimal, window_end = 20, 45, 60\n",
    "        window_source = \"default\"\n",
    "\n",
    "    timing_bucket = \"unknown\"\n",
    "    schedule_start_in_days = None\n",
    "    schedule_end_in_days = None\n",
    "\n",
    "    if predicted_days_until_churn is not None:\n",
    "        pd = int(predicted_days_until_churn)\n",
    "        if pd < window_start:\n",
    "            timing_bucket = \"too_late\"\n",
    "        elif pd <= window_end:\n",
    "            timing_bucket = \"optimal\"\n",
    "        else:\n",
    "            timing_bucket = \"too_early\"\n",
    "\n",
    "        # When should we start/end outreach relative to today?\n",
    "        schedule_start_in_days = max(0, pd - window_end)\n",
    "        schedule_end_in_days = max(0, pd - window_start)\n",
    "\n",
    "    return {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"churn_probability\": round(churn_prob, 4),\n",
    "        \"risk_tier\": risk_tier,\n",
    "        \"predicted_days_until_churn\": predicted_days_until_churn,\n",
    "        \"key_risk_factors\": risk_factors if risk_factors else [\"No major risk factors identified\"],\n",
    "        \"risk_context\": risk_context,\n",
    "        \"timing_bucket\": timing_bucket,\n",
    "        \"intervention_window\": {\n",
    "            \"window_start_days\": window_start,\n",
    "            \"window_optimal_days\": window_optimal,\n",
    "            \"window_end_days\": window_end,\n",
    "            \"source\": window_source,\n",
    "        },\n",
    "        \"recommended_outreach_schedule\": {\n",
    "            \"start_in_days\": schedule_start_in_days,\n",
    "            \"end_in_days\": schedule_end_in_days,\n",
    "        },\n",
    "        \"clv_at_risk\": round(float(c.get(\"clv_estimate\", 0.0)), 2),\n",
    "        \"model_source\": {\n",
    "            \"churn_probability\": \"Logistic Regression (trained)\",\n",
    "            \"predicted_days_until_churn\": \"Cox PH survival model (or heuristic fallback if lifelines unavailable)\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… Tool functions loaded (using ML model predictions)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_intervention(\n",
    "    customer_id: str,\n",
    "    churn_probability: Optional[float] = None,\n",
    "    predicted_days_until_churn: Optional[int] = None,\n",
    "    risk_factors: Optional[List[str]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate personalized retention intervention recommendation.\n",
    "    \n",
    "    ALIGNED WITH A/B TEST VARIANTS:\n",
    "    - Email:    Automated email campaigns (high ROI, scalable)\n",
    "    - Discount: Discount offers (medium ROI, effective for price-sensitive)\n",
    "    - Call:     Personal phone calls (lower ROI, high-touch for VIPs)\n",
    "    - Combined: Multi-channel approach (for critical risk customers)\n",
    "    \n",
    "    The recommendation is based on:\n",
    "    1. Customer's risk factors (what problem to solve)\n",
    "    2. Customer's value tier (how much to invest)\n",
    "    3. Churn probability (urgency level)\n",
    "    \n",
    "    Args:\n",
    "        customer_id: Customer identifier\n",
    "        churn_probability: Predicted churn probability (0-1)\n",
    "        risk_factors: List of identified risk factors\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with intervention_channel, intervention_action, priority, expected_lift, roi_estimate\n",
    "    \"\"\"\n",
    "\n",
    "    # Backward-compatible argument handling:\n",
    "    # Some notebook cells call recommend_intervention(customer_id, churn_probability, risk_factors)\n",
    "    # which passes the risk_factors list into predicted_days_until_churn position.\n",
    "    if isinstance(predicted_days_until_churn, (list, tuple)) and risk_factors is None:\n",
    "        risk_factors = list(predicted_days_until_churn)\n",
    "        predicted_days_until_churn = None\n",
    "    # Guard: handle accidental positional calls where risk_factors was passed as the 3rd argument\n",
    "    if isinstance(predicted_days_until_churn, list) and risk_factors is None:\n",
    "        risk_factors = predicted_days_until_churn\n",
    "        predicted_days_until_churn = None\n",
    "\n",
    "    # Safe normalization for predicted_days_until_churn (may be str/float/int)\n",
    "    pdays: Optional[int] = None\n",
    "    if predicted_days_until_churn is not None:\n",
    "        try:\n",
    "            pdays = int(float(predicted_days_until_churn))\n",
    "        except (TypeError, ValueError):\n",
    "            pdays = None\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Align inputs with model outputs\n",
    "    # If the caller does not provide churn_probability / timing / risk_factors,\n",
    "    # fetch them from the scored dataset produced by the ML + survival steps.\n",
    "    # ----------------------------------------------------------------\n",
    "    df = load_customer_df()\n",
    "    row = df[df[\"customer_id\"] == customer_id]\n",
    "    if row.empty:\n",
    "        return {\"error\": f\"Customer not found: {customer_id}\"}\n",
    "\n",
    "    c = row.iloc[0]\n",
    "\n",
    "    INACTIVITY_DAYS = int(CONFIG['feature_thresholds']['inactivity_days'])\n",
    "    INACTIVITY_LABEL = f\"Product inactivity (>{INACTIVITY_DAYS} days)\"\n",
    "\n",
    "    if churn_probability is None:\n",
    "        churn_probability = float(c.get(\"churn_probability\", 0.0))\n",
    "    if predicted_days_until_churn is None:\n",
    "        pdays = c.get(\"predicted_days_until_churn\", None)\n",
    "        predicted_days_until_churn = int(pdays) if pdays is not None and str(pdays) != \"nan\" else None\n",
    "\n",
    "    if risk_factors is None:\n",
    "        # Standardized factors (keeps names aligned with channel mappings)\n",
    "        risk_factors = []\n",
    "        if int(c.get(\"has_payment_issues\", 0)) == 1:\n",
    "            risk_factors.append(\"Payment issues detected\")\n",
    "        if int(c.get('payment_delays_12m', 0)) > CONFIG['feature_thresholds']['payment_delays_high']:\n",
    "            risk_factors.append(\"Multiple payment delays\")\n",
    "        if int(c.get(\"is_heavy_support_user\", 0)) == 1:\n",
    "            risk_factors.append(\"High support ticket volume\")\n",
    "        if int(c.get(\"is_inactive\", 0)) == 1:\n",
    "            risk_factors.append(INACTIVITY_LABEL)\n",
    "        if float(c.get('nps_score', 10)) < CONFIG['feature_thresholds']['nps_low']:\n",
    "            risk_factors.append(\"Low NPS score\")\n",
    "        if float(c.get('engagement_score', 100)) < CONFIG['feature_thresholds']['engagement_low']:\n",
    "            risk_factors.append(\"Low engagement\")\n",
    "\n",
    "    tier = str(c.get(\"subscription_tier\", \"Standard\"))\n",
    "    clv = float(c.get(\"clv_estimate\", 0.0))\n",
    "    is_high_value = bool(c.get(\"is_high_value\", False))\n",
    "\n",
    "    # Timing: use survival-derived window (in days-until-churn space)\n",
    "    stats = globals().get(\"SURVIVAL_INTERVENTION_STATS\", None)\n",
    "    if stats:\n",
    "        window_start = int(stats.get(\"window_start\", 20))\n",
    "        window_optimal = int(stats.get(\"window_optimal\", (window_start + int(stats.get(\"window_end\", 60))) // 2))\n",
    "        window_end = int(stats.get(\"window_end\", 60))\n",
    "        window_source = str(stats.get(\"source\", \"SURVIVAL_INTERVENTION_STATS\"))\n",
    "    else:\n",
    "        window_start, window_optimal, window_end = 20, 45, 60\n",
    "        window_source = \"default\"\n",
    "\n",
    "    timing_bucket = \"unknown\"\n",
    "    schedule_start_in_days = None\n",
    "    schedule_end_in_days = None\n",
    "\n",
    "    if pdays is not None:\n",
    "        if pdays < window_start:\n",
    "            timing_bucket = \"too_late\"\n",
    "        elif pdays <= window_end:\n",
    "            timing_bucket = \"optimal\"\n",
    "        else:\n",
    "            timing_bucket = \"too_early\"\n",
    "\n",
    "        schedule_start_in_days = max(0, pdays - window_end)\n",
    "        schedule_end_in_days = max(0, pdays - window_start)\n",
    "\n",
    "\n",
    "    logger.info(f\"Generating intervention for {customer_id}\")\n",
    "    \n",
    "    df = load_customer_df()\n",
    "    customer = df[df['customer_id'] == customer_id]\n",
    "    \n",
    "    if customer.empty:\n",
    "        return {\"error\": f\"Customer {customer_id} not found\"}\n",
    "    \n",
    "    c = customer.iloc[0]\n",
    "    clv = c['clv_estimate']\n",
    "    tier = c['subscription_tier']\n",
    "    is_high_value = tier in ['Premium', 'Enterprise'] or clv > CONFIG['feature_thresholds']['high_value_clv']\n",
    "    \n",
    "    # ================================================================\n",
    "    # INTERVENTION CHANNEL SELECTION\n",
    "    # Aligned with A/B test variants: Email, Discount, Call, Combined\n",
    "    # ================================================================\n",
    "    \n",
    "    # Channel effectiveness from A/B test results (calculated in Section 5)\n",
    "    # CHANNEL_EFFECTIVENESS is set by the A/B Testing section (Section 5) which should run after Local Testing\n",
    "    if 'CHANNEL_EFFECTIVENESS' not in globals() or not globals()['CHANNEL_EFFECTIVENESS']:\n",
    "        raise ValueError(\n",
    "            \"âŒ CHANNEL_EFFECTIVENESS not found. \"\n",
    "            \"Please run Section 5 (A/B Testing Framework) first.\"\n",
    "        )\n",
    "    \n",
    "    CHANNEL_EFFECTIVENESS = globals()['CHANNEL_EFFECTIVENESS']\n",
    "    \n",
    "    # Risk factor to intervention mapping\n",
    "    # Maps what problem to solve â†’ best channel to use\n",
    "    RISK_FACTOR_CHANNEL = {\n",
    "        \"Payment issues detected\": \"Discount\",           # Price sensitivity â†’ offer discount\n",
    "        \"Multiple payment delays\": \"Discount\",           # Payment problems â†’ flexible pricing\n",
    "        \"High support ticket volume\": \"Call\",            # Complex issues â†’ personal touch\n",
    "        INACTIVITY_LABEL: \"Email\",        # Re-engagement â†’ automated campaign\n",
    "        \"Product inactivity\": \"Email\",                   # Re-engagement â†’ automated campaign\n",
    "        \"Low NPS score\": \"Call\",                         # Dissatisfaction â†’ personal outreach\n",
    "        \"Low satisfaction score\": \"Call\",                # Dissatisfaction â†’ personal outreach\n",
    "        \"Low engagement\": \"Email\",                       # Feature adoption â†’ email series\n",
    "    }\n",
    "    \n",
    "    # Specific action based on risk factor\n",
    "    RISK_FACTOR_ACTION = {\n",
    "        \"Payment issues detected\": \"Flexible payment plan offer\",\n",
    "        \"Multiple payment delays\": \"Payment restructuring consultation\",\n",
    "        \"High support ticket volume\": \"Dedicated success manager assignment\",\n",
    "        INACTIVITY_LABEL: \"Re-engagement email series with training\",\n",
    "        \"Product inactivity\": \"Feature highlight email campaign\",\n",
    "        \"Low NPS score\": \"Executive outreach call with service recovery\",\n",
    "        \"Low satisfaction score\": \"Personal check-in call with credit offer\",\n",
    "        \"Low engagement\": \"Personalized feature adoption email program\",\n",
    "    }\n",
    "    \n",
    "    # ================================================================\n",
    "    # SELECT INTERVENTION CHANNEL\n",
    "    # ================================================================\n",
    "    \n",
    "    # Default channel based on customer value\n",
    "    if is_high_value:\n",
    "        default_channel = \"Call\"  # High-touch for valuable customers\n",
    "    else:\n",
    "        default_channel = \"Email\"  # Scalable for standard customers\n",
    "    \n",
    "    # Override based on risk factors\n",
    "    selected_channel = default_channel\n",
    "    selected_action = \"Proactive retention outreach\"\n",
    "    \n",
    "    if risk_factors and risk_factors[0] not in [\"No major risk factors\", \"No major risk factors identified\"]:\n",
    "        primary_risk = risk_factors[0]\n",
    "        selected_channel = RISK_FACTOR_CHANNEL.get(primary_risk, default_channel)\n",
    "        selected_action = RISK_FACTOR_ACTION.get(primary_risk, \"Targeted retention outreach\")\n",
    "    \n",
    "    # Escalate to Combined for critical cases\n",
    "    if churn_probability >= CONFIG['risk_tiers']['cutoffs']['critical']:\n",
    "        if is_high_value or len(risk_factors) > 2:\n",
    "            selected_channel = \"Combined\"\n",
    "            selected_action = \"Multi-channel urgent retention campaign\"\n",
    "    \n",
    "    # ================================================================\n",
    "    # CALCULATE EXPECTED IMPACT\n",
    "    # ================================================================\n",
    "    channel_data = CHANNEL_EFFECTIVENESS[selected_channel]\n",
    "    \n",
    "    # Adjust lift based on customer tier\n",
    "    tier_multiplier = {\n",
    "        'Basic': 0.8,\n",
    "        'Standard': 1.0,\n",
    "        'Premium': 1.2,\n",
    "        'Enterprise': 1.4\n",
    "    }.get(tier, 1.0)\n",
    "    \n",
    "    expected_lift = channel_data['lift'] * tier_multiplier\n",
    "    intervention_cost = channel_data['cost']\n",
    "    \n",
    "    # Calculate ROI\n",
    "    value_at_risk = clv * churn_probability\n",
    "    value_saved = value_at_risk * expected_lift\n",
    "    roi = value_saved / max(intervention_cost, 1)\n",
    "    \n",
    "    # ================================================================\n",
    "    # DETERMINE PRIORITY\n",
    "    # ================================================================\n",
    "    if churn_probability >= CONFIG['risk_tiers']['cutoffs']['critical'] and clv > CONFIG['feature_thresholds']['high_value_clv']:\n",
    "        priority = 1  # Critical - immediate action\n",
    "    elif churn_probability >= CONFIG['risk_tiers']['cutoffs']['high'] or clv > CONFIG['feature_thresholds']['mid_value_clv']:\n",
    "        priority = 2  # High - action within 24h\n",
    "    elif churn_probability >= CONFIG['risk_tiers']['cutoffs']['medium']:\n",
    "        priority = 3  # Medium - action within week\n",
    "    else:\n",
    "        priority = 4  # Low - scheduled outreach\n",
    "    \n",
    "    return {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"predicted_days_until_churn\": predicted_days_until_churn,\n",
    "        \"timing_bucket\": timing_bucket,\n",
    "        \"intervention_window\": {\n",
    "            \"window_start_days\": window_start,\n",
    "            \"window_optimal_days\": window_optimal,\n",
    "            \"window_end_days\": window_end,\n",
    "            \"source\": window_source,\n",
    "        },\n",
    "        \"recommended_outreach_schedule\": {\n",
    "            \"start_in_days\": schedule_start_in_days,\n",
    "            \"end_in_days\": schedule_end_in_days,\n",
    "        },\n",
    "        \"intervention_channel\": selected_channel,  # Aligned with A/B variants\n",
    "        \"intervention_action\": selected_action,    # Specific action to take\n",
    "        \"priority\": priority,\n",
    "        \"priority_label\": {1: \"Critical\", 2: \"High\", 3: \"Medium\", 4: \"Low\"}[priority],\n",
    "        \"expected_lift\": round(expected_lift, 3),\n",
    "        \"intervention_cost\": round(intervention_cost, 2),\n",
    "        \"roi_estimate\": round(roi, 1),\n",
    "        \"value_at_risk\": round(value_at_risk, 2),\n",
    "        \"value_if_saved\": round(value_saved, 2),\n",
    "        \"risk_factors_addressed\": risk_factors[:3] if risk_factors else [],\n",
    "        \"channel_source\": \"A/B Test Results\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_behavior(customer_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieve comprehensive behavioral summary for a customer.\n",
    "    \n",
    "    Args:\n",
    "        customer_id: Unique customer identifier\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with profile, engagement, health_indicators, and risk_flags\n",
    "    \"\"\"\n",
    "    logger.info(f\"Fetching behavior data for {customer_id}\")\n",
    "    \n",
    "    df = load_customer_df()\n",
    "    customer = df[df['customer_id'] == customer_id]\n",
    "    \n",
    "    if customer.empty:\n",
    "        return {\"error\": f\"Customer {customer_id} not found\"}\n",
    "    \n",
    "    c = customer.iloc[0]\n",
    "    \n",
    "    return {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"profile\": {\n",
    "            \"tenure_months\": int(c['tenure_months']),\n",
    "            \"subscription_tier\": c['subscription_tier'],\n",
    "            \"monthly_charges\": float(c['monthly_charges']),\n",
    "            \"clv_estimate\": float(c['clv_estimate'])\n",
    "        },\n",
    "        \"engagement\": {\n",
    "            \"login_frequency_monthly\": int(c['login_frequency_monthly']),\n",
    "            \"feature_usage_pct\": float(c['feature_usage_pct']),\n",
    "            \"email_open_rate\": float(c['email_open_rate']),\n",
    "            \"last_activity_days\": int(c['last_activity_days']),\n",
    "            \"engagement_score\": round(float(c['engagement_score']), 2)\n",
    "        },\n",
    "        \"health_indicators\": {\n",
    "            \"nps_score\": int(c['nps_score']),\n",
    "            \"support_tickets_90d\": int(c['support_tickets_90d']),\n",
    "            \"payment_delays_12m\": int(c['payment_delays_12m'])\n",
    "        },\n",
    "        \"risk_flags\": {\n",
    "            \"is_high_value\": bool(c['is_high_value']),\n",
    "            \"has_payment_issues\": bool(c['has_payment_issues']),\n",
    "            \"is_heavy_support_user\": bool(c['is_heavy_support_user']),\n",
    "            \"is_inactive\": bool(c['is_inactive'])\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_survival_analysis(risk_tier: str = \"all\") -> Dict[str, Any]:\n",
    "    \"\"\"Cohort-level churn timing analysis aligned with the notebook's survival model.\n",
    "\n",
    "    This tool is used by evaluation/monitoring agents to answer:\n",
    "    - How quickly do customers churn (by cohort/risk tier)?\n",
    "    - What is the median time-to-churn (days) and retention at key horizons?\n",
    "    - What intervention window should we use?\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - If lifelines is available AND the dataset contains observed survival labels\n",
    "      (duration_days + event_observed), we run a Kaplan-Meier analysis.\n",
    "    - Otherwise, we fall back to descriptive stats on predicted_days_until_churn.\n",
    "\n",
    "    Args:\n",
    "        risk_tier: One of {\"Low\",\"Medium\",\"High\",\"Critical\",\"all\"}.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with survival/timing statistics.\n",
    "    \"\"\"\n",
    "    df = load_customer_df().copy()\n",
    "\n",
    "    if risk_tier.lower() != \"all\":\n",
    "        df = df[df[\"risk_tier\"].str.lower() == risk_tier.lower()].copy()\n",
    "\n",
    "    stats = globals().get(\"SURVIVAL_INTERVENTION_STATS\", None)\n",
    "\n",
    "    # Prefer observed survival labels if present (for KM)\n",
    "    has_observed = (\"duration_days\" in df.columns) and (\"event_observed\" in df.columns)\n",
    "    lifelines_ok = \"KaplanMeierFitter\" in globals() and globals().get(\"KaplanMeierFitter\") is not None\n",
    "\n",
    "    if has_observed and lifelines_ok:\n",
    "        T = df[\"duration_days\"].astype(float)\n",
    "        E = df[\"event_observed\"].astype(int)\n",
    "\n",
    "        kmf = KaplanMeierFitter()\n",
    "        kmf.fit(T, E, label=f\"{risk_tier.title()} cohort\" if risk_tier.lower() != \"all\" else \"Overall cohort\")\n",
    "\n",
    "        median_survival = kmf.median_survival_time_\n",
    "        retention = {}\n",
    "        for d in [30, 60, 90, 120]:\n",
    "            try:\n",
    "                retention[str(d)] = float(kmf.survival_function_at_times(d).values[0])\n",
    "            except Exception:\n",
    "                retention[str(d)] = None\n",
    "\n",
    "        return {\n",
    "            \"analysis_type\": \"Kaplan-Meier (observed duration)\",\n",
    "            \"risk_tier\": risk_tier,\n",
    "            \"sample_size\": int(len(df)),\n",
    "            \"event_rate\": float(E.mean()) if len(E) else None,\n",
    "            \"median_survival_days\": float(median_survival) if median_survival is not None and not np.isinf(median_survival) else None,\n",
    "            \"retention_probability\": retention,\n",
    "            \"intervention_window\": stats,\n",
    "        }\n",
    "\n",
    "    # Fallback: summarize predicted timing (still useful for agent decisions)\n",
    "    p = df.get(\"predicted_days_until_churn\", pd.Series(dtype=float)).dropna()\n",
    "    return {\n",
    "        \"analysis_type\": \"Descriptive stats (predicted days until churn)\",\n",
    "        \"risk_tier\": risk_tier,\n",
    "        \"sample_size\": int(len(df)),\n",
    "        \"predicted_days_summary\": {\n",
    "            \"min\": float(p.min()) if len(p) else None,\n",
    "            \"p25\": float(p.quantile(0.25)) if len(p) else None,\n",
    "            \"median\": float(p.median()) if len(p) else None,\n",
    "            \"p75\": float(p.quantile(0.75)) if len(p) else None,\n",
    "            \"max\": float(p.max()) if len(p) else None,\n",
    "        },\n",
    "        \"intervention_window\": stats,\n",
    "        \"note\": \"Kaplan-Meier skipped (missing lifelines or observed survival labels).\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Custom tool functions defined\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "def list_at_risk_customers(min_probability: float = 0.5, limit: int = 10) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get prioritized list of customers above a churn probability threshold.\n",
    "    \n",
    "    Args:\n",
    "        min_probability: Minimum churn probability threshold (0-1)\n",
    "        limit: Maximum number of customers to return\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with threshold, count, total_clv_at_risk, and customer list\n",
    "    \"\"\"\n",
    "    logger.info(f\"Listing at-risk customers (prob >= {min_probability})\")\n",
    "    \n",
    "    df = load_customer_df()\n",
    "    at_risk = df[df['churn_probability'] >= min_probability].copy()\n",
    "    at_risk['expected_value_at_risk'] = at_risk['clv_estimate'] * at_risk['churn_probability']\n",
    "\n",
    "    # Rank by business impact first, then urgency (sooner predicted churn)\n",
    "    if 'predicted_days_until_churn' in at_risk.columns:\n",
    "        at_risk['_urgency_days'] = pd.to_numeric(at_risk['predicted_days_until_churn'], errors='coerce').fillna(10**9)\n",
    "        at_risk = at_risk.sort_values(['expected_value_at_risk', '_urgency_days'], ascending=[False, True]).head(limit)\n",
    "        at_risk = at_risk.drop(columns=['_urgency_days'])\n",
    "    else:\n",
    "        at_risk = at_risk.sort_values(['expected_value_at_risk'], ascending=[False]).head(limit)\n",
    "    \n",
    "    customers = []\n",
    "    for _, row in at_risk.iterrows():\n",
    "        customers.append({\n",
    "            \"customer_id\": row['customer_id'],\n",
    "            \"churn_probability\": float(row['churn_probability']),\n",
    "            \"subscription_tier\": row['subscription_tier'],\n",
    "            \"clv_estimate\": float(row['clv_estimate']),\n",
    "            \"predicted_days_until_churn\": int(row['predicted_days_until_churn']) if pd.notna(row.get('predicted_days_until_churn', None)) else None,\n",
    "            \"expected_value_at_risk\": float(row['expected_value_at_risk']) if pd.notna(row.get('expected_value_at_risk', None)) else float(row['clv_estimate'] * row['churn_probability'])\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"threshold\": min_probability,\n",
    "        \"count\": len(customers),\n",
    "        \"total_clv_at_risk\": float(at_risk['clv_estimate'].sum()),\n",
    "        \"total_expected_value_at_risk\": float(at_risk['expected_value_at_risk'].sum()) if \"expected_value_at_risk\" in at_risk.columns else float((at_risk['clv_estimate'] * at_risk['churn_probability']).sum()),\n",
    "        \"intervention_window\": globals().get(\"SURVIVAL_INTERVENTION_STATS\", None),\n",
    "        \"customers\": customers\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… Custom tool functions defined\")\n",
    "\n",
    "\n",
    "def get_customer_base_metrics() -> Dict[str, Any]:\n",
    "    \"\"\"Return customer-base KPIs (population-level), including overall churn rate.\n",
    "\n",
    "    This is the correct tool for questions like:\n",
    "    - \"What's the overall churn rate in our customer base?\"\n",
    "    - \"How many customers have churned?\"\n",
    "    - \"What is the average churn probability?\"\n",
    "    - \"What is the distribution of risk tiers?\"\n",
    "\n",
    "    Notes:\n",
    "    - Uses the observed label `churned` if available.\n",
    "    - Falls back to the mean of `churn_probability` if `churned` is missing.\n",
    "    \"\"\"\n",
    "    logger.info(\"Computing customer-base KPIs (overall churn rate, distributions)\")\n",
    "\n",
    "    df = load_customer_df()\n",
    "    n_customers = int(len(df))\n",
    "    if n_customers == 0:\n",
    "        return {\n",
    "            \"total_customers\": 0,\n",
    "            \"overall_churn_rate\": None,\n",
    "            \"churned_customers\": 0,\n",
    "            \"avg_churn_probability\": None,\n",
    "            \"risk_tier_distribution\": {},\n",
    "            \"note\": \"No customers found in the current dataset.\"\n",
    "        }\n",
    "\n",
    "    # Overall churn rate (prefer observed label)\n",
    "    churned_customers = None\n",
    "    overall_churn_rate = None\n",
    "    if \"churned\" in df.columns:\n",
    "        churned_series = pd.to_numeric(df[\"churned\"], errors=\"coerce\").fillna(0)\n",
    "        churned_series = churned_series.astype(float).clip(0, 1)\n",
    "        churned_customers = int(round(float(churned_series.sum())))\n",
    "        overall_churn_rate = float(churned_series.mean())\n",
    "    elif \"churn_probability\" in df.columns:\n",
    "        prob = pd.to_numeric(df[\"churn_probability\"], errors=\"coerce\")\n",
    "        overall_churn_rate = float(prob.mean())\n",
    "\n",
    "    # Average predicted churn probability (if present)\n",
    "    avg_prob = None\n",
    "    if \"churn_probability\" in df.columns:\n",
    "        prob = pd.to_numeric(df[\"churn_probability\"], errors=\"coerce\")\n",
    "        avg_prob = float(prob.mean())\n",
    "\n",
    "    # Risk tier distribution (if present; else derive from CONFIG thresholds)\n",
    "    risk_dist = {}\n",
    "    if \"risk_tier\" in df.columns:\n",
    "        risk_dist = df[\"risk_tier\"].fillna(\"unknown\").value_counts().to_dict()\n",
    "    elif \"churn_probability\" in df.columns:\n",
    "        cutoffs = CONFIG[\"risk_tiers\"][\"cutoffs\"]\n",
    "        prob = pd.to_numeric(df[\"churn_probability\"], errors=\"coerce\").fillna(0).clip(0, 1)\n",
    "        tier = pd.Series(\"low\", index=prob.index)\n",
    "        tier = tier.mask(prob >= cutoffs[\"medium\"], \"medium\")\n",
    "        tier = tier.mask(prob >= cutoffs[\"high\"], \"high\")\n",
    "        tier = tier.mask(prob >= cutoffs[\"critical\"], \"critical\")\n",
    "        risk_dist = tier.value_counts().to_dict()\n",
    "\n",
    "    return {\n",
    "        \"total_customers\": n_customers,\n",
    "        \"overall_churn_rate\": None if overall_churn_rate is None else round(float(overall_churn_rate), 4),\n",
    "        \"churned_customers\": churned_customers,\n",
    "        \"avg_churn_probability\": None if avg_prob is None else round(float(avg_prob), 4),\n",
    "        \"risk_tier_distribution\": risk_dist,\n",
    "        \"label_source\": \"observed_churned\" if \"churned\" in df.columns else \"estimated_from_probability\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:08:45,026 | __main__ | INFO | Retrieving churn prediction for CUST_000001\n",
      "2025-12-27 16:08:45,045 | __main__ | INFO | Generating intervention for CUST_000001\n",
      "2025-12-27 16:08:45,053 | __main__ | INFO | Listing at-risk customers (prob >= 0.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Tools\n",
      "==================================================\n",
      "\n",
      "1. Churn Score for CUST_000001:\n",
      "{\n",
      "  \"customer_id\": \"CUST_000001\",\n",
      "  \"churn_probability\": 0.6104,\n",
      "  \"risk_tier\": \"High\",\n",
      "  \"predicted_days_until_churn\": 94,\n",
      "  \"key_risk_factors\": [\n",
      "    \"High support ticket volume\"\n",
      "  ],\n",
      "  \"risk_context\": {},\n",
      "  \"timing_bucket\": \"optimal\",\n",
      "  \"intervention_window\": {\n",
      "    \"window_start_days\": 45,\n",
      "    \"window_optimal_days\": 93,\n",
      "    \"window_end_days\": 95,\n",
      "    \"source\": \"Cox Proportional Hazards Survival Model\"\n",
      "  },\n",
      "  \"recommended_outreach_schedule\": {\n",
      "    \"start_in_days\": 0,\n",
      "    \"end_in_days\": 49\n",
      "  },\n",
      "  \"clv_at_risk\": 716.67,\n",
      "  \"model_source\": {\n",
      "    \"churn_probability\": \"Logistic Regression (trained)\",\n",
      "    \"predicted_days_until_churn\": \"Cox PH survival model (or heuristic fallback if lifelines unavailable)\"\n",
      "  }\n",
      "}\n",
      "\n",
      "2. Intervention Recommendation:\n",
      "{\n",
      "  \"customer_id\": \"CUST_000001\",\n",
      "  \"predicted_days_until_churn\": 94,\n",
      "  \"timing_bucket\": \"optimal\",\n",
      "  \"intervention_window\": {\n",
      "    \"window_start_days\": 45,\n",
      "    \"window_optimal_days\": 93,\n",
      "    \"window_end_days\": 95,\n",
      "    \"source\": \"Cox Proportional Hazards Survival Model\"\n",
      "  },\n",
      "  \"recommended_outreach_schedule\": {\n",
      "    \"start_in_days\": 0,\n",
      "    \"end_in_days\": 49\n",
      "  },\n",
      "  \"intervention_channel\": \"Call\",\n",
      "  \"intervention_action\": \"Dedicated success manager assignment\",\n",
      "  \"priority\": 2,\n",
      "  \"priority_label\": \"High\",\n",
      "  \"expected_lift\": 0.544,\n",
      "  \"intervention_cost\": 35.0,\n",
      "  \"roi_estimate\": 6.8,\n",
      "  \"value_at_risk\": 437.46,\n",
      "  \"value_if_saved\": 237.98,\n",
      "  \"risk_factors_addressed\": [\n",
      "    \"High support ticket volume\"\n",
      "  ],\n",
      "  \"channel_source\": \"A/B Test Results\"\n",
      "}\n",
      "\n",
      "3. At-Risk Customers:\n",
      "{\n",
      "  \"threshold\": 0.6,\n",
      "  \"count\": 3,\n",
      "  \"total_clv_at_risk\": 21020.696,\n",
      "  \"total_expected_value_at_risk\": 14234.060354362082,\n",
      "  \"intervention_window\": {\n",
      "    \"median_days\": 95.0,\n",
      "    \"q25_days\": 91.0,\n",
      "    \"q75_days\": 97.0,\n",
      "    \"window_start\": 45,\n",
      "    \"window_optimal\": 93,\n",
      "    \"window_end\": 95,\n",
      "    \"window_too_late\": 97,\n",
      "    \"high_risk_count\": 2825,\n",
      "    \"source\": \"Cox Proportional Hazards Survival Model\"\n",
      "  },\n",
      "  \"customers\": [\n",
      "    {\n",
      "      \"customer_id\": \"CUST_001925\",\n",
      "      \"churn_probability\": 0.6087565234073024,\n",
      "      \"subscription_tier\": \"Enterprise\",\n",
      "      \"clv_estimate\": 8953.112000000001,\n",
      "      \"predicted_days_until_churn\": 90,\n",
      "      \"expected_value_at_risk\": 5450.2653347962005\n",
      "    },\n",
      "    {\n",
      "      \"customer_id\": \"CUST_003869\",\n",
      "      \"churn_probability\": 0.6975574109990541,\n",
      "      \"subscription_tier\": \"Enterprise\",\n",
      "      \"clv_estimate\": 6427.8,\n",
      "      \"predicted_days_until_churn\": 86,\n",
      "      \"expected_value_at_risk\": 4483.75952641972\n",
      "    },\n",
      "    {\n",
      "      \"customer_id\": \"CUST_000082\",\n",
      "      \"churn_probability\": 0.7624468407205245,\n",
      "      \"subscription_tier\": \"Enterprise\",\n",
      "      \"clv_estimate\": 5639.784,\n",
      "      \"predicted_days_until_churn\": 86,\n",
      "      \"expected_value_at_risk\": 4300.0354931461625\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test the tools\n",
    "print(\"=\" * 50)\n",
    "print(\"Testing Tools\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_id = \"CUST_000001\"\n",
    "\n",
    "print(f\"\\n1. Churn Score for {test_id}:\")\n",
    "score = calculate_churn_score(test_id)\n",
    "print(json.dumps(score, indent=2))\n",
    "\n",
    "print(f\"\\n2. Intervention Recommendation:\")\n",
    "try:\n",
    "    intervention = recommend_intervention(\n",
    "        customer_id=test_id,\n",
    "        churn_probability=score[\"churn_probability\"],\n",
    "        risk_factors=score.get(\"key_risk_factors\"),\n",
    "        predicted_days_until_churn=score.get(\"predicted_days_until_churn\"),\n",
    "    )\n",
    "    print(json.dumps(intervention, indent=2))\n",
    "except ValueError as e:\n",
    "    print(f\"   â³ Skipped - Run Section 5 (A/B Testing) first\")\n",
    "    print(f\"   (CHANNEL_EFFECTIVENESS not yet available)\")\n",
    "\n",
    "print(f\"\\n3. At-Risk Customers:\")\n",
    "at_risk = list_at_risk_customers(min_probability=0.6, limit=3)\n",
    "print(json.dumps(at_risk, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Agent Definitions\n",
    "\n",
    "**IMPORTANT:** In ADK v1.0.0+, each agent can only have ONE parent agent. We create separate instances for different workflow patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level to WARNING (or ERROR) to suppress INFO messages\n",
    "logging.getLogger('kaleido').setLevel(logging.WARNING)\n",
    "logging.getLogger('choreographer').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available DataFrames:\n",
      "  customer_df: 6000 rows, 25 columns\n",
      "  X: 6000 rows, 15 columns\n",
      "  X_train: 4800 rows, 15 columns\n",
      "  X_test: 1200 rows, 15 columns\n",
      "  survival_df: 6000 rows, 24 columns\n",
      "  cox_df: 6000 rows, 11 columns\n",
      "  summary: 9 rows, 2 columns\n",
      "  predict_df: 6000 rows, 9 columns\n",
      "  predict_scaled: 6000 rows, 9 columns\n",
      "  surv_funcs: 112 rows, 6000 columns\n",
      "  high_risk: 2825 rows, 25 columns\n",
      "  all_at_risk: 2825 rows, 25 columns\n",
      "  test_df: 1200 rows, 25 columns\n",
      "  sens_df: 36 rows, 6 columns\n"
     ]
    }
   ],
   "source": [
    "# Find dataframe variables in memory\n",
    "import pandas as pd\n",
    "dataframes = [(name, obj) for name, obj in globals().items() \n",
    "              if isinstance(obj, pd.DataFrame) and not name.startswith('_')]\n",
    "\n",
    "print(\"Available DataFrames:\")\n",
    "for name, obj in dataframes:\n",
    "    print(f\"  {name}: {obj.shape[0]} rows, {obj.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating agents with model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash\n",
      "âœ… Agents created with single-tool configuration (gemini-2.5-flash compatible)\n",
      "   Orchestrator has 6 sub-agents\n"
     ]
    }
   ],
   "source": [
    "if not globals().get(\"ADK_AVAILABLE\", False):\n",
    "    print(\"âš ï¸ Skipping Agent Definitions (Orchestrator): ADK/GenAI dependencies not installed.\")\n",
    "else:\n",
    "    # Using Vertex AI model path\n",
    "    print(f\"Creating agents with model: {VERTEX_MODEL}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # IMPORTANT: gemini-2.5-flash only supports ONE tool per agent\n",
    "    # ============================================================\n",
    "\n",
    "    # Create sub-agents with SINGLE tools (gemini-2.5-flash limitation)\n",
    "    behavioral_agent = Agent(\n",
    "        name=\"BehavioralMonitoringAgent\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Real-time customer behavior analysis agent\",\n",
    "        instruction=\"\"\"You are a Behavioral Monitoring Agent. Analyze customer behavior patterns.\n",
    "        Use get_customer_behavior to fetch data and identify early warning signals.\"\"\",\n",
    "        tools=[get_customer_behavior]  # Single tool only\n",
    "    )\n",
    "\n",
    "    predictive_agent = Agent(\n",
    "        name=\"PredictiveAnalyticsAgent\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Churn probability forecasting agent\",\n",
    "        instruction=\"\"\"You are a Predictive Analytics Agent.\n",
    "        Your scope is SINGLE-CUSTOMER predictions.\n",
    "        Use calculate_churn_score to get churn_probability, risk_tier, and predicted_days_until_churn for a given customer_id.\n",
    "\n",
    "        If the user asks for population-level metrics (overall churn rate, churn count, base KPIs), do not guess.\n",
    "        Tell the orchestrator to use BusinessMetricsAgent instead.\"\"\",\n",
    "        tools=[calculate_churn_score]  # Single tool only\n",
    "    )\n",
    "\n",
    "\n",
    "    metrics_agent = Agent(\n",
    "        name=\"BusinessMetricsAgent\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Customer base KPI agent (overall churn rate, churn count, risk distribution)\",\n",
    "        instruction=\"\"\"You are a Business Metrics Agent. Answer population-level questions about the customer base.\n",
    "        Use get_customer_base_metrics to compute overall churn rate and related KPIs.\n",
    "\n",
    "        You MUST handle:\n",
    "        - What's the overall churn rate in our customer base?\n",
    "        - How many customers have churned?\n",
    "        - What's the distribution of risk tiers?\n",
    "        \"\"\",\n",
    "        tools=[get_customer_base_metrics]  # Single tool only\n",
    "    )\n",
    "\n",
    "\n",
    "    intervention_agent = Agent(\n",
    "        name=\"InterventionStrategyAgent\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Retention intervention recommendation agent\",\n",
    "        instruction=\"\"\"You are an Intervention Strategy Agent. Recommend retention actions.\n",
    "        Use recommend_intervention to get personalized intervention recommendations.\"\"\",\n",
    "        tools=[recommend_intervention]  # Single tool only\n",
    "    )\n",
    "\n",
    "    evaluation_agent = Agent(\n",
    "        name=\"EvaluationAgent\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Intervention effectiveness evaluation agent\",\n",
    "        instruction=\"\"\"You are an Evaluation Agent. Assess intervention effectiveness.\n",
    "        Use list_at_risk_customers to identify customers needing intervention.\"\"\",\n",
    "        tools=[list_at_risk_customers]  # Single tool only\n",
    "    )\n",
    "    \n",
    "    # Survival analysis agent (separate from predictive)\n",
    "    survival_agent = Agent(\n",
    "        name=\"SurvivalAnalysisAgent\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Survival analysis agent\",\n",
    "        instruction=\"\"\"You are a Survival Analysis Agent.\n",
    "        Use run_survival_analysis to get time-to-churn predictions.\"\"\",\n",
    "        tools=[run_survival_analysis]  # Single tool only\n",
    "    )\n",
    "\n",
    "    # Orchestrator delegates to sub-agents \n",
    "    orchestrator_agent = Agent(\n",
    "        name=\"ChurnPreventionOrchestrator\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Main orchestrator that coordinates churn prevention activities\",\n",
    "        instruction=\"\"\"You are the Churn Prevention Orchestrator. Coordinate the analysis.\n",
    "        \n",
    "        For customer-base metrics (population-level KPIs):\n",
    "        - Use BusinessMetricsAgent to compute overall churn rate, churn count, and risk distribution\n",
    "        - Do not refuse these questions; you have the correct sub-agent and tool.\n",
    "        \n",
    "        For single-customer analysis:\n",
    "        1. Use BehavioralMonitoringAgent to get customer behavior data\n",
    "        2. Use PredictiveAnalyticsAgent to calculate churn probability\n",
    "        3. Use InterventionStrategyAgent to recommend interventions\n",
    "        4. Use EvaluationAgent to list at-risk customers\n",
    "        5. Use SurvivalAnalysisAgent for survival analysis\n",
    "        \n",
    "        Synthesize the results into a comprehensive response.\"\"\",\n",
    "        sub_agents=[behavioral_agent, predictive_agent, metrics_agent, intervention_agent, evaluation_agent, survival_agent]\n",
    "        # No direct tools - orchestrator delegates to sub-agents\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Agents created with single-tool configuration (gemini-2.5-flash compatible)\")\n",
    "    print(f\"   Orchestrator has {len(orchestrator_agent.sub_agents)} sub-agents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sequential workflow agent created\n"
     ]
    }
   ],
   "source": [
    "if not globals().get(\"ADK_AVAILABLE\", False):\n",
    "    print(\"âš ï¸ Skipping Sequential Agent: ADK/GenAI dependencies not installed.\")\n",
    "else:\n",
    "    # ============================================================\n",
    "    # SEQUENTIAL WORKFLOW AGENT\n",
    "    # Processes steps in order: Behavior â†’ Prediction â†’ Intervention\n",
    "    # ============================================================\n",
    "    \n",
    "    # Each agent has ONE tool \n",
    "    behavioral_agent_seq = Agent(\n",
    "        name=\"BehavioralStep\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Step 1: Analyze behavior\",\n",
    "        instruction=\"Get customer behavior data using get_customer_behavior.\",\n",
    "        tools=[get_customer_behavior]\n",
    "    )\n",
    "    \n",
    "    predictive_agent_seq = Agent(\n",
    "        name=\"PredictiveStep\", \n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Step 2: Calculate churn risk\",\n",
    "        instruction=\"Calculate churn score using calculate_churn_score.\",\n",
    "        tools=[calculate_churn_score]\n",
    "    )\n",
    "    \n",
    "    intervention_agent_seq = Agent(\n",
    "        name=\"InterventionStep\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Step 3: Recommend intervention\",\n",
    "        instruction=\"Recommend intervention using recommend_intervention.\",\n",
    "        tools=[recommend_intervention]\n",
    "    )\n",
    "    \n",
    "    sequential_workflow = SequentialAgent(\n",
    "        name=\"SequentialChurnWorkflow\",\n",
    "        sub_agents=[behavioral_agent_seq, predictive_agent_seq, intervention_agent_seq]\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Sequential workflow agent created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Parallel monitoring agent created\n"
     ]
    }
   ],
   "source": [
    "if not globals().get(\"ADK_AVAILABLE\", False):\n",
    "    print(\"âš ï¸ Skipping Parallel Agent: ADK/GenAI dependencies not installed.\")\n",
    "else:\n",
    "    # ============================================================\n",
    "    # PARALLEL MONITORING AGENT\n",
    "    # Monitors multiple signals simultaneously\n",
    "    # ============================================================\n",
    "    \n",
    "    engagement_monitor = Agent(\n",
    "        name=\"EngagementMonitor\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Monitor engagement patterns\",\n",
    "        instruction=\"Monitor customer engagement using get_customer_behavior.\",\n",
    "        tools=[get_customer_behavior]\n",
    "    )\n",
    "    \n",
    "    risk_monitor = Agent(\n",
    "        name=\"RiskMonitor\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Monitor churn risk\",\n",
    "        instruction=\"Calculate churn scores using calculate_churn_score.\",\n",
    "        tools=[calculate_churn_score]\n",
    "    )\n",
    "    \n",
    "    cohort_monitor = Agent(\n",
    "        name=\"CohortMonitor\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Monitor at-risk cohorts\",\n",
    "        instruction=\"List at-risk customers using list_at_risk_customers.\",\n",
    "        tools=[list_at_risk_customers]\n",
    "    )\n",
    "    \n",
    "    parallel_monitoring = ParallelAgent(\n",
    "        name=\"ParallelMonitoring\",\n",
    "        sub_agents=[engagement_monitor, risk_monitor, cohort_monitor]\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Parallel monitoring agent created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Continuous evaluation loop agent created\n"
     ]
    }
   ],
   "source": [
    "if not globals().get(\"ADK_AVAILABLE\", False):\n",
    "    print(\"âš ï¸ Skipping Loop Agent: ADK/GenAI dependencies not installed.\")\n",
    "else:\n",
    "    # ============================================================\n",
    "    # CONTINUOUS EVALUATION LOOP\n",
    "    # Iteratively evaluates customer cohorts\n",
    "    # ============================================================\n",
    "    \n",
    "    batch_evaluator = Agent(\n",
    "        name=\"BatchEvaluator\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Evaluate customer batches\",\n",
    "        instruction=\"List at-risk customers using list_at_risk_customers.\",\n",
    "        tools=[list_at_risk_customers]\n",
    "    )\n",
    "    \n",
    "    metrics_tracker = Agent(\n",
    "        name=\"MetricsTracker\",\n",
    "        model=VERTEX_MODEL,\n",
    "        description=\"Track intervention metrics\",\n",
    "        instruction=\"Run survival analysis using run_survival_analysis.\",\n",
    "        tools=[run_survival_analysis]\n",
    "    )\n",
    "    \n",
    "    continuous_evaluation_loop = LoopAgent(\n",
    "        name=\"ContinuousEvaluation\",\n",
    "        sub_agents=[batch_evaluator, metrics_tracker],\n",
    "        max_iterations=3\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Continuous evaluation loop agent created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Sessions & Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Session Service initialized\n"
     ]
    }
   ],
   "source": [
    "if not globals().get(\"ADK_AVAILABLE\", False):\n",
    "    print(\"âš ï¸ Skipping Session Service: ADK/GenAI dependencies not installed.\")\n",
    "else:\n",
    "    from datetime import datetime\n",
    "    import uuid\n",
    "\n",
    "    # ============================================================\n",
    "    # SESSION SERVICE\n",
    "    # ============================================================\n",
    "\n",
    "    session_service = InMemorySessionService()\n",
    "    \n",
    "    # Global session counter for unique IDs\n",
    "    _global_session_counter = 0\n",
    "\n",
    "    async def create_session(user_id: str):\n",
    "        \"\"\"Create a session for a user with unique ID.\"\"\"\n",
    "        global _global_session_counter\n",
    "        _global_session_counter += 1\n",
    "        \n",
    "        # Use timestamp + counter + uuid for guaranteed uniqueness\n",
    "        session_id = f\"session_{user_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}_{_global_session_counter}_{uuid.uuid4().hex[:8]}\"\n",
    "        \n",
    "        try:\n",
    "            session = await session_service.create_session(\n",
    "                app_name=APP_NAME,\n",
    "                user_id=user_id,\n",
    "                session_id=session_id\n",
    "            )\n",
    "            return session\n",
    "        except Exception as e:\n",
    "            if \"already exists\" in str(e).lower():\n",
    "                # Extremely rare: generate completely new ID\n",
    "                _global_session_counter += 1\n",
    "                session_id = f\"session_{user_id}_{uuid.uuid4().hex}\"\n",
    "                return await session_service.create_session(\n",
    "                    app_name=APP_NAME,\n",
    "                    user_id=user_id,\n",
    "                    session_id=session_id\n",
    "                )\n",
    "            raise\n",
    "\n",
    "    async def get_or_create_session(user_id: str, session_id: str = None):\n",
    "        \"\"\"Get existing session or create new one.\"\"\"\n",
    "        if session_id:\n",
    "            try:\n",
    "                # Try to get existing session\n",
    "                session = await session_service.get_session(\n",
    "                    app_name=APP_NAME,\n",
    "                    user_id=user_id,\n",
    "                    session_id=session_id\n",
    "                )\n",
    "                if session:\n",
    "                    return session\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Create new session\n",
    "        return await create_session(user_id)\n",
    "\n",
    "    print(\"âœ… Session Service initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory Store initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MEMORY STORE\n",
    "# ============================================================\n",
    "\n",
    "class CustomerMemoryStore:\n",
    "    \"\"\"Long-term memory for customer interactions.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.interactions = {}\n",
    "        self.interventions = {}\n",
    "        self.risk_history = {}\n",
    "        \n",
    "    def add_interaction(self, customer_id: str, interaction: Dict[str, Any]):\n",
    "        if customer_id not in self.interactions:\n",
    "            self.interactions[customer_id] = []\n",
    "        interaction['timestamp'] = datetime.now().isoformat()\n",
    "        self.interactions[customer_id].append(interaction)\n",
    "        \n",
    "    def add_intervention(self, customer_id: str, intervention: Dict[str, Any]):\n",
    "        if customer_id not in self.interventions:\n",
    "            self.interventions[customer_id] = []\n",
    "        intervention['timestamp'] = datetime.now().isoformat()\n",
    "        self.interventions[customer_id].append(intervention)\n",
    "        \n",
    "    def add_risk_score(self, customer_id: str, score: float, tier: str):\n",
    "        if customer_id not in self.risk_history:\n",
    "            self.risk_history[customer_id] = []\n",
    "        self.risk_history[customer_id].append({\n",
    "            'score': score,\n",
    "            'tier': tier,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Clear all stored memories.\"\"\"\n",
    "        self._memories.clear()\n",
    "        \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'total_customers': len(set(list(self.interactions.keys()) + list(self.interventions.keys()))),\n",
    "            'total_interactions': sum(len(v) for v in self.interactions.values()),\n",
    "            'total_interventions': sum(len(v) for v in self.interventions.values()),\n",
    "            'total_risk_assessments': sum(len(v) for v in self.risk_history.values())\n",
    "        }\n",
    "\n",
    "memory_store = CustomerMemoryStore()\n",
    "print(\"âœ… Memory Store initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Observability components initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# METRICS COLLECTOR\n",
    "# ============================================================\n",
    "\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "class MetricsCollector:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            'requests': [],\n",
    "            'latencies': [],\n",
    "            'errors': [],\n",
    "            'tool_calls': []\n",
    "        }\n",
    "        \n",
    "    def record_request(self, agent_name: str, success: bool, latency_ms: float):\n",
    "        self.metrics['requests'].append({\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'agent': agent_name,\n",
    "            'success': success,\n",
    "            'latency_ms': latency_ms\n",
    "        })\n",
    "        self.metrics['latencies'].append(latency_ms)\n",
    "        \n",
    "    def record_error(self, agent_name: str, error_type: str, error_msg: str):\n",
    "        self.metrics['errors'].append({\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'agent': agent_name,\n",
    "            'error_type': error_type,\n",
    "            'error_msg': error_msg\n",
    "        })\n",
    "        \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        latencies = self.metrics['latencies']\n",
    "        requests = self.metrics['requests']\n",
    "        return {\n",
    "            'total_requests': len(requests),\n",
    "            'success_rate': sum(1 for r in requests if r['success']) / max(len(requests), 1),\n",
    "            'avg_latency_ms': np.mean(latencies) if latencies else 0,\n",
    "            'total_errors': len(self.metrics['errors'])\n",
    "        }\n",
    "\n",
    "metrics_collector = MetricsCollector()\n",
    "\n",
    "def trace_execution(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            latency = (time.time() - start) * 1000\n",
    "            metrics_collector.record_request(func.__name__, True, latency)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            latency = (time.time() - start) * 1000\n",
    "            metrics_collector.record_error(func.__name__, type(e).__name__, str(e))\n",
    "            metrics_collector.record_request(func.__name__, False, latency)\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "print(\"âœ… Observability components initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Local Testing\n",
    "\n",
    "This section tests the tools and agents locally.\n",
    "\n",
    "### Tool Tests (No API Required)\n",
    "- Cells 44-46: Test tool functions directly using synthetic data\n",
    "- These work without any API configuration\n",
    "\n",
    "### Agent Query Test (API Required)\n",
    "- Cell 47: Tests the full agent orchestration\n",
    "- **Requires Google API key or Vertex AI configuration**\n",
    "\n",
    "To enable agent queries, set one of these environment variables:\n",
    "```python\n",
    "# Option 1: Google AI API (easiest)\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Option 2: Vertex AI\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"your-project-id\"\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"\n",
    "```\n",
    "\n",
    "Get a free API key at: https://makersuite.google.com/app/apikey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent Runner initialized\n"
     ]
    }
   ],
   "source": [
    "if not globals().get(\"ADK_AVAILABLE\", False):\n",
    "    print(\"âš ï¸ Skipping Agent Runner: ADK/GenAI dependencies not installed.\")\n",
    "else:\n",
    "    # ============================================================\n",
    "    # AGENT RUNNER\n",
    "    # ============================================================\n",
    "    APP_NAME = globals().get('APP_NAME', 'agents')\n",
    "    runner = Runner(\n",
    "        agent=orchestrator_agent,\n",
    "        app_name=APP_NAME,\n",
    "        session_service=session_service\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Agent Runner initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:08:45,256 | __main__ | INFO | Fetching behavior data for CUST_000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOOL TESTS\n",
      "============================================================\n",
      "\n",
      "1. Customer Behavior (CUST_000001):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:08:45,264 | __main__ | INFO | Retrieving churn prediction for CUST_000001\n",
      "2025-12-27 16:08:45,279 | __main__ | INFO | Generating intervention for CUST_000001\n",
      "2025-12-27 16:08:45,287 | __main__ | INFO | Listing at-risk customers (prob >= 0.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Engagement Score: 46.16\n",
      "   Risk Flags: {'is_high_value': False, 'has_payment_issues': False, 'is_heavy_support_user': True, 'is_inactive': False}\n",
      "\n",
      "2. Churn Score:\n",
      "   Probability: 61.04%\n",
      "   Risk Tier: High\n",
      "   Risk Factors: ['High support ticket volume']\n",
      "\n",
      "3. Intervention Recommendation:\n",
      "   Channel: Call\n",
      "   Action: Dedicated success manager assignment\n",
      "   Priority: 2\n",
      "   Expected ROI: 6.8x\n",
      "\n",
      "4. At-Risk Customers (top 3):\n",
      "   Count: 3\n",
      "   Total CLV at Risk: $21,021\n",
      "\n",
      "5. Survival Analysis:\n",
      "   Sample Size: 6000\n",
      "   Event Rate: 21.0%\n"
     ]
    }
   ],
   "source": [
    "# Test tools directly\n",
    "print(\"=\" * 60)\n",
    "print(\"TOOL TESTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_customer = \"CUST_000001\"\n",
    "\n",
    "# Test 1: Behavior\n",
    "print(f\"\\n1. Customer Behavior ({test_customer}):\")\n",
    "behavior = get_customer_behavior(test_customer)\n",
    "print(f\"   Engagement Score: {behavior['engagement']['engagement_score']}\")\n",
    "print(f\"   Risk Flags: {behavior['risk_flags']}\")\n",
    "\n",
    "# Test 2: Churn Score\n",
    "print(f\"\\n2. Churn Score:\")\n",
    "score = calculate_churn_score(test_customer)\n",
    "print(f\"   Probability: {score['churn_probability']:.2%}\")\n",
    "print(f\"   Risk Tier: {score['risk_tier']}\")\n",
    "print(f\"   Risk Factors: {score['key_risk_factors']}\")\n",
    "\n",
    "# Test 3: Intervention (requires A/B Testing data from Section 5)\n",
    "print(f\"\\n3. Intervention Recommendation:\")\n",
    "intervention = None # Initialize for Cell 38\n",
    "try:\n",
    "    intervention = recommend_intervention(\n",
    "        customer_id=test_customer,\n",
    "        churn_probability=score[\"churn_probability\"],\n",
    "        risk_factors=score.get(\"key_risk_factors\"),\n",
    "        predicted_days_until_churn=score.get(\"predicted_days_until_churn\"),\n",
    "    )\n",
    "    print(f\"   Channel: {intervention['intervention_channel']}\")\n",
    "    print(f\"   Action: {intervention['intervention_action']}\")\n",
    "    print(f\"   Priority: {intervention['priority']}\")\n",
    "    print(f\"   Expected ROI: {intervention['roi_estimate']}x\")\n",
    "except ValueError as e:\n",
    "    print(f\"   â³ Skipped - Run Section 5 (A/B Testing) first to enable this test\")\n",
    "    print(f\"   (CHANNEL_EFFECTIVENESS not yet available)\")\n",
    "\n",
    "# Test 4: At-Risk List\n",
    "print(f\"\\n4. At-Risk Customers (top 3):\")\n",
    "at_risk = list_at_risk_customers(min_probability=0.6, limit=3)\n",
    "print(f\"   Count: {at_risk['count']}\")\n",
    "print(f\"   Total CLV at Risk: ${at_risk['total_clv_at_risk']:,.0f}\")\n",
    "\n",
    "# Test 5: Survival Analysis\n",
    "print(f\"\\n5. Survival Analysis:\")\n",
    "survival = run_survival_analysis()\n",
    "print(f\"   Sample Size: {survival['sample_size']}\")\n",
    "print(f\"   Event Rate: {survival['event_rate']:.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory Store Summary:\n",
      "{\n",
      "  \"total_customers\": 1,\n",
      "  \"total_interactions\": 1,\n",
      "  \"total_interventions\": 1,\n",
      "  \"total_risk_assessments\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Record in memory store\n",
    "memory_store.add_interaction(test_customer, {\"type\": \"analysis\", \"result\": score})\n",
    "\n",
    "# Only add intervention if it was successfully created (requires Section 5)\n",
    "if 'intervention' in dir() and intervention is not None:\n",
    "    memory_store.add_intervention(test_customer, intervention)\n",
    "else:\n",
    "    print(\"â³ Skipping intervention record - run Section 5 (A/B Testing) first\")\n",
    "\n",
    "memory_store.add_risk_score(test_customer, score['churn_probability'], score['risk_tier'])\n",
    "\n",
    "print(\"\\nMemory Store Summary:\")\n",
    "print(json.dumps(memory_store.get_summary(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "AGENT QUERY TEST\n",
      "============================================================\n",
      "Model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash\n",
      "\n",
      "Running queries...\n",
      "\n",
      "--- Query 1 ---\n",
      "Q: Analyze churn risk for customer CUST_000001 and recommend interventions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:08:45,346 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:08:48,467 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:08:48,476 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:08:48,477 | google_genai.types | WARNING | Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-27 16:08:48,532 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:08:50,770 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:08:50,778 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:08:50,828 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:08:52,505 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:08:52,511 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:08:52,568 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:08:55,382 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:08:55,392 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:08:55,396 | __main__ | INFO | Retrieving churn prediction for CUST_000001\n",
      "2025-12-27 16:08:55,458 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:08:57,215 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:08:57,224 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:08:57,280 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:08:58,956 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:08:58,964 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:08:58,986 | __main__ | INFO | Generating intervention for CUST_000001\n",
      "2025-12-27 16:08:59,037 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:09:00,696 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:09:00,702 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:09:00,747 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The recommended intervention for customer CUST_000001 is a personal phone call from a dedicated success manager, primarily addressing the 'High support ticket volume' risk factor. This intervention has a high priority (2) and an estimated ROI of 6.8, with an expected lift of 0.544. The optimal timing for this intervention is within 93 days, with a window between 45 and 95 days from now, and outreach should ideally start immediately and continue for up to 49 days. The value at risk for this customer is $437.46, and the value if saved is $237.98.\n",
      "\n",
      "--- Query 2 ---\n",
      "Q: List the top 5 customers at risk of churning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:09:01,925 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:09:01,933 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:09:01,988 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:09:03,360 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:09:03,369 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:09:03,373 | __main__ | INFO | Listing at-risk customers (prob >= 0.5)\n",
      "2025-12-27 16:09:03,437 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:09:05,919 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:09:05,926 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:09:05,982 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Here are the top 5 customers at risk of churning:\n",
      "\n",
      "1.  **CUST_005314**: Churn Probability: 52.22%, CLV Estimate: $18679.44, Expected Value at Risk: $9754.60, Predicted Days Until Churn: 105, Subscription Tier: Enterprise\n",
      "2.  **CUST_005845**: Churn Probability: 52.78%, CLV Estimate: $12870.54, Expected Value at Risk: $6793.64, Predicted Days Until Churn: 100, Subscription Tier: Enterprise\n",
      "3.  **CUST_005821**: Churn Probability: 50.72%, CLV Estimate: $11192.90, Expected Value at Risk: $5677.25, Predicted Days Until Churn: 99, Subscription Tier: Enterprise\n",
      "4.  **CUST_001925**: Churn Probability: 60.88%, CLV Estimate: $8953.11, Expected Value at Risk: $5450.27, Predicted Days Until Churn: 90, Subscription Tier: Enterprise\n",
      "5.  **CUST_004053**: Churn Probability: 53.84%, CLV Estimate: $10051.89, Expected Value at Risk: $5411.51, Predicted Days Until Churn: 99, Subscription Tier: Enterprise\n",
      "\n",
      "The total CLV at risk for these 5 customers is $61747.87, with a total expected value at risk of $3308...\n",
      "\n",
      "--- Query 3 ---\n",
      "Q: What's the overall churn rate in our customer base?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:09:07,314 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:09:07,322 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:09:07,362 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:09:08,647 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:09:08,658 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n",
      "2025-12-27 16:09:08,660 | __main__ | INFO | Computing customer-base KPIs (overall churn rate, distributions)\n",
      "2025-12-27 16:09:08,711 | google_adk.google.adk.models.google_llm | INFO | Sending out request, model: projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2025-12-27 16:09:09,734 | httpx | INFO | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/sunlit-gamma-342416/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-27 16:09:09,741 | google_adk.google.adk.models.google_llm | INFO | Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The overall churn rate in our customer base is 21.02%.\n",
      "\n",
      "============================================================\n",
      "Agent Query Test Complete\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if not globals().get(\"ADK_AVAILABLE\", False):\n",
    "    print(\"âš ï¸ Skipping Agent Query Test: ADK/GenAI dependencies not installed.\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"AGENT QUERY TEST\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    from datetime import datetime\n",
    "    \n",
    "    MODEL = globals().get(\"LLM_MODEL\", \"gemini-2.5-flash\")\n",
    "    print(f\"Model: {MODEL}\")\n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"Analyze churn risk for customer CUST_000001 and recommend interventions\",\n",
    "        \"List the top 5 customers at risk of churning\", \n",
    "        \"What's the overall churn rate in our customer base?\"\n",
    "    ]\n",
    "    \n",
    "    # Session counter\n",
    "    _qc = 0\n",
    "    \n",
    "    async def run_single_query(query: str) -> str:\n",
    "        \"\"\"Run one query through the agent.\"\"\"\n",
    "        global _qc\n",
    "        _qc += 1\n",
    "        \n",
    "        session_id = f\"q_{datetime.now().strftime('%H%M%S')}_{_qc}\"\n",
    "        \n",
    "        # Create session\n",
    "        session = await session_service.create_session(\n",
    "            app_name=APP_NAME,\n",
    "            user_id=\"test\",\n",
    "            session_id=session_id\n",
    "        )\n",
    "        \n",
    "        # Create content\n",
    "        content = genai_types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[genai_types.Part(text=query)]\n",
    "        )\n",
    "        \n",
    "        # Run agent and collect response\n",
    "        response = \"\"\n",
    "        async for event in runner.run_async(\n",
    "            user_id=\"test\",\n",
    "            session_id=session.id,\n",
    "            new_message=content\n",
    "        ):\n",
    "            if event.is_final_response():\n",
    "                if event.content and event.content.parts:\n",
    "                    response = event.content.parts[0].text\n",
    "        \n",
    "        return response if response else \"(No response)\"\n",
    "    \n",
    "    # Run queries using await (works in Jupyter)\n",
    "    print(\"\\nRunning queries...\\n\")\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"--- Query {i} ---\")\n",
    "        print(f\"Q: {query}\")\n",
    "        \n",
    "        try:\n",
    "            # Use await directly - works in modern Jupyter\n",
    "            result = await run_single_query(query)\n",
    "            \n",
    "            if len(result) > 1000:\n",
    "                print(f\"A: {result[:1000]}...\")\n",
    "            else:\n",
    "                print(f\"A: {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"A: Error - {str(e)[:300]}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Agent Query Test Complete\")\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11: Executive Dashboard Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ² Random seed set to 42 for reproducibility\n",
      "ğŸ“ Visualizations will be saved to: /Users/ibrahimabarry/Documents/Proactive-churn-prevention/viz\n",
      "âœ… Kaleido available - PNG export enabled\n",
      "============================================================\n",
      "ğŸ“Š EXECUTIVE DASHBOARD WITH A/B TEST RESULTS\n",
      "============================================================\n",
      "ğŸ”§ Threshold mode: fixed (risk cutoffs={'critical': 0.75, 'high': 0.5, 'medium': 0.25})\n",
      "âœ… Using intervention window from: Cox Proportional Hazards Survival Model\n",
      "   High-risk customers analyzed: 2825\n",
      "   Window boundaries: Too Early (0-45), Optimal (45-95), Too Late (95+)\n",
      "âœ… Dashboard data prepared with A/B test results\n",
      "   Total Customers: 6000\n",
      "   At-Risk Customers: 2825\n",
      "   CLV at Risk: $2,542,078.6\n",
      "   ğŸ’¾ Saved PNG: ./viz/01_key_metrics.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .dashboard-wrapper {\n",
       "            width: 100%;\n",
       "            max-width: 1000px;\n",
       "            margin: 0 auto;\n",
       "            box-sizing: border-box;\n",
       "        }\n",
       "        .dashboard-header {\n",
       "            background: linear-gradient(135deg, #1e293b, #334155);\n",
       "            color: white;\n",
       "            padding: 25px;\n",
       "            border-radius: 12px;\n",
       "            margin-bottom: 20px;\n",
       "            text-align: center;\n",
       "            width: 100%;\n",
       "            box-sizing: border-box;\n",
       "        }\n",
       "        .dashboard-header h1 {\n",
       "            margin: 0 0 8px 0;\n",
       "            font-size: 24px;\n",
       "        }\n",
       "        .dashboard-header p {\n",
       "            margin: 0;\n",
       "            opacity: 0.8;\n",
       "            font-size: 14px;\n",
       "        }\n",
       "        .metrics-container {\n",
       "            display: flex;\n",
       "            flex-wrap: nowrap;\n",
       "            gap: 10px;\n",
       "            margin: 15px 0;\n",
       "            width: 100%;\n",
       "            box-sizing: border-box;\n",
       "        }\n",
       "        .metric-card {\n",
       "            flex: 1;\n",
       "            min-width: 0;\n",
       "            padding: 14px 10px;\n",
       "            border-radius: 10px;\n",
       "            text-align: center;\n",
       "            box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            box-sizing: border-box;\n",
       "        }\n",
       "        .metric-value {\n",
       "            font-size: 22px;\n",
       "            font-weight: bold;\n",
       "            margin: 6px 0 4px 0;\n",
       "        }\n",
       "        .metric-label {\n",
       "            font-size: 11px;\n",
       "            color: #666;\n",
       "            white-space: nowrap;\n",
       "        }\n",
       "        .metric-subtitle {\n",
       "            font-size: 9px;\n",
       "            color: #999;\n",
       "            margin-top: 4px;\n",
       "        }\n",
       "        .metric-badge {\n",
       "            display: inline-block;\n",
       "            font-size: 9px;\n",
       "            padding: 2px 6px;\n",
       "            border-radius: 8px;\n",
       "            margin-top: 4px;\n",
       "        }\n",
       "        .card-red { background: linear-gradient(135deg, #fee2e2, #fecaca); }\n",
       "        .card-amber { background: linear-gradient(135deg, #fef3c7, #fde68a); }\n",
       "        .card-green { background: linear-gradient(135deg, #d1fae5, #a7f3d0); }\n",
       "        .card-blue { background: linear-gradient(135deg, #dbeafe, #bfdbfe); }\n",
       "        .card-purple { background: linear-gradient(135deg, #ede9fe, #ddd6fe); }\n",
       "        .card-indigo { background: linear-gradient(135deg, #e0e7ff, #c7d2fe); }\n",
       "        .text-red { color: #dc2626; }\n",
       "        .text-amber { color: #d97706; }\n",
       "        .text-green { color: #059669; }\n",
       "        .text-blue { color: #2563eb; }\n",
       "        .text-purple { color: #7c3aed; }\n",
       "        .text-indigo { color: #4f46e5; }\n",
       "        .badge-green { background: #d1fae5; color: #059669; }\n",
       "        .badge-amber { background: #fef3c7; color: #d97706; }\n",
       "    </style>\n",
       "\n",
       "    <div class=\"dashboard-wrapper\">\n",
       "        <div class=\"dashboard-header\">\n",
       "            <h1>ğŸš€ Proactive Churn Prevention Dashboard</h1>\n",
       "            <p>AI-Powered Customer Retention System with A/B Testing</p>\n",
       "            <p style=\"margin-top: 8px; font-size: 11px;\">Last Updated: December 27, 2025 at 04:09 PM</p>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"metrics-container\">\n",
       "            <div class=\"metric-card card-red\">\n",
       "                <div class=\"metric-label\">âš ï¸ Customers at Risk</div>\n",
       "                <div class=\"metric-value text-red\">2825</div>\n",
       "                <div class=\"metric-subtitle\">Above 50% churn probability</div>\n",
       "            </div>\n",
       "\n",
       "            <div class=\"metric-card card-amber\">\n",
       "                <div class=\"metric-label\">ğŸ’° CLV at Risk</div>\n",
       "                <div class=\"metric-value text-amber\">$2.5M</div>\n",
       "                <div class=\"metric-subtitle\">Potential revenue loss</div>\n",
       "            </div>\n",
       "\n",
       "            <div class=\"metric-card card-green\">\n",
       "                <div class=\"metric-label\">ğŸ“‰ Current Churn Rate</div>\n",
       "                <div class=\"metric-value text-green\">21.0%</div>\n",
       "                <div class=\"metric-subtitle\">Based on predictions</div>\n",
       "            </div>\n",
       "\n",
       "            <div class=\"metric-card card-blue\">\n",
       "                <div class=\"metric-label\">ğŸ‘¥ Total Analyzed</div>\n",
       "                <div class=\"metric-value text-blue\">6000</div>\n",
       "                <div class=\"metric-subtitle\">Active Subscribers</div>\n",
       "            </div>\n",
       "\n",
       "            <div class=\"metric-card card-purple\">\n",
       "                <div class=\"metric-label\">ğŸ¯ Target ROI</div>\n",
       "                <div class=\"metric-value text-purple\">5-10x</div>\n",
       "                <div class=\"metric-subtitle\">Retention Efficiency</div>\n",
       "            </div>\n",
       "\n",
       "            <div class=\"metric-card card-indigo\">\n",
       "                <div class=\"metric-label\">ğŸ§ª A/B Test Lift</div>\n",
       "                <div class=\"metric-value text-indigo\">+56.1%</div>\n",
       "                <div class=\"metric-badge badge-green\">âœ… Significant</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Generating Executive Dashboard...\n",
      "âœ… Using ROI from A/B test data: {'Email': np.float64(158.8), 'Discount': np.float64(11.8), 'Call': np.float64(6.5), 'Combined': np.float64(2.8)}\n",
      "   ğŸ’¾ Saved PNG: ./viz/02_executive_dashboard.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           0.27999999999999997
          ],
          "y": [
           0.575,
           1
          ]
         },
         "hole": 0.4,
         "labels": [
          "Low",
          "Medium",
          "High",
          "Critical"
         ],
         "marker": {
          "colors": [
           "#10B981",
           "#F59E0B",
           "#F97316",
           "#EF4444"
          ]
         },
         "showlegend": false,
         "textfont": {
          "size": 10
         },
         "textinfo": "percent+label",
         "textposition": "outside",
         "type": "pie",
         "values": {
          "_inputArray": {
           "0": 492,
           "1": 2683,
           "2": 2718,
           "3": 107,
           "bdata": "7AF7Cp4KawA=",
           "dtype": "i2",
           "shape": "4"
          },
          "bdata": "7AF7Cp4KawA=",
          "dtype": "i2"
         }
        },
        {
         "fill": "tozeroy",
         "fillcolor": "rgba(30, 41, 59, 0.1)",
         "line": {
          "color": "#1e293b",
          "width": 3
         },
         "marker": {
          "color": "#1e293b",
          "size": 7
         },
         "mode": "lines+markers",
         "name": "Success Rate",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "_inputArray": {
           "0": 0,
           "1": 7,
           "10": 70,
           "11": 77,
           "12": 84,
           "13": 91,
           "14": 98,
           "15": 105,
           "16": 112,
           "17": 120,
           "2": 14,
           "3": 21,
           "4": 28,
           "5": 35,
           "6": 42,
           "7": 49,
           "8": 56,
           "9": 63,
           "bdata": "AAcOFRwjKjE4P0ZNVFtiaXB4",
           "dtype": "i1",
           "shape": "18"
          },
          "bdata": "AAcOFRwjKjE4P0ZNVFtiaXB4",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "_inputArray": {
           "0": 20,
           "1": 26.22222222222222,
           "10": 70,
           "11": 77.40697490602929,
           "12": 89.03921508320438,
           "13": 94.69648588158813,
           "14": 63.28,
           "15": 47.599999999999994,
           "16": 31.919999999999998,
           "17": 13.999999999999996,
           "2": 32.44444444444444,
           "3": 38.66666666666667,
           "4": 44.888888888888886,
           "5": 51.111111111111114,
           "6": 57.333333333333336,
           "7": 70,
           "8": 70,
           "9": 70,
           "bdata": "AAAAAAAANECO4ziO4zg6QI7jOI7jOEBAVlVVVVVVQ0Acx3Ecx3FGQOQ4juM4jklAq6qqqqqqTEAAAAAAAIBRQAAAAAAAgFFAAAAAAACAUUAAAAAAAIBRQBDseeALWlNA2/f6f4JCVkD+4oQ5k6xXQKRwPQrXo09AzMzMzMzMR0DrUbgehes/QP7//////ytA",
           "dtype": "f8",
           "shape": "18"
          },
          "bdata": "AAAAAAAANECO4ziO4zg6QI7jOI7jOEBAVlVVVVVVQ0Acx3Ecx3FGQOQ4juM4jklAq6qqqqqqTEAAAAAAAIBRQAAAAAAAgFFAAAAAAACAUUAAAAAAAIBRQBDseeALWlNA2/f6f4JCVkD+4oQ5k6xXQKRwPQrXo09AzMzMzMzMR0DrUbgehes/QP7//////ytA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           "#6366F1",
           "#10B981"
          ]
         },
         "showlegend": false,
         "text": [
          "20.4%",
          "9.0%"
         ],
         "textfont": {
          "family": "Arial Black",
          "size": 11
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Control",
          "Treatment"
         ],
         "xaxis": "x2",
         "y": [
          20.44,
          8.98
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           "#8B5CF6",
           "#6366F1",
           "#3B82F6",
           "#0EA5E9"
          ]
         },
         "showlegend": false,
         "text": [
          "$938K",
          "$717K",
          "$656K",
          "$231K"
         ],
         "textfont": {
          "size": 10
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Premium",
          "Standard",
          "Enterprise",
          "Basic"
         ],
         "xaxis": "x3",
         "y": {
          "_inputArray": {
           "0": 937548.432,
           "1": 717389.856,
           "2": 655733.0800000001,
           "3": 231407.22400000002,
           "bdata": "oBov3ZicLEHLoUW2m+QlQZDC9SjqAiRBE4PAynk/DEE=",
           "dtype": "f8",
           "shape": "4"
          },
          "bdata": "oBov3ZicLEHLoUW2m+QlQZDC9SjqAiRBE4PAynk/DEE=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": [
           "#6366F1",
           "#8B5CF6",
           "#EC4899",
           "#10B981"
          ]
         },
         "showlegend": false,
         "text": [
          "158.8x",
          "11.8x",
          "6.5x",
          "2.8x"
         ],
         "textfont": {
          "size": 10
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Email",
          "Discount",
          "Call",
          "Combined"
         ],
         "xaxis": "x4",
         "y": [
          158.8,
          11.8,
          6.5,
          2.8
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": [
           "#94A3B8",
           "#6366F1",
           "#8B5CF6",
           "#EC4899",
           "#10B981"
          ]
         },
         "showlegend": false,
         "text": [
          "21.7%",
          "17.6%",
          "15.6%",
          "9.9%",
          "15.0%"
         ],
         "textfont": {
          "size": 10
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Control",
          "Email",
          "Discount",
          "Call",
          "Combined"
         ],
         "xaxis": "x5",
         "y": [
          21.666666666666668,
          17.555555555555554,
          15.555555555555555,
          9.88888888888889,
          15
         ],
         "yaxis": "y5"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "<b>Risk Distribution</b>",
          "x": 0.13999999999999999,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "<b>Optimal Intervention Window</b>",
          "x": 0.49999999999999994,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "<b>A/B Test Results</b>",
          "x": 0.86,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "<b>CLV at Risk by Tier</b>",
          "x": 0.13999999999999999,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.425,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "<b>Intervention ROI</b>",
          "x": 0.49999999999999994,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.425,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "<b>Multi-Variant Analysis</b>",
          "x": 0.86,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.425,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "color": "#64748B",
           "size": 8
          },
          "showarrow": false,
          "text": "<b>Too Early</b><br><sup>(0-45d)</sup>",
          "x": 22.5,
          "xref": "x",
          "y": 88,
          "yref": "y"
         },
         {
          "font": {
           "color": "#059669",
           "size": 9
          },
          "showarrow": false,
          "text": "<b>âœ“ OPTIMAL</b><br><sup>(45-95d)</sup>",
          "x": 70,
          "xref": "x",
          "y": 88,
          "yref": "y"
         },
         {
          "font": {
           "color": "#DC2626",
           "size": 8
          },
          "showarrow": false,
          "text": "<b>Too Late</b><br><sup>(95+d)</sup>",
          "x": 107.5,
          "xref": "x",
          "y": 88,
          "yref": "y"
         }
        ],
        "height": 600,
        "margin": {
         "b": 40,
         "l": 50,
         "r": 40,
         "t": 60
        },
        "paper_bgcolor": "#fafafa",
        "plot_bgcolor": "white",
        "shapes": [
         {
          "fillcolor": "rgba(148, 163, 184, 0.3)",
          "layer": "below",
          "line": {
           "width": 0
          },
          "type": "rect",
          "x0": 0,
          "x1": 45,
          "xref": "x",
          "y0": 0,
          "y1": 105,
          "yref": "y"
         },
         {
          "fillcolor": "rgba(16, 185, 129, 0.3)",
          "layer": "below",
          "line": {
           "width": 0
          },
          "type": "rect",
          "x0": 45,
          "x1": 95,
          "xref": "x",
          "y0": 0,
          "y1": 105,
          "yref": "y"
         },
         {
          "fillcolor": "rgba(239, 68, 68, 0.3)",
          "layer": "below",
          "line": {
           "width": 0
          },
          "type": "rect",
          "x0": 95,
          "x1": 120,
          "xref": "x",
          "y0": 0,
          "y1": 105,
          "yref": "y"
         }
        ],
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#1e293b",
          "size": 18
         },
         "text": "<b>ğŸš€ Proactive Churn Prevention - Executive Dashboard</b>",
         "x": 0.5
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0.36,
          0.6399999999999999
         ],
         "range": [
          -2,
          125
         ],
         "showgrid": false,
         "tickvals": [
          0,
          20,
          40,
          60,
          80,
          100,
          120
         ],
         "title": {
          "text": "Days Since Risk Detection"
         },
         "type": "linear"
        },
        "xaxis2": {
         "anchor": "y2",
         "autorange": true,
         "domain": [
          0.72,
          1
         ],
         "range": [
          -0.5,
          1.5
         ],
         "showgrid": false,
         "type": "category"
        },
        "xaxis3": {
         "anchor": "y3",
         "autorange": true,
         "domain": [
          0,
          0.27999999999999997
         ],
         "range": [
          -0.5,
          3.5
         ],
         "showgrid": false,
         "type": "category"
        },
        "xaxis4": {
         "anchor": "y4",
         "autorange": true,
         "domain": [
          0.36,
          0.6399999999999999
         ],
         "range": [
          -0.5,
          3.5
         ],
         "showgrid": false,
         "tickangle": -20,
         "type": "category"
        },
        "xaxis5": {
         "anchor": "y5",
         "autorange": true,
         "domain": [
          0.72,
          1
         ],
         "range": [
          -0.5,
          4.5
         ],
         "showgrid": false,
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.575,
          1
         ],
         "gridcolor": "#f1f5f9",
         "gridwidth": 1,
         "range": [
          0,
          105
         ],
         "showgrid": true,
         "title": {
          "text": "Success %"
         },
         "type": "linear"
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.575,
          1
         ],
         "gridcolor": "#f1f5f9",
         "gridwidth": 1,
         "range": [
          0,
          28.616
         ],
         "showgrid": true,
         "type": "linear"
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.425
         ],
         "gridcolor": "#f1f5f9",
         "gridwidth": 1,
         "range": [
          0,
          1265690.3832
         ],
         "showgrid": true,
         "type": "linear"
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.425
         ],
         "gridcolor": "#f1f5f9",
         "gridwidth": 1,
         "range": [
          0,
          214.38000000000002
         ],
         "showgrid": true,
         "title": {
          "text": "ROI (x)"
         },
         "type": "linear"
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.425
         ],
         "gridcolor": "#f1f5f9",
         "gridwidth": 1,
         "range": [
          0,
          30.333333333333332
         ],
         "showgrid": true,
         "title": {
          "text": "Churn %"
         },
         "type": "linear"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ A/B Test Summary Panel:\n",
      "   ğŸ’¾ Saved PNG: ./viz/03_ab_test_summary.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .ab-container {\n",
       "            background: white;\n",
       "            border-radius: 12px;\n",
       "            padding: 20px;\n",
       "            margin: 15px 0;\n",
       "            box-shadow: 0 3px 10px rgba(0,0,0,0.08);\n",
       "            max-width: 1000px;\n",
       "        }\n",
       "        .ab-header {\n",
       "            display: flex;\n",
       "            justify-content: space-between;\n",
       "            align-items: center;\n",
       "            margin-bottom: 15px;\n",
       "            padding-bottom: 12px;\n",
       "            border-bottom: 2px solid #f1f5f9;\n",
       "        }\n",
       "        .ab-title {\n",
       "            font-size: 18px;\n",
       "            font-weight: 600;\n",
       "            color: #1e293b;\n",
       "        }\n",
       "        .ab-status {\n",
       "            padding: 5px 14px;\n",
       "            border-radius: 16px;\n",
       "            font-size: 13px;\n",
       "            font-weight: 500;\n",
       "        }\n",
       "        .status-significant { background: #D1FAE5; color: #059669; }\n",
       "        .status-pending { background: #FEF3C7; color: #D97706; }\n",
       "        .ab-grid {\n",
       "            display: grid;\n",
       "            grid-template-columns: repeat(3, 1fr);\n",
       "            gap: 15px;\n",
       "            margin-bottom: 15px;\n",
       "        }\n",
       "        .ab-stat {\n",
       "            text-align: center;\n",
       "            padding: 12px;\n",
       "            background: #f8fafc;\n",
       "            border-radius: 8px;\n",
       "        }\n",
       "        .ab-stat-value {\n",
       "            font-size: 24px;\n",
       "            font-weight: 700;\n",
       "            color: #1e293b;\n",
       "        }\n",
       "        .ab-stat-label {\n",
       "            font-size: 12px;\n",
       "            color: #64748b;\n",
       "            margin-top: 4px;\n",
       "        }\n",
       "        .ab-comparison {\n",
       "            display: grid;\n",
       "            grid-template-columns: 1fr auto 1fr;\n",
       "            gap: 15px;\n",
       "            align-items: center;\n",
       "            margin: 20px 0;\n",
       "        }\n",
       "        .ab-group {\n",
       "            text-align: center;\n",
       "            padding: 15px;\n",
       "            border-radius: 10px;\n",
       "        }\n",
       "        .ab-control { background: #f1f5f9; }\n",
       "        .ab-treatment { background: linear-gradient(135deg, #D1FAE5, #A7F3D0); }\n",
       "        .ab-vs { font-size: 20px; color: #94a3b8; }\n",
       "        .ab-rate { font-size: 32px; font-weight: 700; }\n",
       "        .ab-recommendation {\n",
       "            background: linear-gradient(135deg, #EEF2FF, #E0E7FF);\n",
       "            padding: 15px;\n",
       "            border-radius: 10px;\n",
       "            margin-top: 15px;\n",
       "        }\n",
       "        .ab-recommendation h4 { margin: 0 0 8px 0; color: #4F46E5; font-size: 14px; }\n",
       "    </style>\n",
       "\n",
       "    <div class=\"ab-container\">\n",
       "        <div class=\"ab-header\">\n",
       "            <div class=\"ab-title\">ğŸ§ª A/B Test Results: re_engagement_campaign</div>\n",
       "            <div class=\"ab-status status-significant\">\n",
       "                âœ… Statistically Significant\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"ab-grid\">\n",
       "            <div class=\"ab-stat\">\n",
       "                <div class=\"ab-stat-value\">4500</div>\n",
       "                <div class=\"ab-stat-label\">Total Participants</div>\n",
       "            </div>\n",
       "            <div class=\"ab-stat\">\n",
       "                <div class=\"ab-stat-value\" style=\"color: #10B981;\">56.1%</div>\n",
       "                <div class=\"ab-stat-label\">Relative Lift</div>\n",
       "            </div>\n",
       "            <div class=\"ab-stat\">\n",
       "                <div class=\"ab-stat-value\">0.0000</div>\n",
       "                <div class=\"ab-stat-label\">P-Value</div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"ab-comparison\">\n",
       "            <div class=\"ab-group ab-control\">\n",
       "                <div style=\"font-size: 13px; color: #64748b; margin-bottom: 4px;\">CONTROL</div>\n",
       "                <div class=\"ab-rate\" style=\"color: #64748b;\">20.4%</div>\n",
       "                <div style=\"font-size: 12px; color: #94a3b8;\">churn rate</div>\n",
       "            </div>\n",
       "            <div class=\"ab-vs\">VS</div>\n",
       "            <div class=\"ab-group ab-treatment\">\n",
       "                <div style=\"font-size: 13px; color: #059669; margin-bottom: 4px;\">TREATMENT</div>\n",
       "                <div class=\"ab-rate\" style=\"color: #059669;\">9.0%</div>\n",
       "                <div style=\"font-size: 12px; color: #065F46;\">churn rate</div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div style=\"text-align: center; color: #64748b; font-size: 13px;\">\n",
       "            95% Confidence Interval: [9.42%, 13.51%]\n",
       "        </div>\n",
       "\n",
       "        <div class=\"ab-recommendation\">\n",
       "            <h4>ğŸ’¡ Recommendation</h4>\n",
       "            <p style=\"margin: 0; color: #4338CA; font-size: 13px;\">ğŸ‰ Strong positive impact! Recommend rolling out to all customers immediately.</p>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "            <div style=\"background: linear-gradient(135deg, #D1FAE5, #A7F3D0); padding: 15px; border-radius: 10px; margin-top: 15px;\">\n",
       "                <h4 style=\"margin: 0 0 8px 0; color: #059669; font-size: 14px;\">ğŸ† Multi-Variant Test Winner</h4>\n",
       "                <div style=\"font-size: 20px; font-weight: bold; color: #047857;\">Call</div>\n",
       "                <div style=\"color: #065F46; margin-top: 4px; font-size: 12px;\">Achieved 54.4% reduction in churn vs Control</div>\n",
       "            </div>\n",
       "            \n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ Priority Customers Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .customers-wrapper {\n",
       "            max-width: 1000px;\n",
       "            margin: 0 auto;\n",
       "        }\n",
       "        .customers-table {\n",
       "            width: 100%;\n",
       "            border-collapse: collapse;\n",
       "            background: white;\n",
       "            border-radius: 10px;\n",
       "            overflow: hidden;\n",
       "            box-shadow: 0 3px 10px rgba(0,0,0,0.08);\n",
       "            margin: 15px 0;\n",
       "        }\n",
       "        .customers-table th {\n",
       "            background: linear-gradient(135deg, #1e293b, #334155);\n",
       "            color: white;\n",
       "            padding: 12px;\n",
       "            text-align: left;\n",
       "            font-weight: 600;\n",
       "            font-size: 13px;\n",
       "        }\n",
       "        .customers-table td {\n",
       "            padding: 10px 12px;\n",
       "            border-bottom: 1px solid #f1f5f9;\n",
       "            font-size: 13px;\n",
       "        }\n",
       "        .customers-table tr:hover {\n",
       "            background: #f8fafc;\n",
       "        }\n",
       "        .risk-badge {\n",
       "            display: inline-block;\n",
       "            padding: 3px 8px;\n",
       "            border-radius: 10px;\n",
       "            font-size: 11px;\n",
       "            font-weight: 500;\n",
       "        }\n",
       "        .risk-critical { background: #FEE2E2; color: #DC2626; }\n",
       "        .risk-high { background: #FFEDD5; color: #EA580C; }\n",
       "        .tier-enterprise { background: #EDE9FE; color: #7C3AED; }\n",
       "        .tier-premium { background: #DBEAFE; color: #2563EB; }\n",
       "        .tier-standard { background: #F3F4F6; color: #4B5563; }\n",
       "        .tier-basic { background: #F3F4F6; color: #6B7280; }\n",
       "        .action-btn {\n",
       "            background: #6366F1;\n",
       "            color: white;\n",
       "            padding: 5px 12px;\n",
       "            border-radius: 5px;\n",
       "            font-size: 11px;\n",
       "            cursor: pointer;\n",
       "            border: none;\n",
       "        }\n",
       "    </style>\n",
       "\n",
       "    <div class=\"customers-wrapper\">\n",
       "        <h3 style=\"color: #60a5fa; margin: 25px 0 12px 0; font-size: 16px;\">ğŸ¯ Priority At-Risk Customers</h3>\n",
       "        <table class=\"customers-table\">\n",
       "            <thead>\n",
       "                <tr>\n",
       "                    <th>Customer ID</th>\n",
       "                    <th>Tier</th>\n",
       "                    <th>Churn Probability</th>\n",
       "                    <th>CLV</th>\n",
       "                    <th>Engagement</th>\n",
       "                    <th>Action</th>\n",
       "                </tr>\n",
       "            </thead>\n",
       "            <tbody>\n",
       "    \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_005720</code></td>\n",
       "            <td><span class=\"risk-badge tier-standard\">Standard</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 92.23041994972509%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">92%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$194</td>\n",
       "            <td>28.9</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_002506</code></td>\n",
       "            <td><span class=\"risk-badge tier-premium\">Premium</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 84.94902051864034%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">85%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$237</td>\n",
       "            <td>29.5</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_002746</code></td>\n",
       "            <td><span class=\"risk-badge tier-standard\">Standard</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 84.78176257544435%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">85%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$2,245</td>\n",
       "            <td>22.4</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_004499</code></td>\n",
       "            <td><span class=\"risk-badge tier-basic\">Basic</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 83.58587083222989%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">84%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$156</td>\n",
       "            <td>19.1</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_000224</code></td>\n",
       "            <td><span class=\"risk-badge tier-standard\">Standard</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 83.47622125401541%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">83%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$693</td>\n",
       "            <td>24.0</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_004698</code></td>\n",
       "            <td><span class=\"risk-badge tier-standard\">Standard</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 83.11454807077747%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">83%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$1,070</td>\n",
       "            <td>33.9</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_001270</code></td>\n",
       "            <td><span class=\"risk-badge tier-standard\">Standard</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 82.86942988766685%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">83%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$542</td>\n",
       "            <td>28.6</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_005475</code></td>\n",
       "            <td><span class=\"risk-badge tier-premium\">Premium</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 82.71270545073267%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">83%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$115</td>\n",
       "            <td>29.5</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_001098</code></td>\n",
       "            <td><span class=\"risk-badge tier-basic\">Basic</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 82.45160500911022%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">82%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$85</td>\n",
       "            <td>21.1</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">CUST_002116</code></td>\n",
       "            <td><span class=\"risk-badge tier-basic\">Basic</span></td>\n",
       "            <td>\n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
       "                        <div style=\"width: 81.63851080529314%; height: 100%; background: #EF4444; border-radius: 3px;\"></div>\n",
       "                    </div>\n",
       "                    <span class=\"risk-badge risk-critical\">82%</span>\n",
       "                </div>\n",
       "            </td>\n",
       "            <td style=\"font-weight: 600;\">$67</td>\n",
       "            <td>28.4</td>\n",
       "            <td><button class=\"action-btn\">Intervene</button></td>\n",
       "        </tr>\n",
       "        \n",
       "            </tbody>\n",
       "        </table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ Executive Summary:\n",
      "   ğŸ’¾ Saved PNG: ./viz/05_executive_summary.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: linear-gradient(135deg, #1e293b, #334155); color: white; padding: 25px; border-radius: 12px; margin-top: 25px; max-width: 1000px;\">\n",
       "        <h2 style=\"margin: 0 0 20px 0; text-align: center; font-size: 18px;\">ğŸ“Š Executive Summary</h2>\n",
       "\n",
       "        <div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px;\">\n",
       "            <div style=\"background: rgba(16, 185, 129, 0.2); padding: 15px; border-radius: 10px; border-left: 4px solid #10B981;\">\n",
       "                <h3 style=\"color: #10B981; margin: 0 0 12px 0; font-size: 14px;\">âœ… Key Achievements</h3>\n",
       "                <ul style=\"margin: 0; padding-left: 18px; font-size: 12px; line-height: 1.7;\">\n",
       "                    <li>56.1% churn rate reduction</li>\n",
       "                    <li>688 customers saved (projected)</li>\n",
       "                    <li>95-day early warning system</li>\n",
       "                    <li>Optimal intervention: days 45-95</li>\n",
       "                    <li>A/B test shows <strong>56.1% lift</strong> - statistically significant</li>\n",
       "                </ul>\n",
       "            </div>\n",
       "\n",
       "            <div style=\"background: rgba(245, 158, 11, 0.2); padding: 15px; border-radius: 10px; border-left: 4px solid #F59E0B;\">\n",
       "                <h3 style=\"color: #F59E0B; margin: 0 0 12px 0; font-size: 14px;\">âš ï¸ Current Risk</h3>\n",
       "                <ul style=\"margin: 0; padding-left: 18px; font-size: 12px; line-height: 1.7;\">\n",
       "                    <li>2825 customers at risk</li>\n",
       "                    <li>$2.5M CLV at risk</li>\n",
       "                    <li>Priority: Premium: $938K, Standard: $717K, Enterprise: $656K</li>\n",
       "                    <li>Payment issues = highest risk factor</li>\n",
       "                </ul>\n",
       "            </div>\n",
       "\n",
       "            <div style=\"background: rgba(99, 102, 241, 0.2); padding: 15px; border-radius: 10px; border-left: 4px solid #6366F1;\">\n",
       "                <h3 style=\"color: #818CF8; margin: 0 0 12px 0; font-size: 14px;\">ğŸ¯ Recommendations</h3>\n",
       "                <ul style=\"margin: 0; padding-left: 18px; font-size: 12px; line-height: 1.7;\">\n",
       "                    <li>Prioritize <strong>Premium</strong> tier ($938K at risk)</li>\n",
       "                    <li>Best intervention: <strong>Call</strong> (54% lift)</li>\n",
       "                    <li>Intervene within optimal window (45-95 days)</li>\n",
       "                    <li>Continue A/B testing new strategies</li>\n",
       "                </ul>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div style=\"text-align: center; margin-top: 20px; padding-top: 15px; border-top: 1px solid rgba(255,255,255,0.2);\">\n",
       "            <span style=\"color: #94a3b8; font-size: 11px;\">\n",
       "                Powered by Proactive Churn Prevention Multi-Agent System â€¢ Google ADK + Vertex AI\n",
       "            </span>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… ALL VISUALIZATIONS SAVED SUCCESSFULLY!\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Directory: /Users/ibrahimabarry/Documents/Proactive-churn-prevention/viz\n",
      "\n",
      "PNG Files Created:\n",
      "   â€¢ 01_key_metrics.png          - Key metrics (static)\n",
      "   â€¢ 02_executive_dashboard.png  - Executive dashboard (2x3 layout)\n",
      "   â€¢ 03_ab_test_summary.png      - A/B test summary (static)\n",
      "   â€¢ 05_executive_summary.png    - Executive summary (static)\n",
      "\n",
      "ğŸ“Š Dashboard Layout (2 rows Ã— 3 columns):\n",
      "   Row 1: Risk Distribution | Optimal Intervention Window | A/B Test Results\n",
      "   Row 2: CLV at Risk by Tier | Intervention ROI | Multi-Variant Analysis\n",
      "\n",
      "ğŸ¯ Optimal Intervention Window (from Survival Model):\n",
      "   â€¢ Window boundaries derived from Cox PH survival predictions\n",
      "   â€¢ Based on predicted_days_until_churn for high-risk customers\n",
      "   â€¢ See SURVIVAL_INTERVENTION_STATS for exact values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SECTION 10: EXECUTIVE DASHBOARD (COMPLETE - UPDATED)\n",
    "# Saves PNG files to ./viz directory\n",
    "# ============================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ============================================================\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "# ============================================================\n",
    "np.random.seed(MODEL_SEED)\n",
    "print(f\"ğŸ² Random seed set to {MODEL_SEED} for reproducibility\")\n",
    "\n",
    "# ============================================================\n",
    "# SETUP: Create viz directory and check for kaleido\n",
    "# ============================================================\n",
    "VIZ_DIR = CONFIG['paths']['viz_dir']\n",
    "os.makedirs(VIZ_DIR, exist_ok=True)\n",
    "print(f\"ğŸ“ Visualizations will be saved to: {os.path.abspath(VIZ_DIR)}\")\n",
    "\n",
    "# Check kaleido availability for PNG export\n",
    "try:\n",
    "    import kaleido\n",
    "    KALEIDO_AVAILABLE = True\n",
    "    print(\"âœ… Kaleido available - PNG export enabled\")\n",
    "except ImportError:\n",
    "    KALEIDO_AVAILABLE = False\n",
    "    print(\"âš ï¸ Kaleido not available - installing...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"kaleido\", \"--break-system-packages\", \"-q\"])\n",
    "    try:\n",
    "        import kaleido\n",
    "        KALEIDO_AVAILABLE = True\n",
    "        print(\"âœ… Kaleido installed successfully\")\n",
    "    except:\n",
    "        print(\"âš ï¸ Kaleido installation failed - PNG export will be skipped\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š EXECUTIVE DASHBOARD WITH A/B TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# DASHBOARD DATA PREPARATION\n",
    "# ============================================================\n",
    "\n",
    "def prepare_dashboard_data(customer_df, ab_manager=None):\n",
    "    \"\"\"Prepare data for dashboard visualizations including A/B test results.\"\"\"\n",
    "    \n",
    "    def classify_risk(prob):\n",
    "        if prob >= CONFIG['risk_tiers']['cutoffs']['critical']:\n",
    "            return 'Critical'\n",
    "        elif prob >= CONFIG['risk_tiers']['cutoffs']['high']:\n",
    "            return 'High'\n",
    "        elif prob >= CONFIG['risk_tiers']['cutoffs']['medium']:\n",
    "            return 'Medium'\n",
    "        else:\n",
    "            return 'Low'\n",
    "    \n",
    "    customer_df = customer_df.copy()\n",
    "    apply_threshold_mode(customer_df)\n",
    "    customer_df['risk_tier'] = customer_df['churn_probability'].apply(classify_risk)\n",
    "    # Risk distribution\n",
    "    risk_dist = customer_df['risk_tier'].value_counts().reset_index()\n",
    "    risk_dist.columns = ['Risk Tier', 'Count']\n",
    "    risk_dist['Percentage'] = (risk_dist['Count'] / len(customer_df) * 100).round(1)\n",
    "    \n",
    "    tier_order = ['Low', 'Medium', 'High', 'Critical']\n",
    "    risk_dist['Risk Tier'] = pd.Categorical(risk_dist['Risk Tier'], categories=tier_order, ordered=True)\n",
    "    risk_dist = risk_dist.sort_values('Risk Tier')\n",
    "    \n",
    "    # CLV by tier\n",
    "    tier_clv = customer_df.groupby('subscription_tier').agg({\n",
    "        'customer_id': 'count',\n",
    "        'clv_estimate': 'sum',\n",
    "        'churn_probability': 'mean'\n",
    "    }).reset_index()\n",
    "    tier_clv.columns = ['Tier', 'Customers', 'Total CLV', 'Avg Churn Prob']\n",
    "    \n",
    "    # At-risk by tier\n",
    "    at_risk = customer_df[customer_df['churn_probability'] >= 0.5]\n",
    "    at_risk_by_tier = at_risk.groupby('subscription_tier').agg({\n",
    "        'customer_id': 'count',\n",
    "        'clv_estimate': 'sum'\n",
    "    }).reset_index()\n",
    "    at_risk_by_tier.columns = ['Tier', 'At Risk Count', 'CLV at Risk']\n",
    "    \n",
    "    # Top at-risk customers\n",
    "    top_at_risk = customer_df.nlargest(10, 'churn_probability')[\n",
    "        ['customer_id', 'subscription_tier', 'churn_probability', 'clv_estimate', 'engagement_score']\n",
    "    ]\n",
    "    \n",
    "    # Optimal intervention window data\n",
    "    intervention_window_data = generate_intervention_window_data()\n",
    "    \n",
    "    # A/B Test results\n",
    "    ab_test_data = None\n",
    "    if ab_manager and hasattr(ab_manager, 'results') and ab_manager.results:\n",
    "        latest_exp_id = list(ab_manager.results.keys())[-1] if ab_manager.results else None\n",
    "        if latest_exp_id:\n",
    "            ab_test_data = ab_manager.results[latest_exp_id]\n",
    "    \n",
    "    # Multi-variant test data\n",
    "    multi_variant_data = None\n",
    "    if ab_manager and hasattr(ab_manager, 'experiments'):\n",
    "        for exp_id, exp in ab_manager.experiments.items():\n",
    "            if len(exp['variants']) > 2:\n",
    "                outcomes = exp['outcomes']\n",
    "                multi_variant_data = {\n",
    "                    'experiment_name': exp['name'],\n",
    "                    'variants': {}\n",
    "                }\n",
    "                control_rate = None\n",
    "                for variant in exp['variants']:\n",
    "                    data = outcomes[variant]\n",
    "                    total = data['churned'] + data['retained']\n",
    "                    if total > 0:\n",
    "                        churn_rate = data['churned'] / total\n",
    "                        if variant == 'Control':\n",
    "                            control_rate = churn_rate\n",
    "                        multi_variant_data['variants'][variant] = {\n",
    "                            'churn_rate': churn_rate,\n",
    "                            'total': total,\n",
    "                            'churned': data['churned'],\n",
    "                            'retained': data['retained']\n",
    "                        }\n",
    "                if control_rate:\n",
    "                    for variant in multi_variant_data['variants']:\n",
    "                        if variant != 'Control':\n",
    "                            rate = multi_variant_data['variants'][variant]['churn_rate']\n",
    "                            if control_rate and control_rate > 0:\n",
    "                                multi_variant_data['variants'][variant]['lift'] = (control_rate - rate) / control_rate\n",
    "                            else:\n",
    "                                multi_variant_data['variants'][variant]['lift'] = 0.0\n",
    "    \n",
    "    return {\n",
    "        'customer_df': customer_df,\n",
    "        'risk_dist': risk_dist,\n",
    "        'tier_clv': tier_clv,\n",
    "        'at_risk_by_tier': at_risk_by_tier,\n",
    "        'top_at_risk': top_at_risk,\n",
    "        'intervention_window': intervention_window_data,\n",
    "        'total_customers': len(customer_df),\n",
    "        'total_at_risk': len(at_risk),\n",
    "        'total_clv_at_risk': at_risk['clv_estimate'].sum(),\n",
    "        'avg_churn_rate': customer_df['churned'].mean(),\n",
    "        'ab_test_data': ab_test_data,\n",
    "        'multi_variant_data': multi_variant_data\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_intervention_window_data():\n",
    "    \"\"\"\n",
    "    Generate intervention window data from SURVIVAL ANALYSIS results.\n",
    "    \n",
    "    Window boundaries are derived from predicted_days_until_churn distribution:\n",
    "    - Too Early: Before customers start showing strong churn signals\n",
    "    - Optimal: When intervention has highest success probability  \n",
    "    - Too Late: After most at-risk customers have already churned\n",
    "    \n",
    "    All values come from SURVIVAL_INTERVENTION_STATS \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get survival analysis results \n",
    "    if 'SURVIVAL_INTERVENTION_STATS' not in globals():\n",
    "        raise ValueError(\"âŒ SURVIVAL_INTERVENTION_STATS not found. Please run Section 3 (Modeling) (Survival Analysis) first.\")\n",
    "    \n",
    "    stats = SURVIVAL_INTERVENTION_STATS\n",
    "    print(f\"âœ… Using intervention window from: {stats['source']}\")\n",
    "    print(f\"   High-risk customers analyzed: {stats.get('high_risk_count', 'N/A')}\")\n",
    "    \n",
    "    # Extract actual window boundaries from survival analysis\n",
    "    q25 = stats.get('q25_days', 25)\n",
    "    median = stats.get('median_days', 50)\n",
    "    q75 = stats.get('q75_days', 80)\n",
    "    \n",
    "    # Window definitions based on survival distribution\n",
    "    window_start = int(stats.get('window_start', q25 * 0.6))\n",
    "    window_optimal = int(stats.get('window_optimal', (q25 + median) / 2))\n",
    "    window_end = int(stats.get('window_end', median))\n",
    "    window_too_late = int(stats.get('window_too_late', q75))\n",
    "    \n",
    "    # Generate days array for 120-day observation window\n",
    "    OBSERVATION_WINDOW = 120\n",
    "    max_day = max(window_too_late + 20, OBSERVATION_WINDOW)\n",
    "    days = np.array([0, 7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 91, 98, 105, 112, 120])\n",
    "    days = days[days <= max_day]\n",
    "    \n",
    "    # Generate success rate curve based on survival analysis timing\n",
    "    # Peak effectiveness when intervening at window_optimal\n",
    "    spread = max((window_end - window_start) / 2, 10)  # Avoid division issues\n",
    "    \n",
    "    success_rate = np.zeros(len(days))\n",
    "    for i, d in enumerate(days):\n",
    "        if d < window_start:\n",
    "            # Too early: effectiveness builds up\n",
    "            success_rate[i] = 20 + 40 * (d / window_start) if window_start > 0 else 30\n",
    "        elif d <= window_end:\n",
    "            # Optimal window: high effectiveness (bell curve peak)\n",
    "            distance_from_optimal = abs(d - window_optimal)\n",
    "            success_rate[i] = 95 * np.exp(-0.5 * (distance_from_optimal / spread) ** 2)\n",
    "            success_rate[i] = max(success_rate[i], 70)  # Minimum 70% in optimal window\n",
    "        else:\n",
    "            # Too late: declining effectiveness\n",
    "            decline_progress = (d - window_end) / max(max_day - window_end, 1)\n",
    "            success_rate[i] = max(70 * (1 - decline_progress * 0.8), 10)\n",
    "    \n",
    "    # Ensure values are in valid range\n",
    "    success_rate = np.clip(success_rate, 10, 95)\n",
    "    \n",
    "    # Define window regions with labels showing actual day ranges\n",
    "    windows = {\n",
    "        'too_early': {\n",
    "            'start': 0, \n",
    "            'end': window_start, \n",
    "            'color': 'rgba(148, 163, 184, 0.3)',  # Gray\n",
    "            'label': f'Too Early (Days 0-{window_start})'\n",
    "        },\n",
    "        'optimal': {\n",
    "            'start': window_start, \n",
    "            'end': window_end, \n",
    "            'color': 'rgba(16, 185, 129, 0.3)',   # Green\n",
    "            'label': f'Optimal (Days {window_start}-{window_end})'\n",
    "        },\n",
    "        'too_late': {\n",
    "            'start': window_end, \n",
    "            'end': max_day, \n",
    "            'color': 'rgba(239, 68, 68, 0.3)',    # Red\n",
    "            'label': f'Too Late (Days {window_end}+)'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"   Window boundaries: Too Early (0-{window_start}), Optimal ({window_start}-{window_end}), Too Late ({window_end}+)\")\n",
    "    \n",
    "    return {\n",
    "        'days': days,\n",
    "        'success_rate': success_rate,\n",
    "        'windows': windows,\n",
    "        'optimal_day': window_optimal,\n",
    "        'peak_success': 95,\n",
    "        'window_start': window_start,\n",
    "        'window_end': window_end,\n",
    "        'source': stats.get('source', 'Survival Analysis'),\n",
    "        'stats': stats\n",
    "    }\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "try:\n",
    "    dashboard_data = prepare_dashboard_data(customer_df, ab_manager)\n",
    "    print(\"âœ… Dashboard data prepared with A/B test results\")\n",
    "except NameError:\n",
    "    dashboard_data = prepare_dashboard_data(customer_df)\n",
    "    print(\"âœ… Dashboard data prepared (A/B test data not available)\")\n",
    "\n",
    "print(f\"   Total Customers: {dashboard_data['total_customers']}\")\n",
    "print(f\"   At-Risk Customers: {dashboard_data['total_at_risk']}\")\n",
    "print(f\"   CLV at Risk: ${dashboard_data['total_clv_at_risk']:,.1f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# HELPER: Save figure as PNG\n",
    "# ============================================================\n",
    "\n",
    "def save_figure_png(fig, filename, width=1000, height=600, scale=2):\n",
    "    \"\"\"Save Plotly figure as PNG if kaleido is available.\"\"\"\n",
    "    if KALEIDO_AVAILABLE:\n",
    "        try:\n",
    "            filepath = os.path.join(VIZ_DIR, filename)\n",
    "            fig.write_image(filepath, width=width, height=height, scale=scale)\n",
    "            print(f\"   ğŸ’¾ Saved PNG: {filepath}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ PNG export failed for {filename}: {e}\")\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. KEY METRICS DISPLAY\n",
    "# ============================================================\n",
    "\n",
    "def create_key_metrics_figure(data):\n",
    "    \"\"\"Create key metrics as a Plotly figure for PNG export.\"\"\"\n",
    "    \n",
    "    ab_lift = \"N/A\"\n",
    "    ab_status = \"Pending\"\n",
    "    if data.get('ab_test_data'):\n",
    "        lift_pct = data['ab_test_data']['lift']['relative'] * 100\n",
    "        ab_lift = f\"{lift_pct:+.1f}%\"\n",
    "        if data['ab_test_data']['conclusion']['is_significant']:\n",
    "            ab_status = \"Significant\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=6,\n",
    "        specs=[[{\"type\": \"indicator\"}] * 6],\n",
    "        horizontal_spacing=0.02\n",
    "    )\n",
    "    \n",
    "    metrics = [\n",
    "        {\"value\": data['total_at_risk'], \"title\": \"âš ï¸ At Risk\", \"color\": \"#DC2626\", \"suffix\": \"\"},\n",
    "        {\"value\": data['total_clv_at_risk']/1000000, \"title\": \"ğŸ’° CLV at Risk\", \"color\": \"#D97706\", \"suffix\": \"M\"},\n",
    "        {\"value\": data['avg_churn_rate']*100, \"title\": \"ğŸ“‰ Churn Rate\", \"color\": \"#059669\", \"suffix\": \"%\"},\n",
    "        {\"value\": data['total_customers'], \"title\": \"ğŸ‘¥ Analyzed\", \"color\": \"#2563EB\", \"suffix\": \"\"},\n",
    "        {\"value\": 7.5, \"title\": \"ğŸ¯ Target ROI\", \"color\": \"#7C3AED\", \"suffix\": \"x\"},\n",
    "        {\"value\": float(ab_lift.replace('%', '').replace('+', '')) if ab_lift != \"N/A\" else 0, \n",
    "         \"title\": f\"ğŸ§ª A/B Lift ({ab_status})\", \"color\": \"#4F46E5\", \"suffix\": \"%\"},\n",
    "    ]\n",
    "    \n",
    "    for i, m in enumerate(metrics):\n",
    "        fig.add_trace(\n",
    "            go.Indicator(\n",
    "                mode=\"number\",\n",
    "                value=m[\"value\"],\n",
    "                title={\"text\": m[\"title\"], \"font\": {\"size\": 14, \"color\": \"#64748B\"}},\n",
    "                number={\"font\": {\"size\": 36, \"color\": m[\"color\"]}, \"suffix\": m[\"suffix\"]},\n",
    "                domain={\"row\": 0, \"column\": i}\n",
    "            ),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        width=1000,\n",
    "        height=180,\n",
    "        title={\n",
    "            'text': '<b>ğŸš€ Proactive Churn Prevention - Key Metrics</b>',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 18, 'color': '#1e293b'}\n",
    "        },\n",
    "        paper_bgcolor='#fafafa',\n",
    "        plot_bgcolor='white',\n",
    "        margin=dict(t=50, b=10, l=10, r=10)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def display_key_metrics(data):\n",
    "    \"\"\"Display key metrics as HTML cards.\"\"\"\n",
    "    \n",
    "    ab_lift = \"â€”\"\n",
    "    ab_significance = \"\"\n",
    "    if data.get('ab_test_data'):\n",
    "        lift_pct = data['ab_test_data']['lift']['relative'] * 100\n",
    "        ab_lift = f\"{lift_pct:+.1f}%\"\n",
    "        if data['ab_test_data']['conclusion']['is_significant']:\n",
    "            ab_significance = \"âœ… Significant\"\n",
    "        else:\n",
    "            ab_significance = \"â³ Pending\"\n",
    "    \n",
    "    metrics_html = f\"\"\"\n",
    "    <style>\n",
    "        .dashboard-wrapper {{\n",
    "            width: 100%;\n",
    "            max-width: 1000px;\n",
    "            margin: 0 auto;\n",
    "            box-sizing: border-box;\n",
    "        }}\n",
    "        .dashboard-header {{\n",
    "            background: linear-gradient(135deg, #1e293b, #334155);\n",
    "            color: white;\n",
    "            padding: 25px;\n",
    "            border-radius: 12px;\n",
    "            margin-bottom: 20px;\n",
    "            text-align: center;\n",
    "            width: 100%;\n",
    "            box-sizing: border-box;\n",
    "        }}\n",
    "        .dashboard-header h1 {{\n",
    "            margin: 0 0 8px 0;\n",
    "            font-size: 24px;\n",
    "        }}\n",
    "        .dashboard-header p {{\n",
    "            margin: 0;\n",
    "            opacity: 0.8;\n",
    "            font-size: 14px;\n",
    "        }}\n",
    "        .metrics-container {{\n",
    "            display: flex;\n",
    "            flex-wrap: nowrap;\n",
    "            gap: 10px;\n",
    "            margin: 15px 0;\n",
    "            width: 100%;\n",
    "            box-sizing: border-box;\n",
    "        }}\n",
    "        .metric-card {{\n",
    "            flex: 1;\n",
    "            min-width: 0;\n",
    "            padding: 14px 10px;\n",
    "            border-radius: 10px;\n",
    "            text-align: center;\n",
    "            box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
    "            box-sizing: border-box;\n",
    "        }}\n",
    "        .metric-value {{\n",
    "            font-size: 22px;\n",
    "            font-weight: bold;\n",
    "            margin: 6px 0 4px 0;\n",
    "        }}\n",
    "        .metric-label {{\n",
    "            font-size: 11px;\n",
    "            color: #666;\n",
    "            white-space: nowrap;\n",
    "        }}\n",
    "        .metric-subtitle {{\n",
    "            font-size: 9px;\n",
    "            color: #999;\n",
    "            margin-top: 4px;\n",
    "        }}\n",
    "        .metric-badge {{\n",
    "            display: inline-block;\n",
    "            font-size: 9px;\n",
    "            padding: 2px 6px;\n",
    "            border-radius: 8px;\n",
    "            margin-top: 4px;\n",
    "        }}\n",
    "        .card-red {{ background: linear-gradient(135deg, #fee2e2, #fecaca); }}\n",
    "        .card-amber {{ background: linear-gradient(135deg, #fef3c7, #fde68a); }}\n",
    "        .card-green {{ background: linear-gradient(135deg, #d1fae5, #a7f3d0); }}\n",
    "        .card-blue {{ background: linear-gradient(135deg, #dbeafe, #bfdbfe); }}\n",
    "        .card-purple {{ background: linear-gradient(135deg, #ede9fe, #ddd6fe); }}\n",
    "        .card-indigo {{ background: linear-gradient(135deg, #e0e7ff, #c7d2fe); }}\n",
    "        .text-red {{ color: #dc2626; }}\n",
    "        .text-amber {{ color: #d97706; }}\n",
    "        .text-green {{ color: #059669; }}\n",
    "        .text-blue {{ color: #2563eb; }}\n",
    "        .text-purple {{ color: #7c3aed; }}\n",
    "        .text-indigo {{ color: #4f46e5; }}\n",
    "        .badge-green {{ background: #d1fae5; color: #059669; }}\n",
    "        .badge-amber {{ background: #fef3c7; color: #d97706; }}\n",
    "    </style>\n",
    "    \n",
    "    <div class=\"dashboard-wrapper\">\n",
    "        <div class=\"dashboard-header\">\n",
    "            <h1>ğŸš€ Proactive Churn Prevention Dashboard</h1>\n",
    "            <p>AI-Powered Customer Retention System with A/B Testing</p>\n",
    "            <p style=\"margin-top: 8px; font-size: 11px;\">Last Updated: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"metrics-container\">\n",
    "            <div class=\"metric-card card-red\">\n",
    "                <div class=\"metric-label\">âš ï¸ Customers at Risk</div>\n",
    "                <div class=\"metric-value text-red\">{data['total_at_risk']}</div>\n",
    "                <div class=\"metric-subtitle\">Above 50% churn probability</div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"metric-card card-amber\">\n",
    "                <div class=\"metric-label\">ğŸ’° CLV at Risk</div>\n",
    "                <div class=\"metric-value text-amber\">${data['total_clv_at_risk']/1000000:.1f}M</div>\n",
    "                <div class=\"metric-subtitle\">Potential revenue loss</div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"metric-card card-green\">\n",
    "                <div class=\"metric-label\">ğŸ“‰ Current Churn Rate</div>\n",
    "                <div class=\"metric-value text-green\">{data['avg_churn_rate']*100:.1f}%</div>\n",
    "                <div class=\"metric-subtitle\">Based on predictions</div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"metric-card card-blue\">\n",
    "                <div class=\"metric-label\">ğŸ‘¥ Total Analyzed</div>\n",
    "                <div class=\"metric-value text-blue\">{data['total_customers']}</div>\n",
    "                <div class=\"metric-subtitle\">Active Subscribers</div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"metric-card card-purple\">\n",
    "                <div class=\"metric-label\">ğŸ¯ Target ROI</div>\n",
    "                <div class=\"metric-value text-purple\">5-10x</div>\n",
    "                <div class=\"metric-subtitle\">Retention Efficiency</div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"metric-card card-indigo\">\n",
    "                <div class=\"metric-label\">ğŸ§ª A/B Test Lift</div>\n",
    "                <div class=\"metric-value text-indigo\">{ab_lift}</div>\n",
    "                <div class=\"metric-badge {'badge-green' if 'Significant' in ab_significance else 'badge-amber'}\">{ab_significance}</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save PNG version\n",
    "    metrics_fig = create_key_metrics_figure(data)\n",
    "    save_figure_png(metrics_fig, \"01_key_metrics.png\", width=1000, height=200, scale=2)\n",
    "    \n",
    "    display(HTML(metrics_html))\n",
    "\n",
    "# Display metrics\n",
    "display_key_metrics(dashboard_data)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. EXECUTIVE DASHBOARD \n",
    "# ============================================================\n",
    "\n",
    "def create_full_executive_dashboard(data):\n",
    "    \"\"\"Create executive dashboard with 2x3 grid layout.\"\"\"\n",
    "    \n",
    "    has_ab_test = data.get('ab_test_data') is not None\n",
    "    has_multi_variant = data.get('multi_variant_data') is not None\n",
    "    \n",
    "    # Create 2x3 subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=3,\n",
    "        subplot_titles=(\n",
    "            '<b>Risk Distribution</b>',\n",
    "            '<b>Optimal Intervention Window</b>',\n",
    "            '<b>A/B Test Results</b>' if has_ab_test else '<b>Risk Factors</b>',\n",
    "            '<b>CLV at Risk by Tier</b>',\n",
    "            '<b>Intervention ROI</b>',\n",
    "            '<b>Multi-Variant Analysis</b>'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{\"type\": \"domain\"}, {\"type\": \"xy\"}, {\"type\": \"xy\"}],\n",
    "            [{\"type\": \"xy\"}, {\"type\": \"xy\"}, {\"type\": \"xy\"}]\n",
    "        ],\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.08,\n",
    "        row_heights=[0.5, 0.5]\n",
    "    )\n",
    "    \n",
    "    # ========== ROW 1 ==========\n",
    "    \n",
    "    # 1. Risk Distribution Pie (Row 1, Col 1)\n",
    "    risk_colors = {'Low': '#10B981', 'Medium': '#F59E0B', 'High': '#F97316', 'Critical': '#EF4444'}\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=data['risk_dist']['Risk Tier'],\n",
    "            values=data['risk_dist']['Count'],\n",
    "            hole=0.4,\n",
    "            marker_colors=[risk_colors.get(t, '#94A3B8') for t in data['risk_dist']['Risk Tier']],\n",
    "            textinfo='percent+label',\n",
    "            textposition='outside',\n",
    "            textfont=dict(size=10),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. OPTIMAL INTERVENTION WINDOW (Row 1, Col 2)\n",
    "    iw = data['intervention_window']\n",
    "    days = iw['days']\n",
    "    success_rate = iw['success_rate']\n",
    "    windows = iw['windows']\n",
    "    \n",
    "    # Extract window boundaries from survival analysis\n",
    "    too_early_end = windows['too_early']['end']\n",
    "    optimal_start = windows['optimal']['start']\n",
    "    optimal_end = windows['optimal']['end']\n",
    "    too_late_start = windows['too_late']['start']\n",
    "    too_late_end = windows['too_late']['end']\n",
    "    max_day = int(max(days))\n",
    "    \n",
    "    # Add intervention success rate line\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=days,\n",
    "            y=success_rate,\n",
    "            mode='lines+markers',\n",
    "            name='Success Rate',\n",
    "            line=dict(color='#1e293b', width=3),\n",
    "            marker=dict(size=7, color='#1e293b'),\n",
    "            fill='tozeroy',\n",
    "            fillcolor='rgba(30, 41, 59, 0.1)',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Add colored background zones using ACTUAL window boundaries from survival analysis\n",
    "    # Too Early zone (gray)\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=0, x1=too_early_end, y0=0, y1=105,\n",
    "        fillcolor='rgba(148, 163, 184, 0.3)',\n",
    "        line_width=0,\n",
    "        layer='below',\n",
    "        xref='x', yref='y'\n",
    "    )\n",
    "    # Optimal zone (green)\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=optimal_start, x1=optimal_end, y0=0, y1=105,\n",
    "        fillcolor='rgba(16, 185, 129, 0.3)',\n",
    "        line_width=0,\n",
    "        layer='below',\n",
    "        xref='x', yref='y'\n",
    "    )\n",
    "    # Too Late zone (red)\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=too_late_start, x1=max_day, y0=0, y1=105,\n",
    "        fillcolor='rgba(239, 68, 68, 0.3)',\n",
    "        line_width=0,\n",
    "        layer='below',\n",
    "        xref='x', yref='y'\n",
    "    )\n",
    "    \n",
    "    # Add zone labels at dynamic positions\n",
    "    fig.add_annotation(\n",
    "        x=too_early_end / 2, y=88,\n",
    "        text=f\"<b>Too Early</b><br><sup>(0-{too_early_end}d)</sup>\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=8, color='#64748B'),\n",
    "        xref='x', yref='y'\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=(optimal_start + optimal_end) / 2, y=88,\n",
    "        text=f\"<b>âœ“ OPTIMAL</b><br><sup>({optimal_start}-{optimal_end}d)</sup>\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=9, color='#059669'),\n",
    "        xref='x', yref='y'\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=(too_late_start + max_day) / 2, y=88,\n",
    "        text=f\"<b>Too Late</b><br><sup>({too_late_start}+d)</sup>\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=8, color='#DC2626'),\n",
    "        xref='x', yref='y'\n",
    "    )\n",
    "    \n",
    "    # 3. A/B Test or Risk Factors (Row 1, Col 3)\n",
    "    if has_ab_test:\n",
    "        ab_data = data['ab_test_data']\n",
    "        control_rate = ab_data['churn_rates']['control'] * 100\n",
    "        treatment_rate = ab_data['churn_rates']['treatment'] * 100\n",
    "        max_rate = max(control_rate, treatment_rate)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=['Control', 'Treatment'],\n",
    "                y=[control_rate, treatment_rate],\n",
    "                marker_color=['#6366F1', '#10B981'],  # Different colors\n",
    "                text=[f\"{control_rate:.1f}%\", f\"{treatment_rate:.1f}%\"],\n",
    "                textposition='outside',\n",
    "                textfont=dict(size=11, family='Arial Black'),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=3\n",
    "        )\n",
    "    else:\n",
    "        df = data['customer_df']\n",
    "        risk_factors = {}\n",
    "        \n",
    "        # Calculate risk factors from actual data \n",
    "        if 'has_payment_issues' in df.columns:\n",
    "            payment_churned = df[df['has_payment_issues'] == 1]['churned']\n",
    "            risk_factors['Payment'] = payment_churned.mean() * 100 if len(payment_churned) > 0 else None\n",
    "        else:\n",
    "            risk_factors['Payment'] = None\n",
    "            \n",
    "        if 'is_heavy_support_user' in df.columns:\n",
    "            support_churned = df[df['is_heavy_support_user'] == 1]['churned']\n",
    "            risk_factors['Support'] = support_churned.mean() * 100 if len(support_churned) > 0 else None\n",
    "        else:\n",
    "            risk_factors['Support'] = None\n",
    "            \n",
    "        if 'is_inactive' in df.columns:\n",
    "            inactive_churned = df[df['is_inactive'] == 1]['churned']\n",
    "            risk_factors['Inactive'] = inactive_churned.mean() * 100 if len(inactive_churned) > 0 else None\n",
    "        else:\n",
    "            risk_factors['Inactive'] = None\n",
    "        \n",
    "        # Filter out None values\n",
    "        risk_factors = {k: v for k, v in risk_factors.items() if v is not None}\n",
    "        \n",
    "        if not risk_factors:\n",
    "            print(\"âš ï¸ No risk factor data available - skipping Risk Factors chart\")\n",
    "            risk_factors = {'No Data': 0}\n",
    "        \n",
    "        max_rate = max(risk_factors.values()) if risk_factors else 1\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=list(risk_factors.keys()),\n",
    "                y=list(risk_factors.values()),\n",
    "                marker_color=['#EF4444', '#F59E0B', '#8B5CF6'],  # Different colors\n",
    "                text=[f'{v:.1f}%' for v in risk_factors.values()],\n",
    "                textposition='outside',\n",
    "                textfont=dict(size=10),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=3\n",
    "        )\n",
    "    \n",
    "    # ========== ROW 2 ==========\n",
    "    \n",
    "    # 4. CLV by Tier (Row 2, Col 1)\n",
    "    at_risk_df = data['at_risk_by_tier'].copy()\n",
    "    at_risk_df = at_risk_df.sort_values('CLV at Risk', ascending=False)\n",
    "    max_clv = at_risk_df['CLV at Risk'].max() if len(at_risk_df) > 0 else 1\n",
    "    \n",
    "    # Different colors for each tier\n",
    "    tier_colors = ['#8B5CF6', '#6366F1', '#3B82F6', '#0EA5E9'][:len(at_risk_df)]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=at_risk_df['Tier'],\n",
    "            y=at_risk_df['CLV at Risk'],\n",
    "            marker_color=tier_colors,  # Different colors\n",
    "            text=[f'${v/1000:.0f}K' for v in at_risk_df['CLV at Risk']],\n",
    "            textposition='outside',\n",
    "            textfont=dict(size=10),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 5. Intervention ROI (Row 2, Col 2)\n",
    "    # Use INTERVENTION_ROI calculated from A/B test data (in A/B Testing section)\n",
    "    if 'INTERVENTION_ROI' not in globals() or not globals()['INTERVENTION_ROI']:\n",
    "        print(\"âš ï¸ INTERVENTION_ROI not found - ROI chart will show 'No Data'\")\n",
    "        print(\"   Please run Section 5 (A/B Testing Framework) first.\")\n",
    "        INTERVENTION_ROI = None\n",
    "    else:\n",
    "        INTERVENTION_ROI = globals()['INTERVENTION_ROI']\n",
    "        print(f\"âœ… Using ROI from A/B test data: {INTERVENTION_ROI}\")\n",
    "    \n",
    "    if INTERVENTION_ROI is None:\n",
    "        # Show \"No Data\" message\n",
    "        fig.add_annotation(\n",
    "            x=0.5, y=0.5,\n",
    "            text=\"ROI Data Not Available<br>Run Section 5 (A/B Testing) first\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=12, color='#64748B'),\n",
    "            xref='x5 domain', yref='y5 domain'\n",
    "        )\n",
    "        max_roi = 10  # Default for axis\n",
    "    else:\n",
    "        interventions = list(INTERVENTION_ROI.keys())\n",
    "        roi_values = list(INTERVENTION_ROI.values())\n",
    "        max_roi = max(roi_values)\n",
    "        \n",
    "        # Different colors for each intervention (matching multi-variant chart)\n",
    "        roi_colors = ['#6366F1', '#8B5CF6', '#EC4899', '#10B981'][:len(interventions)]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=interventions,\n",
    "                y=roi_values,\n",
    "                marker_color=roi_colors,\n",
    "                text=[f'{r:.1f}x' for r in roi_values],\n",
    "                textposition='outside',\n",
    "                textfont=dict(size=10),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    # 6. Multi-Variant Analysis (Row 2, Col 3)\n",
    "    # Show churn rates for different intervention variants\n",
    "    if has_multi_variant and data.get('multi_variant_data'):\n",
    "        mv_data = data['multi_variant_data']\n",
    "        variants = list(mv_data['variants'].keys())\n",
    "        churn_rates = [mv_data['variants'][v]['churn_rate'] * 100 for v in variants]\n",
    "        variant_labels = variants  # Already properly formatted: ['Control', 'Email', 'Discount', 'Call', 'Combined']\n",
    "    else:\n",
    "        # No fallback - show message instead\n",
    "        print(\"âš ï¸ Multi-variant data not available - chart will show 'No Data'\")\n",
    "        print(\"   Please run Section 5 (A/B Testing Framework) first.\")\n",
    "        variant_labels = None\n",
    "        churn_rates = None\n",
    "    \n",
    "    if variant_labels is None or churn_rates is None:\n",
    "        # Show \"No Data\" message\n",
    "        fig.add_annotation(\n",
    "            x=0.5, y=0.5,\n",
    "            text=\"Multi-Variant Data Not Available<br>Run Section 5 (A/B Testing) first\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=12, color='#64748B'),\n",
    "            xref='x6 domain', yref='y6 domain'\n",
    "        )\n",
    "        max_mv_rate = 25  # Default for axis\n",
    "    else:\n",
    "        max_mv_rate = max(churn_rates)\n",
    "        \n",
    "        # Different colors for each variant\n",
    "        variant_colors = ['#94A3B8', '#6366F1', '#8B5CF6', '#EC4899', '#10B981'][:len(variant_labels)]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=variant_labels,\n",
    "                y=churn_rates,\n",
    "                marker_color=variant_colors,\n",
    "                text=[f'{v:.1f}%' for v in churn_rates],\n",
    "                textposition='outside',\n",
    "                textfont=dict(size=10),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=3\n",
    "        )\n",
    "    \n",
    "    # ========== LAYOUT ==========\n",
    "    \n",
    "    fig.update_layout(\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        title={\n",
    "            'text': '<b>ğŸš€ Proactive Churn Prevention - Executive Dashboard</b>',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 18, 'color': '#1e293b'}\n",
    "        },\n",
    "        showlegend=False,\n",
    "        paper_bgcolor='#fafafa',\n",
    "        plot_bgcolor='white',\n",
    "        margin=dict(t=60, b=40, l=50, r=40)\n",
    "    )\n",
    "    \n",
    "    # Update axes\n",
    "    # Optimal Intervention Window (Row 1, Col 2) - x/y\n",
    "    # Use dynamic range based on actual survival analysis window (120-day observation)\n",
    "    iw_max_day = int(max(data['intervention_window']['days']))\n",
    "    fig.update_xaxes(\n",
    "        title_text='Days Since Risk Detection',\n",
    "        range=[-2, iw_max_day + 5],\n",
    "        tickvals=[0, 20, 40, 60, 80, 100, 120][:len([t for t in [0, 20, 40, 60, 80, 100, 120] if t <= iw_max_day + 5])],\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text='Success %',\n",
    "        range=[0, 105],\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # A/B Test (Row 1, Col 3)\n",
    "    fig.update_yaxes(range=[0, max_rate * 1.4 if has_ab_test else 55], row=1, col=3)\n",
    "    \n",
    "    # CLV by Tier (Row 2, Col 1)\n",
    "    fig.update_yaxes(range=[0, max_clv * 1.35], row=2, col=1)\n",
    "    \n",
    "    # Intervention ROI (Row 2, Col 2)\n",
    "    fig.update_yaxes(range=[0, max_roi * 1.35], title_text='ROI (x)', row=2, col=2)\n",
    "    \n",
    "    # Multi-Variant Analysis (Row 2, Col 3)\n",
    "    fig.update_yaxes(range=[0, max_mv_rate * 1.4], title_text='Churn %', row=2, col=3)\n",
    "    \n",
    "    # Grid styling\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#f1f5f9')\n",
    "    fig.update_xaxes(showgrid=False)\n",
    "    fig.update_xaxes(tickangle=-20, row=2, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create and display dashboard\n",
    "print(\"\\nğŸ“Š Generating Executive Dashboard...\")\n",
    "executive_dashboard = create_full_executive_dashboard(dashboard_data)\n",
    "\n",
    "# Save PNG only\n",
    "save_figure_png(executive_dashboard, \"02_executive_dashboard.png\", width=1000, height=600, scale=2)\n",
    "\n",
    "# Display in notebook\n",
    "executive_dashboard.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. A/B TEST RESULTS DETAIL PANEL\n",
    "# ============================================================\n",
    "\n",
    "def create_ab_test_figure(data):\n",
    "    \"\"\"Create A/B test summary as a Plotly figure for PNG export.\"\"\"\n",
    "    \n",
    "    if not data.get('ab_test_data'):\n",
    "        return None\n",
    "    \n",
    "    ab = data['ab_test_data']\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=3,\n",
    "        specs=[[{\"type\": \"indicator\"}, {\"type\": \"bar\"}, {\"type\": \"indicator\"}]],\n",
    "        column_widths=[0.25, 0.5, 0.25],\n",
    "        subplot_titles=('', '<b>Churn Rate Comparison</b>', '')\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=['Control', 'Treatment'],\n",
    "            y=[ab['churn_rates']['control'] * 100, ab['churn_rates']['treatment'] * 100],\n",
    "            marker_color=['#94A3B8', '#10B981'],\n",
    "            text=[f\"{ab['churn_rates']['control']*100:.1f}%\", f\"{ab['churn_rates']['treatment']*100:.1f}%\"],\n",
    "            textposition='outside',\n",
    "            textfont=dict(size=16, family='Arial Black')\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Indicator(\n",
    "            mode=\"number+delta\",\n",
    "            value=ab['churn_rates']['treatment'] * 100,\n",
    "            delta={'reference': ab['churn_rates']['control'] * 100, 'relative': False, 'valueformat': '.1f'},\n",
    "            title={'text': 'Treatment Churn Rate', 'font': {'size': 14}},\n",
    "            number={'suffix': '%', 'font': {'size': 32, 'color': '#10B981'}}\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Indicator(\n",
    "            mode=\"number\",\n",
    "            value=ab['statistical_tests']['p_value'],\n",
    "            title={'text': f\"P-Value<br>{'âœ… Significant' if ab['conclusion']['is_significant'] else 'â³ Pending'}\", \n",
    "                   'font': {'size': 14}},\n",
    "            number={'valueformat': '.4f', 'font': {'size': 32, \n",
    "                    'color': '#10B981' if ab['conclusion']['is_significant'] else '#F59E0B'}}\n",
    "        ),\n",
    "        row=1, col=3\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        width=1000,\n",
    "        height=300,\n",
    "        title={\n",
    "            'text': f\"<b>ğŸ§ª A/B Test Results: {ab['experiment_name']}</b>\",\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 18, 'color': '#1e293b'}\n",
    "        },\n",
    "        paper_bgcolor='#fafafa',\n",
    "        plot_bgcolor='white',\n",
    "        margin=dict(t=70, b=30, l=30, r=30),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(range=[0, max(ab['churn_rates']['control'], ab['churn_rates']['treatment']) * 100 * 1.4], row=1, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def display_ab_test_summary(data):\n",
    "    \"\"\"Display detailed A/B test summary.\"\"\"\n",
    "    \n",
    "    if not data.get('ab_test_data'):\n",
    "        display(HTML(\"<p style='color: #94a3b8;'>â„¹ï¸ A/B test results not available. Run Section 9 first.</p>\"))\n",
    "        return\n",
    "    \n",
    "    ab = data['ab_test_data']\n",
    "    mv = data.get('multi_variant_data')\n",
    "    \n",
    "    winner_text = \"\"\n",
    "    if mv:\n",
    "        best_variant = None\n",
    "        best_lift = -999\n",
    "        for variant, stats in mv['variants'].items():\n",
    "            if variant != 'Control':\n",
    "                lift = stats.get('lift', 0)\n",
    "                if lift > best_lift:\n",
    "                    best_lift = lift\n",
    "                    best_variant = variant\n",
    "        \n",
    "        if best_variant:\n",
    "            winner_text = f\"\"\"\n",
    "            <div style=\"background: linear-gradient(135deg, #D1FAE5, #A7F3D0); padding: 15px; border-radius: 10px; margin-top: 15px;\">\n",
    "                <h4 style=\"margin: 0 0 8px 0; color: #059669; font-size: 14px;\">ğŸ† Multi-Variant Test Winner</h4>\n",
    "                <div style=\"font-size: 20px; font-weight: bold; color: #047857;\">{best_variant}</div>\n",
    "                <div style=\"color: #065F46; margin-top: 4px; font-size: 12px;\">Achieved {best_lift*100:.1f}% reduction in churn vs Control</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "    \n",
    "    ab_html = f\"\"\"\n",
    "    <style>\n",
    "        .ab-container {{\n",
    "            background: white;\n",
    "            border-radius: 12px;\n",
    "            padding: 20px;\n",
    "            margin: 15px 0;\n",
    "            box-shadow: 0 3px 10px rgba(0,0,0,0.08);\n",
    "            max-width: 1000px;\n",
    "        }}\n",
    "        .ab-header {{\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: center;\n",
    "            margin-bottom: 15px;\n",
    "            padding-bottom: 12px;\n",
    "            border-bottom: 2px solid #f1f5f9;\n",
    "        }}\n",
    "        .ab-title {{\n",
    "            font-size: 18px;\n",
    "            font-weight: 600;\n",
    "            color: #1e293b;\n",
    "        }}\n",
    "        .ab-status {{\n",
    "            padding: 5px 14px;\n",
    "            border-radius: 16px;\n",
    "            font-size: 13px;\n",
    "            font-weight: 500;\n",
    "        }}\n",
    "        .status-significant {{ background: #D1FAE5; color: #059669; }}\n",
    "        .status-pending {{ background: #FEF3C7; color: #D97706; }}\n",
    "        .ab-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(3, 1fr);\n",
    "            gap: 15px;\n",
    "            margin-bottom: 15px;\n",
    "        }}\n",
    "        .ab-stat {{\n",
    "            text-align: center;\n",
    "            padding: 12px;\n",
    "            background: #f8fafc;\n",
    "            border-radius: 8px;\n",
    "        }}\n",
    "        .ab-stat-value {{\n",
    "            font-size: 24px;\n",
    "            font-weight: 700;\n",
    "            color: #1e293b;\n",
    "        }}\n",
    "        .ab-stat-label {{\n",
    "            font-size: 12px;\n",
    "            color: #64748b;\n",
    "            margin-top: 4px;\n",
    "        }}\n",
    "        .ab-comparison {{\n",
    "            display: grid;\n",
    "            grid-template-columns: 1fr auto 1fr;\n",
    "            gap: 15px;\n",
    "            align-items: center;\n",
    "            margin: 20px 0;\n",
    "        }}\n",
    "        .ab-group {{\n",
    "            text-align: center;\n",
    "            padding: 15px;\n",
    "            border-radius: 10px;\n",
    "        }}\n",
    "        .ab-control {{ background: #f1f5f9; }}\n",
    "        .ab-treatment {{ background: linear-gradient(135deg, #D1FAE5, #A7F3D0); }}\n",
    "        .ab-vs {{ font-size: 20px; color: #94a3b8; }}\n",
    "        .ab-rate {{ font-size: 32px; font-weight: 700; }}\n",
    "        .ab-recommendation {{\n",
    "            background: linear-gradient(135deg, #EEF2FF, #E0E7FF);\n",
    "            padding: 15px;\n",
    "            border-radius: 10px;\n",
    "            margin-top: 15px;\n",
    "        }}\n",
    "        .ab-recommendation h4 {{ margin: 0 0 8px 0; color: #4F46E5; font-size: 14px; }}\n",
    "    </style>\n",
    "    \n",
    "    <div class=\"ab-container\">\n",
    "        <div class=\"ab-header\">\n",
    "            <div class=\"ab-title\">ğŸ§ª A/B Test Results: {ab['experiment_name']}</div>\n",
    "            <div class=\"ab-status {'status-significant' if ab['conclusion']['is_significant'] else 'status-pending'}\">\n",
    "                {'âœ… Statistically Significant' if ab['conclusion']['is_significant'] else 'â³ Not Yet Significant'}\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"ab-grid\">\n",
    "            <div class=\"ab-stat\">\n",
    "                <div class=\"ab-stat-value\">{ab['sample_sizes']['total']}</div>\n",
    "                <div class=\"ab-stat-label\">Total Participants</div>\n",
    "            </div>\n",
    "            <div class=\"ab-stat\">\n",
    "                <div class=\"ab-stat-value\" style=\"color: #10B981;\">{ab['lift']['relative_pct']}</div>\n",
    "                <div class=\"ab-stat-label\">Relative Lift</div>\n",
    "            </div>\n",
    "            <div class=\"ab-stat\">\n",
    "                <div class=\"ab-stat-value\">{ab['statistical_tests']['p_value']:.4f}</div>\n",
    "                <div class=\"ab-stat-label\">P-Value</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"ab-comparison\">\n",
    "            <div class=\"ab-group ab-control\">\n",
    "                <div style=\"font-size: 13px; color: #64748b; margin-bottom: 4px;\">CONTROL</div>\n",
    "                <div class=\"ab-rate\" style=\"color: #64748b;\">{ab['churn_rates']['control']*100:.1f}%</div>\n",
    "                <div style=\"font-size: 12px; color: #94a3b8;\">churn rate</div>\n",
    "            </div>\n",
    "            <div class=\"ab-vs\">VS</div>\n",
    "            <div class=\"ab-group ab-treatment\">\n",
    "                <div style=\"font-size: 13px; color: #059669; margin-bottom: 4px;\">TREATMENT</div>\n",
    "                <div class=\"ab-rate\" style=\"color: #059669;\">{ab['churn_rates']['treatment']*100:.1f}%</div>\n",
    "                <div style=\"font-size: 12px; color: #065F46;\">churn rate</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"text-align: center; color: #64748b; font-size: 13px;\">\n",
    "            95% Confidence Interval: [{ab['confidence_interval_95']['lower']*100:.2f}%, {ab['confidence_interval_95']['upper']*100:.2f}%]\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"ab-recommendation\">\n",
    "            <h4>ğŸ’¡ Recommendation</h4>\n",
    "            <p style=\"margin: 0; color: #4338CA; font-size: 13px;\">{ab['conclusion']['recommendation']}</p>\n",
    "        </div>\n",
    "        \n",
    "        {winner_text}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save PNG version\n",
    "    ab_fig = create_ab_test_figure(data)\n",
    "    if ab_fig:\n",
    "        save_figure_png(ab_fig, \"03_ab_test_summary.png\", width=1000, height=300, scale=2)\n",
    "    \n",
    "    display(HTML(ab_html))\n",
    "\n",
    "# Display A/B test summary\n",
    "print(\"\\nğŸ“‹ A/B Test Summary Panel:\")\n",
    "display_ab_test_summary(dashboard_data)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. PRIORITY CUSTOMERS TABLE\n",
    "# ============================================================\n",
    "\n",
    "def display_priority_customers(data):\n",
    "    \"\"\"Display top at-risk customers table.\"\"\"\n",
    "    \n",
    "    df = data['top_at_risk'].copy()\n",
    "    \n",
    "    table_html = \"\"\"\n",
    "    <style>\n",
    "        .customers-wrapper {\n",
    "            max-width: 1000px;\n",
    "            margin: 0 auto;\n",
    "        }\n",
    "        .customers-table {\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            background: white;\n",
    "            border-radius: 10px;\n",
    "            overflow: hidden;\n",
    "            box-shadow: 0 3px 10px rgba(0,0,0,0.08);\n",
    "            margin: 15px 0;\n",
    "        }\n",
    "        .customers-table th {\n",
    "            background: linear-gradient(135deg, #1e293b, #334155);\n",
    "            color: white;\n",
    "            padding: 12px;\n",
    "            text-align: left;\n",
    "            font-weight: 600;\n",
    "            font-size: 13px;\n",
    "        }\n",
    "        .customers-table td {\n",
    "            padding: 10px 12px;\n",
    "            border-bottom: 1px solid #f1f5f9;\n",
    "            font-size: 13px;\n",
    "        }\n",
    "        .customers-table tr:hover {\n",
    "            background: #f8fafc;\n",
    "        }\n",
    "        .risk-badge {\n",
    "            display: inline-block;\n",
    "            padding: 3px 8px;\n",
    "            border-radius: 10px;\n",
    "            font-size: 11px;\n",
    "            font-weight: 500;\n",
    "        }\n",
    "        .risk-critical { background: #FEE2E2; color: #DC2626; }\n",
    "        .risk-high { background: #FFEDD5; color: #EA580C; }\n",
    "        .tier-enterprise { background: #EDE9FE; color: #7C3AED; }\n",
    "        .tier-premium { background: #DBEAFE; color: #2563EB; }\n",
    "        .tier-standard { background: #F3F4F6; color: #4B5563; }\n",
    "        .tier-basic { background: #F3F4F6; color: #6B7280; }\n",
    "        .action-btn {\n",
    "            background: #6366F1;\n",
    "            color: white;\n",
    "            padding: 5px 12px;\n",
    "            border-radius: 5px;\n",
    "            font-size: 11px;\n",
    "            cursor: pointer;\n",
    "            border: none;\n",
    "        }\n",
    "    </style>\n",
    "    \n",
    "    <div class=\"customers-wrapper\">\n",
    "        <h3 style=\"color: #60a5fa; margin: 25px 0 12px 0; font-size: 16px;\">ğŸ¯ Priority At-Risk Customers</h3>\n",
    "        <table class=\"customers-table\">\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th>Customer ID</th>\n",
    "                    <th>Tier</th>\n",
    "                    <th>Churn Probability</th>\n",
    "                    <th>CLV</th>\n",
    "                    <th>Engagement</th>\n",
    "                    <th>Action</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "    \"\"\"\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        prob = row['churn_probability']\n",
    "        risk_class = 'risk-critical' if prob >= CONFIG['risk_tiers']['cutoffs']['critical'] else 'risk-high'\n",
    "        tier = row['subscription_tier']\n",
    "        tier_class = f\"tier-{tier.lower()}\"\n",
    "        \n",
    "        table_html += f\"\"\"\n",
    "        <tr>\n",
    "            <td><code style=\"background: #064e3b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px;\">{row['customer_id']}</code></td>\n",
    "            <td><span class=\"risk-badge {tier_class}\">{tier}</span></td>\n",
    "            <td>\n",
    "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
    "                    <div style=\"width: 50px; height: 6px; background: #e2e8f0; border-radius: 3px;\">\n",
    "                        <div style=\"width: {prob*100}%; height: 100%; background: {'#EF4444' if prob >= CONFIG['risk_tiers']['cutoffs']['critical'] else '#F97316'}; border-radius: 3px;\"></div>\n",
    "                    </div>\n",
    "                    <span class=\"risk-badge {risk_class}\">{prob*100:.0f}%</span>\n",
    "                </div>\n",
    "            </td>\n",
    "            <td style=\"font-weight: 600;\">${row['clv_estimate']:,.0f}</td>\n",
    "            <td>{row['engagement_score']:.1f}</td>\n",
    "            <td><button class=\"action-btn\">Intervene</button></td>\n",
    "        </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    table_html += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(table_html))\n",
    "\n",
    "# Display priority customers\n",
    "print(\"\\nğŸ“‹ Priority Customers Table:\")\n",
    "display_priority_customers(dashboard_data)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. EXECUTIVE SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "def create_executive_summary_figure(data):\n",
    "    # Calculate actual metrics from A/B test data\n",
    "    if data.get('ab_test_data'):\n",
    "        ab = data['ab_test_data']\n",
    "        actual_churn_reduction = f\"{ab['lift']['relative'] * 100:.1f}%\"\n",
    "        effect = ab['lift']['absolute']\n",
    "        actual_customers_saved = int(data['total_customers'] * effect) if effect > 0 else 0\n",
    "    else:\n",
    "        actual_churn_reduction = \"N/A\"\n",
    "        actual_customers_saved = \"N/A\"\n",
    "    \n",
    "    \"\"\"Create executive summary as a Plotly figure for PNG export.\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=3,\n",
    "        specs=[[{\"type\": \"table\"}, {\"type\": \"table\"}, {\"type\": \"table\"}]],\n",
    "        subplot_titles=('<b>âœ… Key Achievements</b>', '<b>âš ï¸ Current Risk</b>', '<b>ğŸ¯ Recommendations</b>')\n",
    "    )\n",
    "    \n",
    "    achievements = [\n",
    "        f\"{actual_churn_reduction} churn rate reduction\",\n",
    "        f\"{actual_customers_saved} customers saved (projected)\", \n",
    "        f\"{int(SURVIVAL_INTERVENTION_STATS.get('median_days', 45))}-day early warning system\" if 'SURVIVAL_INTERVENTION_STATS' in globals() else \"Early warning system\",\n",
    "        f\"Optimal window: days {SURVIVAL_INTERVENTION_STATS.get('window_start', 15)}-{SURVIVAL_INTERVENTION_STATS.get('window_end', 45)}\" if 'SURVIVAL_INTERVENTION_STATS' in globals() else \"Optimal window: see survival analysis\"\n",
    "    ]\n",
    "    \n",
    "    risks = [\n",
    "        f\"{data['total_at_risk']} customers at risk\",\n",
    "        f\"${data['total_clv_at_risk']/1000:.0f}K CLV at risk\",\n",
    "        \"Payment issues = highest risk\",\n",
    "        \"Enterprise tier priority\"\n",
    "    ]\n",
    "    \n",
    "    recommendations = [\n",
    "        f\"Intervene within {SURVIVAL_INTERVENTION_STATS.get('window_start', 15)}-{SURVIVAL_INTERVENTION_STATS.get('window_end', 45)} days\" if 'SURVIVAL_INTERVENTION_STATS' in globals() else \"Intervene early\",\n",
    "        \"Scale re-engagement (5-10x expected ROI)\",\n",
    "        \"Address payment issues\",\n",
    "        \"Continue A/B testing\"\n",
    "    ]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Table(\n",
    "            cells=dict(\n",
    "                values=[achievements],\n",
    "                fill_color='rgba(16, 185, 129, 0.1)',\n",
    "                align='left',\n",
    "                font=dict(size=11),\n",
    "                height=28\n",
    "            )\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Table(\n",
    "            cells=dict(\n",
    "                values=[risks],\n",
    "                fill_color='rgba(245, 158, 11, 0.1)',\n",
    "                align='left',\n",
    "                font=dict(size=11),\n",
    "                height=28\n",
    "            )\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Table(\n",
    "            cells=dict(\n",
    "                values=[recommendations],\n",
    "                fill_color='rgba(99, 102, 241, 0.1)',\n",
    "                align='left',\n",
    "                font=dict(size=11),\n",
    "                height=28\n",
    "            )\n",
    "        ),\n",
    "        row=1, col=3\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        width=1000,\n",
    "        height=250,\n",
    "        title={\n",
    "            'text': '<b>ğŸ“Š Executive Summary</b>',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 18, 'color': '#1e293b'}\n",
    "        },\n",
    "        paper_bgcolor='#fafafa',\n",
    "        margin=dict(t=60, b=15, l=15, r=15)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def display_executive_summary(data):\n",
    "    \"\"\"Display executive summary with recommendations.\"\"\"\n",
    "    \n",
    "    # Calculate actual metrics from A/B test data\n",
    "    if data.get('ab_test_data'):\n",
    "        ab = data['ab_test_data']\n",
    "        actual_churn_reduction = f\"{ab['lift']['relative'] * 100:.1f}%\"\n",
    "        effect = ab['lift']['absolute']\n",
    "        actual_customers_saved = int(data['total_customers'] * effect) if effect > 0 else 0\n",
    "    else:\n",
    "        actual_churn_reduction = \"N/A\"\n",
    "        actual_customers_saved = \"N/A\"\n",
    "    \n",
    "    at_risk_by_tier = data['at_risk_by_tier'].copy()\n",
    "    at_risk_by_tier = at_risk_by_tier.sort_values('CLV at Risk', ascending=False)\n",
    "    \n",
    "    if len(at_risk_by_tier) > 0:\n",
    "        priority_tier = at_risk_by_tier.iloc[0]['Tier']\n",
    "        priority_clv = at_risk_by_tier.iloc[0]['CLV at Risk']\n",
    "        priority_text = f\"Prioritize <strong>{priority_tier}</strong> tier (${priority_clv/1000:.0f}K at risk)\"\n",
    "    else:\n",
    "        priority_text = \"Monitor all tiers\"\n",
    "    \n",
    "    tier_priorities = []\n",
    "    for i, (_, row) in enumerate(at_risk_by_tier.iterrows()):\n",
    "        if i < 3:\n",
    "            tier_priorities.append(f\"{row['Tier']}: ${row['CLV at Risk']/1000:.0f}K\")\n",
    "    \n",
    "    ab_insight = \"\"\n",
    "    if data.get('ab_test_data'):\n",
    "        ab = data['ab_test_data']\n",
    "        if ab['conclusion']['is_significant']:\n",
    "            ab_insight = f\"<li>A/B test shows <strong>{ab['lift']['relative_pct']} lift</strong> - statistically significant</li>\"\n",
    "        else:\n",
    "            ab_insight = f\"<li>A/B test trending positive ({ab['lift']['relative_pct']}) - needs more data</li>\"\n",
    "    \n",
    "    mv_insight = \"\"\n",
    "    if data.get('multi_variant_data'):\n",
    "        mv = data['multi_variant_data']\n",
    "        best = None\n",
    "        best_lift = 0\n",
    "        for variant, stats in mv['variants'].items():\n",
    "            if variant != 'Control' and stats.get('lift', 0) > best_lift:\n",
    "                best_lift = stats['lift']\n",
    "                best = variant\n",
    "        if best:\n",
    "            mv_insight = f\"<li>Best intervention: <strong>{best}</strong> ({best_lift*100:.0f}% lift)</li>\"\n",
    "    \n",
    "    summary_html = f\"\"\"\n",
    "    <div style=\"background: linear-gradient(135deg, #1e293b, #334155); color: white; padding: 25px; border-radius: 12px; margin-top: 25px; max-width: 1000px;\">\n",
    "        <h2 style=\"margin: 0 0 20px 0; text-align: center; font-size: 18px;\">ğŸ“Š Executive Summary</h2>\n",
    "        \n",
    "        <div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px;\">\n",
    "            <div style=\"background: rgba(16, 185, 129, 0.2); padding: 15px; border-radius: 10px; border-left: 4px solid #10B981;\">\n",
    "                <h3 style=\"color: #10B981; margin: 0 0 12px 0; font-size: 14px;\">âœ… Key Achievements</h3>\n",
    "                <ul style=\"margin: 0; padding-left: 18px; font-size: 12px; line-height: 1.7;\">\n",
    "                    <li>{actual_churn_reduction} churn rate reduction</li>\n",
    "                    <li>{actual_customers_saved} customers saved (projected)</li>\n",
    "                    <li>{int(SURVIVAL_INTERVENTION_STATS.get(\"median_days\", 45))}-day early warning system</li>\n",
    "                    <li>Optimal intervention: days {SURVIVAL_INTERVENTION_STATS.get(\"window_start\", 15)}-{SURVIVAL_INTERVENTION_STATS.get(\"window_end\", 45)}</li>\n",
    "                    {ab_insight}\n",
    "                </ul>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"background: rgba(245, 158, 11, 0.2); padding: 15px; border-radius: 10px; border-left: 4px solid #F59E0B;\">\n",
    "                <h3 style=\"color: #F59E0B; margin: 0 0 12px 0; font-size: 14px;\">âš ï¸ Current Risk</h3>\n",
    "                <ul style=\"margin: 0; padding-left: 18px; font-size: 12px; line-height: 1.7;\">\n",
    "                    <li>{data['total_at_risk']} customers at risk</li>\n",
    "                    <li>${data['total_clv_at_risk']/1000000:.1f}M CLV at risk</li>\n",
    "                    <li>Priority: {', '.join(tier_priorities) if tier_priorities else 'All tiers'}</li>\n",
    "                    <li>Payment issues = highest risk factor</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"background: rgba(99, 102, 241, 0.2); padding: 15px; border-radius: 10px; border-left: 4px solid #6366F1;\">\n",
    "                <h3 style=\"color: #818CF8; margin: 0 0 12px 0; font-size: 14px;\">ğŸ¯ Recommendations</h3>\n",
    "                <ul style=\"margin: 0; padding-left: 18px; font-size: 12px; line-height: 1.7;\">\n",
    "                    <li>{priority_text}</li>\n",
    "                    {mv_insight if mv_insight else '<li>Scale re-engagement programs (5-10x expected ROI)</li>'}\n",
    "                    <li>Intervene within optimal window ({SURVIVAL_INTERVENTION_STATS.get(\"window_start\", 15)}-{SURVIVAL_INTERVENTION_STATS.get(\"window_end\", 45)} days)</li>\n",
    "                    <li>Continue A/B testing new strategies</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"text-align: center; margin-top: 20px; padding-top: 15px; border-top: 1px solid rgba(255,255,255,0.2);\">\n",
    "            <span style=\"color: #94a3b8; font-size: 11px;\">\n",
    "                Powered by Proactive Churn Prevention Multi-Agent System â€¢ Google ADK + Vertex AI\n",
    "            </span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save PNG version\n",
    "    summary_fig = create_executive_summary_figure(data)\n",
    "    save_figure_png(summary_fig, \"05_executive_summary.png\", width=1000, height=250, scale=2)\n",
    "    \n",
    "    display(HTML(summary_html))\n",
    "\n",
    "# Display executive summary\n",
    "print(\"\\nğŸ“‹ Executive Summary:\")\n",
    "display_executive_summary(dashboard_data)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… ALL VISUALIZATIONS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "ğŸ“ Directory: {os.path.abspath(VIZ_DIR)}\n",
    "\n",
    "PNG Files Created:\n",
    "   â€¢ 01_key_metrics.png          - Key metrics (static)\n",
    "   â€¢ 02_executive_dashboard.png  - Executive dashboard (2x3 layout)\n",
    "   â€¢ 03_ab_test_summary.png      - A/B test summary (static)\n",
    "   â€¢ 05_executive_summary.png    - Executive summary (static)\n",
    "\n",
    "ğŸ“Š Dashboard Layout (2 rows Ã— 3 columns):\n",
    "   Row 1: Risk Distribution | Optimal Intervention Window | A/B Test Results\n",
    "   Row 2: CLV at Risk by Tier | Intervention ROI | Multi-Variant Analysis\n",
    "\n",
    "ğŸ¯ Optimal Intervention Window (from Survival Model):\n",
    "   â€¢ Window boundaries derived from Cox PH survival predictions\n",
    "   â€¢ Based on predicted_days_until_churn for high-risk customers\n",
    "   â€¢ See SURVIVAL_INTERVENTION_STATS for exact values\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Deployment package created at /tmp/churn_prevention_agent\n",
      "\n",
      "Files:\n",
      "  - requirements.txt\n",
      "  - __init__.py\n",
      "  - README.md\n",
      "  - .env\n",
      "  - agent.py\n",
      "\n",
      "âš ï¸  NOTE: agent.py contains STUB functions.\n",
      "   Replace with real implementations before production use.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DEPLOYMENT PACKAGE (Template with Stubs)\n",
    "# ============================================================\n",
    "# This creates a deployable package structure for production.\n",
    "# NOTE: The tool functions below are STUBS for demonstration.\n",
    "# In production, replace with implementations that:\n",
    "# 1. Load the trained models (CHURN_MODEL, SURVIVAL_MODEL)\n",
    "# 2. Read from customer database\n",
    "# 3. Return real predictions\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "DEPLOY_DIR = \"/tmp/churn_prevention_agent\"\n",
    "\n",
    "if os.path.exists(DEPLOY_DIR):\n",
    "    shutil.rmtree(DEPLOY_DIR)\n",
    "os.makedirs(DEPLOY_DIR)\n",
    "\n",
    "# Write agent.py with stub implementations\n",
    "# In production, these should load models and query real data\n",
    "agent_code = '''\"\"\"\n",
    "Proactive Churn Prevention Agent - ADK v1.0.0+\n",
    "\n",
    "IMPORTANT: This is a TEMPLATE with stub functions.\n",
    "For production deployment:\n",
    "1. Replace stub functions with real implementations\n",
    "2. Load trained models (churn_model.pkl, survival_model.pkl)\n",
    "3. Connect to customer database\n",
    "4. Use the patterns from Cell 11 for real implementations\n",
    "\"\"\"\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.code_executors import BuiltInCodeExecutor\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STUB FUNCTIONS - Replace with real implementations\n",
    "# See Cell 11 for production-ready patterns\n",
    "# ============================================================\n",
    "\n",
    "def calculate_churn_score(customer_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    STUB: Calculate churn risk score for a customer.\n",
    "    \n",
    "    Production implementation should:\n",
    "    1. Load customer data from database\n",
    "    2. Apply trained LogisticRegression model\n",
    "    3. Return model.predict_proba() result\n",
    "    \"\"\"\n",
    "    # TODO: Replace with real implementation\n",
    "    # Example: return model.predict_proba(customer_features)[0][1]\n",
    "    return {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"churn_probability\": 0.45,  # STUB VALUE\n",
    "        \"risk_tier\": \"Medium\",\n",
    "        \"key_risk_factors\": [\"Low engagement\"],\n",
    "        \"model_source\": \"STUB - Replace with trained model\"\n",
    "    }\n",
    "\n",
    "\n",
    "def recommend_intervention(customer_id: str, churn_probability: float, risk_factors: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    STUB: Generate retention intervention recommendation.\n",
    "    \n",
    "    ALIGNED WITH A/B TEST VARIANTS:\n",
    "    - Email: Automated campaigns (high ROI)\n",
    "    - Discount: Price incentives (medium ROI)\n",
    "    - Call: Personal outreach (high-touch)\n",
    "    - Combined: Multi-channel (critical cases)\n",
    "    \n",
    "    Production implementation should use intervention rules\n",
    "    based on customer segment and risk factors.\n",
    "    \"\"\"\n",
    "    # TODO: Replace with real implementation from Section 6\n",
    "    return {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"intervention_channel\": \"Email\",  # Aligned with A/B variants\n",
    "        \"intervention_action\": \"Re-engagement email campaign\",\n",
    "        \"priority\": 3,\n",
    "        \"expected_lift\": 0.15,\n",
    "        \"roi_estimate\": 12.1,\n",
    "        \"channel_source\": \"STUB - Replace with A/B test results\"\n",
    "    }\n",
    "\n",
    "\n",
    "def get_customer_behavior(customer_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    STUB: Get customer behavioral summary.\n",
    "    \n",
    "    Production implementation should query customer database\n",
    "    and calculate real engagement metrics.\n",
    "    \"\"\"\n",
    "    # TODO: Replace with real implementation\n",
    "    return {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"engagement_score\": 45.0,\n",
    "        \"risk_flags\": {\"is_inactive\": True}\n",
    "    }\n",
    "\n",
    "\n",
    "# Agent definition (same for production)\n",
    "# Note: gemini-2.5-flash only supports ONE tool per agent\n",
    "root_agent = Agent(\n",
    "    name=\"ChurnPreventionOrchestrator\",\n",
    "    model=VERTEX_MODEL,\n",
    "    description=\"Proactive Churn Prevention System\",\n",
    "    instruction=\"\"\"Analyze customer churn risk.\n",
    "    Use calculate_churn_score to get churn probability for customers.\"\"\",\n",
    "    tools=[calculate_churn_score]  # Single tool for gemini-2.5-flash\n",
    ")\n",
    "'''\n",
    "\n",
    "with open(f\"{DEPLOY_DIR}/agent.py\", \"w\") as f:\n",
    "    f.write(agent_code)\n",
    "\n",
    "# Write __init__.py\n",
    "with open(f\"{DEPLOY_DIR}/__init__.py\", \"w\") as f:\n",
    "    f.write('from .agent import root_agent\\n')\n",
    "\n",
    "# Write requirements.txt\n",
    "with open(f\"{DEPLOY_DIR}/requirements.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"google-adk>=1.0.0\n",
    "pandas>=2.0.0\n",
    "numpy>=1.24.0\n",
    "scikit-learn>=1.3.0\n",
    "lifelines>=0.27.0\n",
    "\"\"\")\n",
    "\n",
    "# Write .env template\n",
    "env_content = f\"\"\"# Environment configuration\n",
    "GOOGLE_GENAI_USE_VERTEXAI=TRUE\n",
    "GOOGLE_CLOUD_PROJECT={PROJECT_ID}\n",
    "GOOGLE_CLOUD_LOCATION={REGION}\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{DEPLOY_DIR}/.env\", \"w\") as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "# Write README\n",
    "readme = \"\"\"# Churn Prevention Agent - Deployment Package\n",
    "\n",
    "## Setup\n",
    "1. Install dependencies: `pip install -r requirements.txt`\n",
    "2. Configure `.env` with your GCP credentials\n",
    "3. Replace stub functions in `agent.py` with real implementations\n",
    "\n",
    "## Production Checklist\n",
    "- [ ] Replace calculate_churn_score() with trained model\n",
    "- [ ] Replace get_customer_behavior() with database query\n",
    "- [ ] Replace recommend_intervention() with business rules\n",
    "- [ ] Add model files (churn_model.pkl, survival_model.pkl)\n",
    "- [ ] Configure database connection\n",
    "- [ ] Set up monitoring and logging\n",
    "\n",
    "## Running\n",
    "```bash\n",
    "adk run .\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{DEPLOY_DIR}/README.md\", \"w\") as f:\n",
    "    f.write(readme)\n",
    "\n",
    "print(f\"âœ… Deployment package created at {DEPLOY_DIR}\")\n",
    "print(f\"\\nFiles:\")\n",
    "for f in os.listdir(DEPLOY_DIR):\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(f\"\\nâš ï¸  NOTE: agent.py contains STUB functions.\")\n",
    "print(f\"   Replace with real implementations before production use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                    DEPLOYMENT COMMANDS                         â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "# Navigate to deployment directory\n",
      "cd /tmp/churn_prevention_agent\n",
      "\n",
      "# Deploy with ADK CLI\n",
      "adk deploy --project=sunlit-gamma-342416 --region=us-central1\n",
      "\n",
      "# Verify deployment\n",
      "adk list --project=sunlit-gamma-342416 --region=us-central1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deployment commands\n",
    "print(f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    DEPLOYMENT COMMANDS                         â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Navigate to deployment directory\n",
    "cd {DEPLOY_DIR}\n",
    "\n",
    "# Deploy with ADK CLI\n",
    "adk deploy --project={PROJECT_ID} --region={REGION}\n",
    "\n",
    "# Verify deployment\n",
    "adk list --project={PROJECT_ID} --region={REGION}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 13: Cleanup (CRITICAL)\n",
    "\n",
    "âš ï¸ **ALWAYS RUN THIS** to prevent unexpected charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ§¹ CLEANUP\n",
      "============================================================\n",
      "\n",
      "# List deployed agents\n",
      "gcloud ai reasoning-engines list --project=YOUR_PROJECT --region=us-central1\n",
      "\n",
      "# Delete agent (replace AGENT_ID with actual ID)\n",
      "# gcloud ai reasoning-engines delete AGENT_ID --project=YOUR_PROJECT --region=us-central1\n",
      "\n",
      "âœ… Session memory cleared\n",
      "âš ï¸ Memory store cleanup: 'CustomerMemoryStore' object has no attribute '_memories'\n",
      "âœ… A/B test data cleared\n",
      "âœ… Async cleanup handler registered\n",
      "âœ… Memory garbage collected\n",
      "\n",
      "============================================================\n",
      "âœ… CLEANUP COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  CLEANUP \n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ§¹ CLEANUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Delete Vertex AI resources \n",
    "cleanup_commands = \"\"\"\n",
    "# List deployed agents\n",
    "gcloud ai reasoning-engines list --project=YOUR_PROJECT --region=us-central1\n",
    "\n",
    "# Delete agent (replace AGENT_ID with actual ID)\n",
    "# gcloud ai reasoning-engines delete AGENT_ID --project=YOUR_PROJECT --region=us-central1\n",
    "\"\"\"\n",
    "print(cleanup_commands)\n",
    "\n",
    "# 2. Clear session memory\n",
    "if 'session_service' in dir():\n",
    "    try:\n",
    "        session_service.sessions.clear()\n",
    "        print(\"âœ… Session memory cleared\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Session cleanup: {e}\")\n",
    "\n",
    "# 3. Clear customer memory store\n",
    "if 'memory_store' in dir():\n",
    "    try:\n",
    "        memory_store.clear()\n",
    "        print(\"âœ… Customer memory store cleared\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Memory store cleanup: {e}\")\n",
    "\n",
    "# 4. Clear A/B test data\n",
    "if 'ab_manager' in dir():\n",
    "    try:\n",
    "        ab_manager.experiments.clear()\n",
    "        ab_manager.results.clear()\n",
    "        print(\"âœ… A/B test data cleared\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ A/B cleanup: {e}\")\n",
    "\n",
    "# 5. Suppress async cleanup error\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*was never retrieved.*\")\n",
    "logging.getLogger('asyncio').setLevel(logging.CRITICAL)\n",
    "\n",
    "# 6. Properly close pending async tasks\n",
    "import asyncio\n",
    "from contextlib import suppress\n",
    "\n",
    "def cleanup_async():\n",
    "    \"\"\"Safely cleanup async resources to prevent BaseApiClient error.\"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            pending = asyncio.all_tasks(loop)\n",
    "        except RuntimeError:\n",
    "            pending = set()\n",
    "        \n",
    "        for task in pending:\n",
    "            task.cancel()\n",
    "            with suppress(asyncio.CancelledError):\n",
    "                loop.run_until_complete(task)\n",
    "                \n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "import atexit\n",
    "atexit.register(cleanup_async)\n",
    "\n",
    "print(\"âœ… Async cleanup handler registered\")\n",
    "\n",
    "# 7. Clear large dataframes from memory\n",
    "import gc\n",
    "\n",
    "large_vars = ['customer_df', 'train_df', 'test_df', 'results_df']\n",
    "for var in large_vars:\n",
    "    if var in dir():\n",
    "        try:\n",
    "            exec(f\"del {var}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "gc.collect()\n",
    "print(\"âœ… Memory garbage collected\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… CLEANUP COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "churn_env",
   "language": "python",
   "name": "churn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
